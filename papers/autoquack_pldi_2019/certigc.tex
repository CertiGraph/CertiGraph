In this section, we explain how we used our graph library
to verify a generational copying garbage collector for the 
CertiCoq compiler. The GC is our most complicated example,
and we will discuss some of its key proofs, but the larger
point here is that we completed this certification using 
exactly the framework and the principles we have discussed
thus far. {\color{magenta}We enjoyed significant code 
reuse from our prior certifications, and when we stated 
new lemmas for the GC, we filed them away at the appropriate
``layers'' so that they may be reused in the future.}

% The last line above is currently false.
% We cannot edit the code to make it 100% true, 
% but the plan is to incorporate GCGraph's special
% properties into a soundness condition that will be
% added atop a LiMaFin-type LabeledGraph.
% Having done that, I'll weaken the last line
% above to match the actual work.

\subsection{Background}
\label{sec:gcbackground}

% My goal here is to start with a broad overview
% and then work my way down to forward
% at the end of this subsection I want it to be pretty
% clear that the whole game is just a series of calls
% to forward.
% This will set us up nicely for the decorated proof of
% forward in the next subsection.

The CertiCoq Project compiles Gallina code into CompCert 
C light, and then uses CompCert to compile C light
into assembly. In order to support Gallina's presumption of
infinite heap memory, CertiCoq provides garbage collection at
the C light level. Their generational copying garbage 
collector is written in C light, and is realistic, 
supporting variable-sized words, 12 generations... 
% Leaving this slot open for the time being, so
% we can highlight those features that we will discuss 
% the most in the technical part later.
Since CertiCoq aims to be end-to-end certified, the GC 
also needs certification.

The GC's client program, also called the mutator, controls
an array of arguments that it cares about. 
% Looking for better term than "cares about"
These arguments may point at memory blocks 
in the heap, and, recursively, the items in those
memory blocks may point at other blocks in the heap. 
By maintaining direct and indirect links to
blocks via this internal ``web of care'', 
% I'm a little iffy about introducing this additional
% analogy, but then again I don't want to introduce
% the analogy of a graph right away. That could be seen
% as a huge conceptual leap, and a skipped step. 
the mutator indicates that it 
cares about those blocks, and reserves the right to 
access them for reading or writing. 
% Maybe add a line about how the mutator can "drop"
% a block, thus showing that it won't need it anymore?

When the mutator runs out of heap space, 
it calls the garbage collector to free up memory. 
The GC is allowed to modify the heap as
it sees fit, with the condition that it not damage the 
mutator's web of care. By this we mean that the same items 
should be accessible from the mutator's arguments
array before and after the collection, and they 
should be reached from the arguments array by 
following similar links as before. 
Other features of the original web, such as where 
items were situated in the heap, may be changed. 
In SECTION, we will explain how we abstracted this
web into a mathematical graph, where preserving the 
web of care is analogous to showing graph isomorphism.

``We thus say that the arguments array is owned by the 
mutator, but the heap is owned by the GC.''

\subsection{Structure of the Program}
\label{sec:gcstructure}
% maybe a diagram showing how everythign calls forward? 
% I sketched one before, can show you sometime.
Ours is a generational copying garbage collector, which
means that it leans on the empirical observation that
new blocks often need to be collected soon after their
allocation, while blocks that survive this initial
culling tend to live for much longer.
% Hm, it would take about another 100 words to explain 
% this fully. I'm wondering if we can elide it, 
% treating the above as adequate revision, and assuming 
% they know the rest of the story.

The mutator only ever allocates new memory in the first, 
smallest generation of heap. This generation is thus 
called the nursery. On finding that the nursery is full, 
the mutator calls the garbage collector to free up space.
The main GC function triggers the collection of the nursery
into the second generation, which is twice in size. These generations
are called the \emph{from} and \emph{to} generations respectively.
To trigger a collection means to examine the elements 
in \emph{from}, see if they are accessible from the mutator's
args array either directly or indirectly, and, if they are, 
copy them over to \emph{to}. This copying is achieved over a few steps, 
and we will examine these shortly, but the larger picture is that 
everything of import in \emph{from} has been copied to \emph{to}, 
and so \emph{from} can safely be reset. The mutator will now have 
enough room for the allocation that it was trying to perform.

One subtlety in this discussion is that we enjoyed a 
guarantee that \emph{to} had enough room to accept 
\emph{from}'s items. In the (unlikely) worst case, 
\emph{all} of \emph{from}'s data was copied over to \emph{to}, 
so in other words \emph{to} could not have been more than 
half full. We relied on this guarantee before this collection, 
and we must ensure we will enjoy it the next time a collection 
is required. So, in case the collection of the nursery caused
the second generation to become more than half full, we trigger
a collection of the second generation to the third. This makes 
both the first and second generations empty, thus giving us our 
guarantee trivially. It should be 
clear to see that this may also trigger further collections in 
a cascade effect. 

Armed with an understanding of how the overall collection 
works, we move one level deeper and examine how we identify and 
copy those items in a \emph{from} generation that are reachable
from the args array tot he \emph{to} generation.

% 150 or so words that explain forward_roots and do_scan.
% End goal is to convince them that everything relies on forward, 
% and forward is all that remains to be explained.
% I can do this writing, just taking a break.

\subsection{Forward}
\label{sec:gcforward}
The Garbage Collector's main workhorse is the function \emph{forward}.
Given a pointer to a block that is in the \emph{from} generation, 
it makes a copy of that block in the \emph{to} generation.
{\color{blue}Maybe at this point we could dedicate one or 
two sentences to explaining that the whole dang opera is really just 
calls to \emph{forward}.}

Figure (blah) shows a decorated proof of the forward function.
The function's behavior is subtly different depending on 
whether the the pointer $p$ lives in the arguments array or in the 
heap itself. The difference lies in lines blah and blah, where 
we wish to update $p$ to point to the new forwarded block. 
When $p$ lives in the arguments array, this update is easy to 
reason about since $p$ is fundamentally $\bigstar$-separated from our heap. 
When $p$ is itself in the heap, this update itself constitutues a
write to the heap. In the decorated proof, we show the second 
case. To this end, we assume in line (blah) that p is (dododo). 

\input{forward_listing.tex}

\subsection{Issues}
\label{sec:gccsemantics}

\paragraph{Pointer Subtraction.}
{\color{blue}Hmm I'm wondering if we should really be mentioning this,
strapped as we are for space. Anyway, will steal off your emails.}
\input{boundary.tex}

\paragraph{Double-Bounded Pointer Comparisons}







