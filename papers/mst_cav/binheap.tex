\lstset{style=myTinyStyle}

A binary heap embeds a heap-ordered tree in an array and uses arithmetic on indices to navigate between a parent and its left and right children~\cite{clrs}.  In addition to providing the standard \texttt{insert} and \texttt{remove-min}/\texttt{remove-max} operations (depending on whether it is a min- or max-ordered heap) in logarithmic time, binary heaps can by upgraded to support two nontrivial operations.  First, Floyd's \texttt{heapify} function builds a binary heap from an unordered array in linear time, and as a related upgrade, \texttt{heapsort} performs a worst-case linearithmic-time sort using only constant additional space.  Second, binary heaps can be upgraded to support logarithmic-time \texttt{decrease-} and \texttt{increase-priority} operations, which we generalize straightforwardly into \texttt{edit\_priority}.

Binary heaps are a good fit for our graph algorithms because Dijkstra's and Prim's algorithms need to edit priorities, and a constant-space \texttt{heapsort} is appropriate for the sparse edge-list-represented graphs typically targeted by Kruskal's.  The~C language has poor support for polymorphic higher-order functions, and a binary heap that supports \texttt{edit\_priority} is half as fast as a binary heap that does not.  Accordingly, we implement binary heaps in C three times:
\[
\begin{array}{l@{\quad}c@{\quad}c@{\quad}c@{\quad}l}
\text{Name} & \text{Heap order} & \texttt{edit\_priority} & \texttt{heapify} & \text{Payload} \\
\hline
\text{basic} & \text{min} & \text{no} & \text{yes} & \texttt{void*} \\
\text{advanced} & \text{min} & \text{yes} & \text{no} & \texttt{int} \\
\text{Kruskal} & \text{max} & \text{no} & \text{yes} & \texttt{int, int} \text{ (\emph{i.e.}, unboxed)}
\end{array}
\]
Priorities are of type \texttt{int}.  %\note[too much detail, too soon?]{The ``advanced'' implementation requires each item to be tagged to a ``key'', which is used to lookup the item whose priority must be changed; these keys are \texttt{unsigned int}s.}
The Kruskal-specific implementation is stripped down to the bare minimum required to implement \texttt{heapsort} (\emph{e.g.} it does not support \texttt{insert}).  We next overview these verifications in three parts: basic heap operations, \texttt{heapify} and \texttt{heapsort} operations, and the \texttt{edit\_priority} operation.

\subsection{The basic heap operations of insertion and min/max-removal}
\label{sec:heapinsertremove}

Because we are juggling three implementations, we take some care to factor our verification to maximize reuse.  First, each C implementation has its own exchange and comparison functions that handle the nitty-gritty of the payload and choose between a min or max heap.  The following lines are from the ``basic'' implementation, in which the ``payload'' (\texttt{data} field) is of type \texttt{void*}:
\begin{lstlisting}[firstnumber=5]
void exch(unsigned int j, unsigned int k, Item arr[]) {
 int priority = arr[j].priority; void* data = arr[j].data;
 arr[j].priority = arr[k].priority; arr[j].data = arr[k].data;
 arr[k].priority = priority; arr[k].data = data; }
int less(unsigned int j, unsigned int k, Item arr[]) {
 return (arr[j].priority <= arr[k].priority); }
\end{lstlisting}
These C functions are specified as refinements of Gallina functions that exchange polymorphic data in lists and compare objects in an abstract preordered set; we verify them in VST after a little irksome engineering.  The payoff is that the key heap operations, which, following Sedgewick~\cite{sedgewick}, we call \texttt{swim} and \texttt{sink}, can use identical~C code (up to alpha renaming) in all three implementations:
\begin{lstlisting}[firstnumber=last]
void swim(unsigned int k, Item arr[]) {
 while (k > ROOT_IDX && less (k, PARENT(k), arr)) {
  exch(k, PARENT(k), arr); k = PARENT(k);         } }
void sink (unsigned int k, Item arr[], unsigned int available) {
 while (LEFT_CHILD(k) < available) {
  unsigned j = LEFT_CHILD(k);
  if (j+1 < available && less(j+1, j, arr)) j++; $\label{code:sinkplusplus}$
  if (less(k, j, arr)) break; exch(k, j, arr); k = j;        } }
\end{lstlisting}
These functions involve a number of complexities, both at the algorithms level and at the semantics-of-C level.  At the C level, there is the potential for a rather subtle bug in the macros \texttt{ROOT\_IDX}, \texttt{PARENT}, etc.  Abstractly, these are simple: the root is in index 0; the children of $x$ at roughly $2x$ and the parent at roughly~$\frac{x}{2}$, with $\pm1$ as necessary.  The danger is thinking that because the variables are \texttt{unsigned int}, all arithmetic will occur in this domain; in fact we must force the associated constants into \texttt{unsigned int} as well:
\[
\begin{array}{@{}l@{~~}|@{~}l@{}}
\begin{minipage}{0.475\textwidth}
\begin{lstlisting}
#define ROOT_IDX  0u
#define PARENT(x) (x-1u)/2u
\end{lstlisting} \end{minipage} &
\begin{minipage}{0.5\textwidth}
\lstset{firstnumber=3}
\begin{lstlisting}
#define LEFT_CHILD(x)  (2u*x)+1u
#define RIGHT_CHILD(x) 2u*(x+1u)
\end{lstlisting}
\end{minipage}
\end{array}
\]
A second C-semantics issue is the potential for overflow within \texttt{LEFT\_CHILD} and \texttt{RIGHT\_CHILD} (as well as the increments on line~\ref{code:sinkplusplus}), and underflow within the \texttt{PARENT} macro (if \texttt{x} should ever be 0).  To avoid this overflow, the precondition of \texttt{sink} requires that when $\texttt{k}$ is in bounds (\emph{i.e.}, $\texttt{k} < \texttt{available}$), then $2\cdot(\texttt{available}-1) \leq \texttt{max\_unsigned}$.  An edge case occurs when deleting the last element from a heap ($\texttt{k}=\texttt{available}$); we then require $2\cdot\texttt{k}\leq \texttt{max\_unsigned}$.

\lstset{style=CoqStyle}

At the algorithmic level, both the \texttt{swim} and \texttt{sink} functions involve nontrivial loop invariants; \texttt{sink} is complicated by the further need to support Floyd's \texttt{heapify}, during which a large portion of the array is unordered.  Accordingly, we build Gallina models of both functions and show that they restore heap order given a mostly-ordered input heap.  There are two different versions of ``mostly-ordered''. Specifically, \texttt{swim} uses a ``bottom-up'' version:
\begin{lstlisting}[firstnumber=5]
Definition weak_heapOrdered2 (L : list A) (j : nat) : Prop :=
 ($\forall$ i b, i $\neq$ j $\rightarrow$ nth_error L i = Some b $\rightarrow$
   $\forall$ a, nth_error L (parent i) = Some a $\rightarrow$ a $\preceq$ b) $\wedge$
 (grandsOk L j root_idx).
\end{lstlisting}
whereas \texttt{sink} uses a ``top-down'' version:
\begin{lstlisting}[firstnumber=last]
Definition weak_heapOrdered_bounded (L:list A) (k:nat) (j:nat) :=
 ($\forall$ i a, i $\ge$ k $\rightarrow$ i $\neq$ j $\rightarrow$ nth_error L i = Some a $\rightarrow$
  ($\forall$ b, nth_error L (left_child i) = Some b $\rightarrow$ a $\preceq$ b) $\wedge$
  ($\forall$ c, nth_error L (right_child i) = Some c $\rightarrow$ a $\preceq$ c)) $\wedge$
 (grandsOk L j k).
\end{lstlisting}
The parameter \texttt{j} indicates a ``hole'', at which the heap may not be heap-ordered; \texttt{grandsOk} bridges this hole by
ordering the parent and the children of \texttt{j}:
\begin{lstlisting}
Definition grandsOk (L : list A) (j : nat) (k : nat) : Prop :=
  j $\neq$ root_idx $\rightarrow$ parent j $\geq$ k $\rightarrow$
    $\forall$ gs bb, parent gs = j $\rightarrow$ nth_error L gs = Some bb $\rightarrow$
      $\forall$ a, nth_error L (parent j) = Some a $\rightarrow$ a $\preceq$ bb.
\end{lstlisting}
The parameter \texttt{k} is used to support Floyd's \texttt{heapify}: it bounds the portion of the list in which elements are heap-ordered (with the exception of \texttt{j}).  The proofs that the Gallina \texttt{swim} and \texttt{sink} can restore (bounded) heap-orderedness involve a number of edge cases, but given the above definitions go through.  The invariants of the~C~versions of \texttt{swim} and \texttt{sink} are stated via the associated
Gallina versions, thereby delegating all heap-ordering proofs to the Gallina versions.

The insertion and remove functions we verify are in fact ``non-checking'' versions (\texttt{insert\_nc} and \texttt{remove\_nc}): their preconditions assume there is room in the heap to add or an item in the heap to remove.  In the context of Dijkstra and Prim, these preconditions can be proven to hold.  The associated verifications involve a little separation logic hackery (specifically, to \textsc{Frame} away the ``junk'' part of the heap-array from the ``live'' part), but are straightforward using VST.  We avoid the overflow issue in \texttt{sink} by bounding the maximum capacity of the heap: $4 \le 12\cdot\texttt{capacity} \leq \texttt{max\_unsigned}$; the magic number 12 comes from the size of the underlying data structure in~C.  We require users to prove this bound on heap creation, and thereafter handle it under the hood.

\lstset{style=myTinyStyle}

\subsection{Bottom-up heapify and heapsort}
\label{sec:heapsort}

Floyd's bottom-up procedure for constructing a binary heap in linear time, and using a binary heap to sort, are classics of the literature~\cite{clrs,sedgewick}.
Happily, while the asymptotic bound on heap construction is nontrivial, the implementations of both are basically repeated calls to \texttt{sink} (and exchanges to remove the root):
\begin{lstlisting}[firstnumber=19]
void build_heap(Item arr[], unsigned int size) {
 unsigned int start = PARENT(size); $\label{code:parentunderflow}$
 while(1) { sink(start, arr, size);
            if (start == 0) break; start--;  } }
void heapsort_rev(Item* arr, unsigned int size) {
 build_heap(arr,size); $\label{code:buildheapsort}$
 while (size > 1) { size--;
  exch(ROOT_IDX, size, arr); sink(ROOT_IDX, arr, size); } }
\end{lstlisting}
Given that in \S\ref{sec:heapinsertremove} we already generalized the specification for \texttt{sink} to handle a portion of the array being unordered, the verification of these functions is straightforward.  There is, however, the possibility of a subtle underflow on line~\ref{code:parentunderflow}, in the case when building an empty heap (\emph{i.e.}, $\texttt{size}=0$).  In turn, this means that \texttt{heapsort\_rev} as given above cannot sort empty lists; in our ``basic'' implementation we strengthen the precondition accordingly, whereas in our ``Kruskal'' implementation we add a line before~\ref{code:buildheapsort} that \texttt{return}s when $\texttt{size}=0$.  We use a max-heap for Kruskal because heapsort yields a \emph{reverse} sorted list.

\subsection{Modifying an element's priority}
\label{sec:modpri}

%In contrast to \texttt{heapify} and \texttt{heapsort}, standard algorithms textbooks are vague on the implementation of .

To support edit-priority, each live item is associated not only with its usual \texttt{int} priority
but also given a unique \texttt{unsigned int} ``key'', generated during \texttt{insert} and returned to the client.
The binary heap internally maintains a secondary array \texttt{key\_table} that maps each key to the current location of the associated item within the primary heap array. The client calls \texttt{edit\_priority} by supplying the key for the item that it wishes to modify, which the binary heap looks up in the \texttt{key\_table} to
locate the item in the heap array before calling \texttt{sink} or \texttt{swim}. To keep everything linked together, the \texttt{key\_table} is modified during \texttt{exch}ange.

To generate the keys on insert, we store a key field within each heap-item in the main array.  These keys are initialized to $0..(\texttt{capacity}-1)$, and thereafter are never modified other than when two cells are swapped during \texttt{exch}ange.  An invariant can then be maintained that the keys from the ``live'' and ``junk'' parts have no duplicates.  On insertion, we ``recycle'' the key of the first ``junk'' item, which is by the invariant known to be appropriately fresh.

%The VST proofs of the C code are only slightly more challenging since the key complexities are encapsulated into the \texttt{exch} function.

\subsection{Related work on binary heaps in algorithms and formal methods}
\label{sec:relworkbinheap}

J. W. J. Williams published the binary heap data structure, along with heapsort, in June 1964~\cite{10.1145/512274.512284}.  Floyd proposed his linear-time bottom-up method to construct such heaps that December~\cite{10.1145/355588.365103}.  Since then, binary heaps, including Floyd's construction and heapsort, have become a staple of the introductory data structure diet~\cite{clrs}.  On the other hand, standard textbooks are surprisingly vague on the implementation of \texttt{edit\_priority}~\cite{clrs,sedgewick,DBLP:books/daglib/0015106}, and completely silent on the generation of fresh keys during insertion.  Our method above of ``recycling keys'' avoids a subtle overflow in a na\"ive approach, and does not appear in the literature we examined.  The na\"ive idea is to have a global counter starting at 0, which is then increased on each insert.  Unfortunately, this is unsound: during (very) long runs involving both \texttt{insert} and \texttt{remove-min}, this key counter will overflow.  Although overflow is defined in C for \texttt{unsigned int}, this overflow is fatal algorithmically: multiple live items could be assigned the same key.

%Unlike the graph algorithms discussed in \S\ref{sec:dijkstra}, \S\ref{sec:prim}, and \S\ref{sec:kruskal}, b

Binary heaps have been verified several times in the literature.  Indeed, they were problem 2 of the VACID-0 benchmark~\cite{Leino10vacid-0:verification}, and solved in this regard as well by the Why3 team~\cite{tafat:binheap}.  These solutions did not implement bottom-up heap construction or edit priority.  The Viper team has verified heapsort~\cite{Muelleremail}.
Lammich has verified Introsort, which includes a heapsort subroutine~\cite{DBLP:conf/cade/Lammich20}.  %He generates LLVM code, \emph{i.e.} uses a deep embedding.
As best we can tell, the previous formal work largely ignores some of the nitty-gritty of~C~code such as the difference between signed and unsigned arithmetic.  We believe we are the first formally verified binary heap to support edit-priority.
