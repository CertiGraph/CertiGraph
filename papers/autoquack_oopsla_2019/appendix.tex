
\appendix

\section{Spanning and Copying}
\label{apx:spanning}

\input{spanning.tex}

In Figure~\ref{fig:spanning} we show a simplified proof script for
the spanning tree algorithm.  Unlike graph marking, the spanning tree algorithm changes the
structure of the graph, leading to a more complicated specification,
in both the pure part and the spatial part. Observe that the $\m{span}$ relation is
rather long; the $\m{e\_span}$ handles the case of either calling spanning tree or deleting an edge.

We put the proof sketch of the graph copying algorithm in
Figure~\ref{fig:copy-part1} and Figure~\ref{fig:copy-part2}. Just like
other parts of the paper, both algorithms have been machine verified.

\input{copy.tex}


%\section{Proof of \infrulestyle{Ramify-P} and \infrulestyle{Ramify-PQ}}
%\label{apx:ruleproofs}

\hide{
\begin{figure*}
Proof of \infrulestyle{Ramify-P} from \infrulestyle{Frame} and \infrulestyle{Consequence}:
\vspace{-3em}
\[
\begin{array}{c}
\infrule{}{
  G_1 |- L_1 * \pguards{c}(L_2 --* G_2) \\
  \infrule{}{\{L_1\}~c~\{L_2\}}
            {\{L_1 * \pguards{c}(L_2 --* G_2)\}~c~\{L_2 * \pguards{c}(L_2 --* G_2)\}}{(1)} \\
  \infrule{}{
            \infrule{}{\stackrel{\langle c \rangle}{\cong} \text{ is reflexive}}{\pguards{c}(L_2 --* G_2) |- L_2 --* G_2}{(2)}}
            {L_2 * \pguards{c}(L_2 --* G_2) |- G_2}{(3)}}
{\{G_1\}~c~\{G_2\}}
{} \\
[5pt]
(1)~ \forall P.~ \pguards{c}P \text{ ignores } \FV(c) \qquad (2)~ \text{axiom T of modal logic} \qquad (3)~ (P * Q |- R) <=> (P |- Q --* R)
\end{array}
\]

Proof of \infrulestyle{Ramify-PQ} from \infrulestyle{Ramify-P}:
\vspace{-4em}
\[
\begin{array}{c}
\infrule{}
{
  \{L_1\}~c~\{\exists x.~ L_2\} \hspace{-0.5em} \\
  \infrule{}
  {
    G_1 |- L_1 * \pguards{c}\big(\forall x.~ (L_2 --* G_2)\big) \hspace{-0.5em} \\
    \infrule{}{
      \infrule{}{
        \infrule{}{
          \vdots
        } {
          \forall x.~ (L_2 --* G_2) |- (\exists x.~ L_2) --* (\exists x.~ G_2)
        } {(1)}
      } {
        \pguards{c}\big(\forall x.~ (L_2 --* G_2)\big) |- \pguards{c}\big((\exists x.~ L_2) --* (\exists x.~ G_2)\big)
      } {(2)}
    } {
      L_1 * \pguards{c}\big(\forall x.~ (L_2 --* G_2)\big) |- L_1 * \pguards{c}\big((\exists x.~ L_2) --* (\exists x.~ G_2)\big)
    } {}
  } {
    G_1 |- L_1 * \pguards{c}\big((\exists x.~ L_2) --* (\exists x.~ G_2)\big)
  } {}
} {
  \{G_1\}~c~\{\exists x.~ G_2\}
} {}
\\
[5pt]
(1)~ \text{tautology using $(P * Q |- R) <=> (P |- Q --* R)$} \qquad (2)~ \text{reduction using modal axioms K and N} %\qquad (3)~ (P |- Q) => (P * F |- Q * F)
\end{array}
\]
\caption{Proofs of \infrulestyle{Ramify-P} and \infrulestyle{Ramify-PQ}}
\label{fig:rampqproofs}
\end{figure*}

See Figure~\ref{fig:rampqproofs} for the proofs of \infrulestyle{Ramify-P} and \infrulestyle{Ramify-PQ}. 
}

\section{Difficulty using $\graphkt$}
\label{apx:problemrecgraph}

\begin{figure*}
\[
\infrule{}
{\infrule{}
  {100 |-> 42,100,0 ~ |- ~ 100 |-> 42,100,0 ** \graphkt(100,\hat{\gamma})}
  {100 |-> 42,100,0 ~ |- ~ \hat{\gamma}(100) = (42,100,0) ~ /| ~ 100 |-> 42,100,0 ** \graphkt(100,\hat{\gamma}) ** \graphkt(0,\hat{\gamma})}
  {(2)}
}
{100 |-> 42,100,0 ~ |- ~ \graphkt(100,\hat{\gamma})}
{(1)}
\]
(1) Unfold $\graphkt$, dismiss first disjunct (contradiction), introduce existentials (which must be 42,100,0) \\
(2) simplify using $P * \p{emp} -|- P$ and remove pure conjunct

\caption{An attempt to prove a ``simple'' entailment}
\label{fig:badcycle}
\end{figure*}

See Figure \ref{fig:badcycle} for an attempt to prove the entailment $100 |-> 42,100,0 ~ |- ~ \graphkt(100,\hat{\gamma})$.  Part of the problem is that the recursive structure interacts very badly with $**$: if the recursion involved~$*$then it \textbf{would} be provable, by induction on the finite memory (each ``recursive call'' would be on a strictly smaller subheap).  This is why Knaster-Tarski works so well with list, tree, and DAG predicates in separation logic.

\section{Problem with Appel and McAllester's fixpoint}
\label{apx:appelfixpiont}

Appel and McAllester proposed another fixpoint $\mu_{\mathsf{A}}$
that is sometimes used to define recursive predicates in separation
logic \cite{appel:fixpoint}.  This time the functional $F_P$ needs to be
\emph{contractive}, which to a first order of approximation means that
all recursion needs to be guarded by the ``approximation
modality''~$\rhd$~\cite{appel:vmm}, \emph{i.e.} our graph predicate would
look like
\begin{align*}
\grapham(x, \gamma) ~ &\stackrel{\Delta}{=}\\
 (x = 0 /| \p{emp}) & |/ \exists m,l,r.~ \gamma(x)=(m,l,r) /| \null \\
 x |-> m,l,r & ** \rhd \grapham(l, \gamma) ** \rhd \grapham(r, \gamma)
\end{align*}

Unfortunately, $\rhd P$ is not precise for all $P$, so $\grapham$ is not precise either.  The approximation modality's universal imprecision has never been noticed before.

\section{Structure of the Garbage Collector Program}
\label{apx:gcstructure}

% My goal here is to start with a broad overview
% and then work my way down to forward.
% At the end of this subsection I want it to be pretty
% clear that the whole game is just a series of calls
% to forward.
% This will set us up nicely for the decorated proof of
% forward in the next subsection.

% maybe a diagram showing how everything calls forward? 
CertiCoq uses a generational copying garbage collector 
that is inspired by the OCaml GC. 
\hide{It leans on the empirical observation that
new blocks often need to be collected soon after their
allocation, while blocks that survive this initial
culling tend to live for much longer.
% I'm wondering if we can elide this. 
% Treat the above as adequate revision and assume
% they know the rest of the story.
}%end hide
The heap is divided into a series of disjoint
spaces called \emph{generations}. The size of the first generation
is carefully calculated, and then subsequent generations
double in size.
The mutator only ever allocates new memory in the first, 
smallest generation of heap, which is called the nursery. 
If it finds that the nursery is full, 
the mutator calls the GC to free up space.
The GC collects the nursery 
(now called the \emph{from} generation)
into the second generation (the \emph{to} generation): 
it examines the elements 
in \emph{from}, sees if they are accessible by
the mutator, and, if they are, 
copies them over to \emph{to}. This copying is achieved over a few steps, 
and we will explain these shortly, but the larger picture is that 
everything of importance in \emph{from} gets copied to \emph{to}, 
and so \emph{from} can safely be reset. 

An important subtlety here is that \emph{to} had enough 
room to accept \emph{from}'s items. 
In the (empirically improbable) worst case, 
\emph{all} of \emph{from}'s fields were copied over to \emph{to}.
Because \emph{to} has twice the capacity of \emph{from},
\emph{to} could not have been more than half full when 
the collection started.
This guarantee must be renewed before the next collection. 
So, in case the collection of the nursery caused
the second generation to become more than half full, 
the second generation is collected into the third. This makes 
both the first and second generations empty, thus ensuring 
the guarantee trivially. It should be 
clear to see that this may also trigger further collections in 
a cascade effect. The GC's task is only complete once this 
cascade (if any) is over. It returns control to the mutator,
which goes ahead with 
the allocation that it was trying to perform in the nursery.

Having shown that the overall collection 
works via (a series of) two-generational collections, 
we now zoom in and explain a two-generation collection.
The GC starts at the mutator-owned arguments array, whose fields
are either data, or pointers that point at memory blocks in the 
heap. It ignores the data entirely, and, among the pointers, 
cares only for the pointers that point into the \emph{from} generation. 
For each pointer that points into \emph{from}, it copies its
target block to \emph{to}, simply adding it in its entirety 
after \emph{to}'s last-used memory field, which is called \emph{next}. 

This operation only takes care of the blocks in the heap that 
the arguments array was pointing at directly, so the GC still has to copy 
over indirectly-accessible blocks. Of course, the only way to 
access an indirect 
block is via one of the direct blocks that it has
just finished copying into a contiguous array. 
It starts at the old \emph{next} in \emph{to}
and works its way ``upwards'' through the freshly copied blocks, 
again looking exclusively for pointers that point into \emph{from}
and copying over their target blocks into \emph{to}. 
In the \emph{to} generation, these newly copied blocks 
simply get stacked atop our first batch of copied blocks. 

The mutator's dependency graph has indefinite depth, so the second 
batch of copied blocks may still have pointers into \emph{from}. 
However, thanks to this systematic
copying strategy, it is very easy to take care of all indirect
blocks. The GC simply keeps scanning upwards in 
\emph{to}, copying over blocks from \emph{from} as necessary, 
until the scanning pointer catches up to the last-used field in
\emph{to}. This completes a collection 
from \emph{from} to \emph{to}, copying all blocks that lived
in \emph{from} and were of interest to the mutator. 
\emph{from} is now reset.

A good question at this juncture is why this rather selective scan 
of the args array and the heap is good enough to collect \emph{from}. 
The GC definitely collected every direct block by scanning the args array,
but what of the indirect blocks? Couldn't there be valid indirect links
that start either below \emph{next} in the \emph{to} generation, 
or from other generations altogether? 

Both of these turn out to be impossible because the 
mutator behaves in a purely functional manner.
The heap is chronologically
faithful, in that higher-indexed generations host
objects that were allocated earlier. Because
of the immutability of objects in a purely functional language, 
it is impossible for objects to point ``backwards'' to 
a younger generation, as the older object would not have
had known about the younger at the time of its allocation, and could not 
have been modified after its allocation. Fields living in generations 
younger than \emph{from} can point into \emph{from} during 
normal mutator activity, but this is
impossible at the time of collection: 
\emph{from} is only ever collected either if it is
the nursery or if a cascade effect has caused all generations younger
than it to be collected and reset. 
In fact, the only time the GC ever sees backwards pointers
is when it creates (and quickly fixes) them during during its 
activities.

\section{Code for Forward Relation}
\label{apx:forwardrelation}
\input{forward_relation_listing.tex}

% \section{Code of Garbage Collector}
% Below we present the code of the garbage collector in its entirety.
% \input{gc.tex}
