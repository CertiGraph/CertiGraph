\input{find_listing.tex}

As an initial demonstration of our techniques, we show the decorated code of the 
\texttt{find} function from the classic disjoint-set data structure~\cite{blah} in 
Figure~\ref{fig:find}. \texttt{find} returns the root 
(ultimate parent) of a \texttt{Node} \texttt{x}. A node is a root when its parent 
pointer points to itself (line~\ref{code:ufif}); 
other than such self-loops at roots, the structure is acyclic. 
For good amortised performance, \texttt{find} also performs path 
compression (line~\ref{code:ufpathcompress}).
At first, \texttt{find} appears rather trivial since it only has about 5 lines 
of code and a \texttt{Node} has only a single outgoing pointer.  
In actual fact, the rather subtle nature of path compression and the 
implicit sharing inherent in parent-pointers make the disjoint-set data 
structure very difficult to reason about. Indeed, the first pen-and-paper 
verification in separation logic required 20 pages~\cite{neelthesis}.

\marginpar{\tiny \color{blue} Would you consider $V_\gamma$ and $E_\gamma$?}
We use a number of basic concepts in our invariants.  We write~$\gamma$ to 
mean a ``mathematical'' (or ``pure'') graph: \emph{roughly}, a set of 
labeled vertices {\color{magenta}$V(\gamma)$ and edges $E(\gamma)$.} 
When $v \in V(\gamma)$, we write $\gamma(v) = (r,p)$ to state that vertex $v$ has 
label $r$ and parent vertex $p$ ($r$ stores the ``rank'' of a node; it is ignored 
in \texttt{find} but used in \texttt{union}).  Pure predicates are written in 
\textit{italic}.  We explain more about mathematical graphs in~\S\ref{sec:mathgraph}. 
Turning our attention to the spatial predicates, each node $v \in V(\gamma)$ will be 
represented by $v \mapsto \gamma(v) {\color{blue} = (r,p)}$ in the heap, 
where we use the usual pen-and-paper 
\marginpar{\tiny \color{blue}I think it would be clearer if it was ``$\m{sizeof}(r)$''.}
trick of writing \emph{e.g.} $v \mapsto r,p$ to mean 
\mbox{$v |-> r * (v + \m{sizeof}(\texttt{\color{magenta}unsigned int})) |-> p$} in the C memory model.
\marginpar{\tiny \color{blue}Bigstar coming in unexplained.}
The whole graph (the entire disjoint-set forest) is then represented by 
$\p{uf\_graph}(\gamma)$, {\color{magenta}essentially the 
separating conjunction of} the representations 
of all the individual verticies $v \in V(\gamma)$. 
Spatial predicates are written 
in \textsf{sans-serif}.  We explain more about spatial graphs in~\S\ref{sec:spacegraph}.

{\color{magenta}Standing as we do on the shoulders of giants, we can see 
further and more clearly.} The invariants at 
each program point are natural despite only minor tidying from our machine-checked 
proof.  We also enjoy good separation between the spatial predicates and pure 
predicates.  All of this is despite verifying real C code, which entails quite a number 
of grungy details. As one example, we will examine some grunginess that occurs in the 
verification of line~\ref{code:ufif} shortly.

The precondition on line~\ref{code:findstart} says exactly that we have a disjoint-set forest representing the abstract graph $\gamma$ and that \texttt{x} is a valid vertex in $\gamma$.  The postcondition is on line~\ref{code:findend}: the heap is representing a new union-find graph $\gamma''$, and \texttt{find} \texttt{ret}urns the node \m{rt}.  
\marginpar{\tiny \color{blue} explain reachability?} 
{\color{magenta}We specify that $\m{rt}$
is the root (ultimate parent) of \texttt{x} with the pure relation $\m{uf\_root}$.}  
We likewise describe how $\gamma''$ 
relates to the original graph $\gamma$ via the relation $\m{findS}$, which 
{\color{magenta}conservatively approximates} the action of path compression.

Most of the verification is straightforward: each individual line of code 
(\ref{code:findram1}, \ref{code:ufif}, \ref{code:ufreccall}, \ref{code:ufpathcompress}, 
and \ref{code:ufreturn}) is bracketed with invariants leading to relatively easy proofs 
of the command (ignoring the symbols $\searrow \text{, } \ramify(i) \text{, and } 
\swarrow$ until~\S\ref{sec:localblocks}).  

In addition to improving human comprehensibility, this 
also aids mechanical comprehensibility---that is, straightforward 
invariants help the underlying verification engine (VST, in our case) handle many grungy 
details for us either automatically or with a little human guidance via suitable lemmas.

The pointer comparison in line~\ref{code:ufif} is an example of where 
such lemmas are necessary. 
Formally, pointer (in-)equality comparison in C is only allowed under somewhat delicate 
circumstances\footnote {\color{magenta}\label{footnote:pointereq}Specifically, 
whenever \texttt{x} and \texttt{p} are both null; or when one of them is null and the 
other has offset between 0 and the size of the memory block into which it is pointing; 
or when if \texttt{x} and \texttt{p} are from the same memory block, then both of their 
offsets are between 0 and the size of that block; or when \texttt{x} and \texttt{p} are 
not in the same memory block and both have offsets between 0 and the size of their 
respective memory blocks \emph{minus one}.}.  VST could prove the definedness of the 
pointer comparison automatically if we knew 
$\texttt{x} |-> \_ * \texttt{p} |-> \_ * \top$, but
unfortunately this does not follow from line~\ref{code:aftparentfind} since, 
when \texttt{x} is a root, self-loop gives us $\texttt{x}=\texttt{p}$ and 
then, because of the way $*$ works, 
$\texttt{x} |-> \_ * \texttt{x} |-> \_ \vdash \bot$.  Accordingly, we must prove a 
relatively simple lemma that states that when $\p{uf\_graph}(\gamma) /| \texttt{x} 
\in V(\gamma) /| {\color{magenta} \texttt{p} \in V(\gamma)}$,
the pointer comparison is defined in C.

\subsection{Localization Blocks}
\label{sec:localblocks}

It is time to explain the not-so-obvious jumps in reasoning punctuated by the 
symbols $\searrow \text{, } \ramify(i)$, and $\swarrow$ 
(lines~\ref{code:ufbefram1}--\ref{code:ufaftram1} and~\ref{code:ufbefram2}--\ref{code:ufaftram2}).  {\color{magenta}As explained above, the verification of the command itself is entirely straightforward given its immediate neighbors (lines~\ref{code:befparentfind}--\ref{code:aftparentfind} and~\ref{code:findbeforexparent}--\ref{code:findafterxparent}).  What is not so straightforward is how \emph{e.g.} line~\ref{code:ufbefram1} leads to line~\ref{code:befparentfind} or how line~\ref{code:aftparentfind} leads to line~\ref{code:ufaftram1}.} The intuitive idea is that we zoom in from a larger ``global'' context to a smaller ``local'' one.  After verifying some commands locally to arrive at a local postcondition, we zoom back out to the global context.  The $\searrow$ and $\swarrow$ symbols formally indicate an application of the \textsc{Localize} rule (\ref{eq:localize}) from page~\pageref{eq:localize}.

{\color{magenta}Recall that \textsc{Localize} connects some ``global'' to a ``local'' one by using five predicates.  For the purposes of guiding intuition in \S\ref{sec:localblocks}, we will use a simpler variant of \textsc{Localize} called \textsc{Ramify} for a moment:}

\begin{equation}
\label{eq:ramify}
\inferrule[Localize]
{\{ L_1 \} ~ c ~ \{ L_2 \} \\
G_1 |- L_1 * (L_2 --* G_2)}
{\{ G_1 \} ~ c ~ \{ G_2 \}} \mathit{freevars}(L_2 --* G_2) \cap \MV(c) = \emptyset
\end{equation}

\marginpar{\tiny \color{blue} I really feel like we're backing into this point. I'd like
to rework it a little.}
{\color{magenta}The \emph{ramification entailment} $G_1 |- L_1 * (L_2 --* G_2)$ captures two key ideas: 
first, that $L_1$ is spatially contained within $G_1$; and second, that 
\emph{replacing} $L_1$ with $L_2$ inside $G_1$ yields $G_2$. \textsc{Ramify} essentially 
combines the two entailments in \textsc{Localize} into one by forcing the choice of 
$R \defeq L_2 --* G_2$; it also does not support the full power of existential 
quantifiers (quantifiers can appear \emph{within} $L_2$ and $G_2$, but 
\emph{the witnesses of such quantifiers cannot be related to each other}).  
Although \textsc{Ramify} is sound\footnote{Use \textsc{Localize} with 
$P -|- \exists x : \m{unit}.P$ for any $x$ not free in $P$.}, 
we shall soon see that these drawbacks are serious.}

Using either \textsc{Localize} or \textsc{Ramify}, the lines adjacent to 
the~$\searrow$ and~$\swarrow$ symbols specify~$G_1$ (line~\ref{code:ufbefram1}), 
$L_1$~(\ref{code:befparentfind}),
$L_2$~(\ref{code:aftparentfind}), and~$G_2$~(\ref{code:ufaftram1}). 
When we want to refer to the ramification entailment of a localization block in 
subsequent text we use the symbol $\ramify(i)$ to connect it to relevant equation 
numbers.  Accordingly, $\ramify(\ref{findram1})$ refers to the ramification entailment 
associated with lines~\ref{code:ufbefram1}--\ref{code:ufaftram1}:
\begin{equation}
\label{findram1}
\p{graph}(\gamma) /| x \in V(\gamma) \quad |- \quad x |-> \gamma(x) * \big(x |-> \gamma(x) --* \p{graph}(\gamma)\big)
%\p{graph}(\gamma) /| x \in V(\gamma) |- x |-> \gamma(x) * (\overbrace{x |-> \gamma(x)}^{L_2'} --* \overbrace{\p{graph}(\gamma)}^{G_2'})
\end{equation}
Here we isolate the spatial parts of the invariants on lines~\ref{code:ufbefram1}--\ref{code:ufaftram1}.  Notice that this lemma is stated for any whole-graph predicate $\p{graph}(\gamma)$, and not merely for the special class of ``union-find graphs'' $\p{uf\_graph}(\gamma)$ (that \emph{e.g.} have only one outgoing edge per node).  That is useful because we use the same lemma to prove similar goals in all of our examples.
Indeed, this ``unchanged vertex'' ramification entailment is used whenever we need to read from a vertex in a graph.  In~\S\ref{sec:spacegraph} we describe other generic and reusable lemmas that prove other ramification entailments.

Unfortunately, we still have a problem: the side condition above requires that 
the free variables of $L_2 --* G_2$ be disjoint from any local variables modified 
by $c$.  Inspection of lines~\ref{code:findram1}--\ref{code:ufaftram1} shows that the 
program variable \texttt{p} \textbf{is} modified by $c$, and \textbf{is} free in 
both $L_2$ and $G_2$.  This problem is fundamental: the whole point of verifying 
a read is to know something about the value that has been read.  Accordingly, 
although \textsc{Ramify} is sound, it is not strong enough to verify
lines~\ref{code:ufbefram1}--\ref{code:ufaftram1}.  We will address this problem 
head-on in~\S\ref{sec:existentials}, but for now let us content ourselves with knowing 
that other than the side condition, \textsc{Ramify} lets us verify 
lines \ref{code:ufbefram1}--\ref{code:ufaftram1}.

The second localization block (lines~\ref{code:ufbefram2}--\ref{code:ufaftram2}) is both easier and harder than the first.  It is easier because \textsc{Ramify} \textbf{is} strong enough to verify it. Line~\ref{code:ufpathcompress} does not modify any local program variables, so the side condition is trivially satisfied.  Moreover, although line~\ref{code:ufaftram2} does contain an existential, line~\ref{code:findafterxparent} does not, and so there is no need to ``link'' the two associated witnesses.  On the other hand, the second localization block is harder than the first because there is more going on spatially. $\ramify(\ref{findram2})$ expresses an update to a single node of our graph:

\begin{equation}
\label{findram2}
\inferrule
{x \in V(\gamma') \; \qquad \gamma'' = [x -> (r,rt)]\gamma'}
{\p{graph}(\gamma') \; |- \; x |-> \gamma'(x) * \big(x |-> \gamma''(x) --* \p{graph}(\gamma'')\big)}
\end{equation}

Here we abuse notation a little bit.  The conclusion of the ``rule'' (actually, lemma) is exactly right and appropriately generic, so spatial ramification lemmas of the kind given in \S\ref{sec:spacegraph} can handle the dirty spatial work for us.  However, the second premise uses a notation for ``mathematical graph node update'' that is customized for union-find graphs, since most graphs have more than a rank and single outgoing edge.  More seriously, as we will discuss in \S\ref{sec:mathgraph}, updating a mathematical graph cannot be done willy-nilly; it is only defined when the properties that restrict the mathematical structure of $\gamma$ are preserved. 
\marginpar{\tiny \color{blue}Too early}
{\color{magenta}These properties are carried around via dependent types;} in the case of union-find graphs, they force \emph{e.g.} acyclicity (other than at roots).

In the actual proof of \texttt{find}, the bulk of the example-specific effort (as opposed to generic lemmas we reuse in other examples) is indeed showing that this mathematical update can be done properly, \emph{i.e.} from 
\marginpar{\tiny \color{blue} Need to come to some decision re: the typesetting.}
\[
\texttt{x} \in V(\gamma) /| \gamma(\texttt{x}) = (r,\m{pa}) \quad \text{ and } \quad
\texttt{x} \neq \m{pa} /|
\m{findS}(\gamma,\m{pa},\gamma') /| \m{uf\_root}(\gamma',\m{pa},\m{rt})
\]
we can prove
\[
\exists \gamma''.~ \gamma'' = [x -> (r,rt)]\gamma' /| \m{uf\_root}(\gamma'',\texttt{x},\m{rt}) /| \m{findS}(\gamma,\texttt{x},\gamma'')
\]


This lemma captures the essence of both finding the root and doing path compression: after compressing your parent and finding its root, you can path compress yourself by rerouting your own parent pointer to your (soon-to-be former) parent's root.  The proof of the lemma is nontrivial, but is completely isolated from the grungy details of C.

With the second localization block complete, the remainder of the verification is straightforward.

\marginpar{\tiny \color{blue}I think this can be cut down to a footnote.}
\paragraph{Notes on notation.} 
{\color{magenta} Although we do not do so in Figure~\ref{fig:find}, localization blocks can safely nest.  When the ramification entailment is not noteworthy we can omit the $\ramify(i)$ reference in pen-and-paper proofs.  When we wish to save vertical space we can write $\{ G_1 \} \searrow \{ L_1 \}$ and $\{ G_2 \} \swarrow \{ L_2 \}$.

As pointed out in \S\ref{sec:intro}, \infrulestyle{Localize} can derive \infrulestyle{Frame}.  Our notation for localization blocks clarifies pen-and-paper uses of \infrulestyle{Frame}, especially in multi-line contexts with nontrivial $F$, for which the current popular notation to express \infrulestyle{Frame} involves a liberal use of 
ellipses, \emph{e.g.}:

\vspace{5pt}

\begin{minipage}{.25\textwidth}
Old notation:
\begin{lstlisting}
// $\{ P_1 * F_1 * F_2 * F_3 \}$
   $c_1$;
// $\{ P_2 * \ldots \}$
   $c_2$;
// $\{ P_3 * \ldots \}$
   $c_3$;
// $\{ P_4 * F_1 * F_2 * F_3 \}$
\end{lstlisting}
\end{minipage} \quad \vline \; ~~~
\begin{minipage}{.3\textwidth}
New notation:
\begin{lstlisting}[numbers=none]
// $\{ P_1 * F_1 * F_2 * F_3 \} \searrow \{ P_1 \}$
      $c_1$;
//    $\{ P_2 \}$
      $c_2$;
//    $\{ P_3 \}$
      $c_3$;
// $\{ P_4 * F_1 * F_2 * F_3 \} \swarrow \{ P_4 \}$
\end{lstlisting}
\end{minipage}
\vspace{-0.75ex}
}

\marginpar{\tiny \color{blue} These have been mentioned a few times, 
and this short discussion feels unsatisfying. Expand?}
\subsection{\color{magenta}Additional verified examples}
\label{sec:application}

Mark for graphs (cyclic), briefly discussed in~\S\ref{sec:existentials}.

In addition to \li{mark} for graphs, we have also verified the same program for DAGs.
More interestingly, we have verified two algorithms that modify the link structure:
\li{spanning} for graphs, which prunes a graph into its spanning tree, and \li{copy}
for graphs, which makes a structure-preserving copy.  For space reasons we put
\li{spanning} and \li{copy} in Appendix~A\hide{\ref{apx:spanning}}.


\hide{
(Assume until~\S\ref{sec:existentials} that $L_2$ and $G_2$ do not contain ``fancy'' existentials; in this case the explicit existentials in \textsc{Localize} can be ,
which effectively makes them trivial.)  What then remains is to choose a predicate $R$ and prove the two entailments in \textsc{Localize}.  If one ignores the side condition about modified local variables

Turning to the body of the verification (lines~\ref{code:inmark}--\ref{code:outmark}), readers may already have noticed our new notation: blocks of proof sketch bracketed

, such as lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}.  We call a bracketed set of lines like this a ``localization block''; localization blocks were inspired by our new \li{localize} $\searrow$ and \li{unlocalize} $\swarrow$ tactics in Floyd (\S\ref{sec:vst}).


In lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}, imagine unfolding the \p{graph} predicate in line~\ref{code:globalbeforerootmark} using equation \eqref{eqn:bigraphintrofoldunfold} and then zooming in to the root node \li{x} for lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}, before zooming back out in line~\ref{code:globalafterrootmark}.

To define localization blocks formally we need to first understand the \infrulestyle{Frame} and \infrulestyle{Ramify} rules.
}

\hide{



In lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}, imagine unfolding the \p{graph} predicate in line~\ref{code:globalbeforerootmark} using equation \eqref{eqn:bigraphintrofoldunfold} and then zooming in to the root node \li{x} for lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}, before zooming back out in line~\ref{code:globalafterrootmark}.

To define localization blocks formally we need to first understand the \infrulestyle{Frame} and \infrulestyle{Ramify} rules.

\subsection{Frames and ramifications are localizations}
%\label{sec:localizations}

The key rule of separation logic is \infrulestyle{Frame}~\cite{rey02}:
\[
\infrule{Frame}
{\{ P \} ~ c ~ \{Q \}}
{\{P * F \} ~ c ~ \{ Q * F \}}
{\begin{array}{c}F \textrm{ ignores } \MV(c) \end{array}} \qquad \qquad
\vspace{-0.75ex}
\]
The reason \infrulestyle{Frame} is so important is because it enables local verifications.  That is, a verifier can focus on the portions of the heap that are relevant to command $c$ and ``frame away'' the rest.  The side condition ``$F \textrm{ ignores } \MV(c)$'' relates to modified program variables and will be discussed in \S\ref{sec:freevars}.

Hobor and Villard observed that \infrulestyle{Frame} is bit rigid because it forces verifiers to split program assertions into syntactically $*$-separated parts~\cite{hobor:ramification}.  This rigidity is particularly troublesome when verifying programs that manipulate data structures with intrinsic unspecified sharing such as DAGs and graphs.  Hobor and Villard proposed the \infrulestyle{Ramify} rule to circumvent this rigidity:
\vspace{-1.5ex}
\[
\infrule{Ramify}
{\{L_1\} ~ c ~ \{L_2\} \\ G_1 |- L_1 * (L_2--* G_2)}
{\{G_1\} ~ c ~ \{G_2\}}
{\begin{array}{c}(L_2 --* G_2) \\ \textrm{ignores} \\ \MV(c) \end{array}} \qquad \qquad \qquad
%{$\begin{array}{l}\m{fv}(Q --* R') \cap \null \\ \m{modif}(c) = \emptyset\end{array}$} \qquad \qquad \qquad
\vspace{-1.5ex}
\]

}


\hide{


%\vspace*{-0.75ex}
\subsection{Marking a graph in VST}
\label{sec:vstgraphmark}
%\vspace*{-0.75ex}


In Figure~\ref{fig:markgraph} we put the code and proof sketch of the classic \li{mark} algorithm that visits and colors every reachable node in a heap-represented graph.  The \li{mark} algorithm is good to start with because it is complex enough to require some care to verify while being simple enough that the invariants are straightforward.  In \S\ref{sec:application} we will discuss more complex examples that \emph{e.g.} add/change/remove edges and/or vertices.

The code in Figure~\ref{fig:markgraph} is written in Clight~\cite{blazy:clight}, an input language to the CompCert certified compiler~\cite{leroy:compcert}, which compiles our code exactly as written.
The paper-format verification sketch for \li{mark} in Figure~\ref{fig:markgraph} is extracted from
a Floyd proof in VST, with only minor cleanup to aid the presentation.
Accordingly, there is an unbroken certified chain from our specification of \li{mark} all the way to the assembly code.  In \S\ref{sec:hipsleek} we use HIP/SLEEK~\cite{chin:hipsleek} to verify a Java version of \li{mark}; the program invariants generated by HIP/SLEEK are slightly different due to HIP/SLEEK's heavier automation.
% but the overall structure is the same.

The specification we certify (lines \ref{code:markstart} and \ref{code:markend}) is
\vspace*{-1ex}
\[
\{\p{graph}(\li{x},\gamma)\}~\li{mark(x)}~\{\exists \gamma'.~ \p{graph}(\li{x},\gamma') /| \m{mark}(\gamma, \li{x}, \gamma')\}
\vspace*{-1ex}
\]
The specification is for full functional correctness, stated using \emph{mathematical} graphs~$\gamma$; until \S\ref{sec:mathgraph} consider $\gamma$ to be a function that maps a vertex $v \in V$ to triples $(m,l,r)$, where $m$ is a ``mark'' bit (0 or 1) and $\{l,r\} \subseteq V \uplus \{0\}$ are the neighbors of $v$.
The \emph{spatial} \p{graph} predicate describes how the mathematical graph $\gamma$ is implemented in the heap.  Until~\S\ref{sec:spacegraph} it is enough to know that \p{graph} satisfies the fold/unfold relationship in
equation~\eqref{eqn:bigraphintrofoldunfold}, located just under the code in Figure~\ref{fig:markgraph}.

This fold/unfold relationship deserves attention.
First, as we explain in~\S\ref{sec:fixpointfail}, it is probably a mistake to write~\eqref{eqn:bigraphintrofoldunfold} as a definition using $\stackrel{\Delta}{=}$ rather than as a biimplication using $<=>$.  Second, \eqref{eqn:bigraphintrofoldunfold} uses the ``overlapping conjunction'' $\ocon$ of separation logic; informally $P ** Q$ means that $P$ and $Q$ may overlap in the heap (\emph{e.g.}, nodes in the left subgraph can also be in the right subgraph or even be the root $x$).  The presence of the unspecified sharing indicated by the $\ocon$ connective is exactly why graph-manipulating algorithms are so hard to verify (\emph{e.g.}, it is hard to apply the \infrulestyle{Frame} rule).  The standard semantics of the separation logic connectives used in this paper are in Figure~\ref{fig:seplogsem}.
Third, \eqref{eqn:bigraphintrofoldunfold} illustrates how industrial-strength settings complicate verification.  Lines~\mbox{\ref{code:nodedefstart}--\ref{code:nodedefend}} define the data type \li{Node} used by \li{mark}.  The \li{_Alignas($n$)} directives tell CompCert to align fields on $n$-byte boundaries.  As explained in~\S\ref{sec:goodgraph}, this alignment is necessary in C-like memory models to prove fold-unfold \eqref{eqn:bigraphintrofoldunfold}, which is why \eqref{eqn:bigraphintrofoldunfold} includes an alignment restriction $x~\mathsf{mod}~16 = 0$ and an existentially-quantified ``blank'' second field for the root $x \mapsto m,-,l,r$.
%{\color{magenta}(In our Floyd proofs the alignment restriction and blank second field are nicely hidden ``behind the scenes''.)}

Notice that the postcondition of \li{mark} is specified \emph{relationally}, \emph{i.e.} $\{\exists \gamma'.~ \p{graph}(\li{x},\gamma') /| \m{mark}(\gamma, \li{x}, \gamma')\}$ instead of \emph{functionally}, \emph{i.e.} $\{\p{graph}\big(\li{x},\m{mark}(\gamma, \li{x})\big)\}$. In the first case $\m{mark}$ is a relation that specifies that~$\gamma'$ is the result of correctly marking~$\gamma$ from~\li{x}, whereas in the second $\m{mark}$ is a function that \textbf{computes} the result of marking~$\gamma$ from~\li{x}. For both theoretical and practical reasons a relational approach is better.
Theoretically, relations are preferable because they are more general.  For example, relations allow ``inputs'' to have no ``outputs'' (\emph{i.e.} be partial) or alternatively have many outputs (\emph{i.e.} be nondeterministic).  Our graph \li{copy} algorithm is specified nondeterministically to avoid specifying how \li{malloc} allocates fresh blocks of memory.  Relations are also preferable to functions because they are more compositional.
We take advantage of compositionality by using $\m{mark}(\gamma,x,\gamma') /| \ldots$ to specify both our ``spanning tree'' and ``graph copy'' algorithms in~\S\ref{sec:application}, which also mark nodes while carrying out their primary tasks.

\begin{figure}
\[
\begin{array}{lcl}
\sigma |= P * Q & \defeq & \exists \sigma_1, \sigma_2.~ \sigma_1 \oplus \sigma_2 = \sigma /| \null \\ && ~~ (\sigma_1 |= P) /| (\sigma_2 |= 2)\\
[-2pt]
\sigma |= P ** Q & \defeq & \exists \sigma_1, \sigma_2, \sigma_3.~ \sigma_1 \oplus \sigma_2 \oplus \sigma_3 = \sigma /| \null \\ && ~~ (\sigma_1 \oplus \sigma_2 |= P) /| (\sigma_2 \oplus \sigma_3 |= Q) \\
[-2pt]
\sigma |= P --* Q & \defeq & \forall \sigma_1, \sigma_2.~ \sigma_1 \oplus \sigma = \sigma_2 /| \null \\ && ~~
(\sigma_1 |= P) => (\sigma_2 |= Q) \\
[-2pt]
\sigma |= P --o Q & \defeq & \exists \sigma_1, \sigma_2.~ \sigma_1 \oplus \sigma = \sigma_2 /| \null \\ && ~~
(\sigma_1 |= P) /| (\sigma_2 |= Q)
\end{array}
\]
\vspace*{-1.5em}
\caption{Separation logic connectives; $\oplus$ is the join operation on states, usually some kind of disjoint union on heaps}
\label{fig:seplogsem}
\vspace*{-1em}
\end{figure}

Practically, it is painful to define computational functions over graphs in a proof assistant like Coq, and portions of this pain are overkill.  For example, Coq requires that all functions terminate, a nontrivial proof obligation over cyclic structures like graphs, but our verification of \li{mark} is only for partial correctness.  Defining relations is much easier because \emph{e.g.} one can use quantifiers and does not have to prove termination.
The $\m{mark}$ and $\m{mark1}$ relations we use are defined straightforwardly at the bottom of Figure~\ref{fig:markgraph}.

Turning to the body of the verification (lines~\ref{code:inmark}--\ref{code:outmark}), readers may already have noticed our new notation: blocks of proof sketch bracketed by the symbols $\searrow$ and $\swarrow$, such as lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}.  We call a bracketed set of lines like this a ``localization block''; localization blocks were inspired by our new \li{localize} $\searrow$ and \li{unlocalize} $\swarrow$ tactics in Floyd (\S\ref{sec:vst}).
The intuitive idea is that we zoom in from a larger ``global'' context to a smaller ``local'' one.  After verifying some commands locally to arrive at a local postcondition, we zoom back out to the global context.  Although we do not do so in Figure~\ref{fig:markgraph}, localization blocks can safely nest.






}
