

To prove the functional correctness of graph-manipulating algorithms implemented in a real language, we need to 
% connect the heap representation of graphs, the memory model of the programming language, and the mathematical properties of abstract graphs from \S\ref{sec:mathgraph}. 
(1) connect the heap representation of graphs to the memory model of the 
programming language, and (2) connect the memory model to the mathematical 
properties of abstract graphs from \S\ref{sec:mathgraph}.
The first of these challenges turns out to be surprisingly subtle: 
the standard tactic of leveraging the \infrulestyle{Frame} rule 
works well for tree-manipulating programs, but fails for graph-manipulating programs.
We review the standard treatment for trees~(\S\ref{sec:seplogtrees}), 
point out the issue with graphs~(\S\ref{sec:fixpointfail}),
and propose a fix for this~(\S\ref{sec:goodgraph}).  
The main challenge thereafter is to engineer a framework that is generic 
and modular enough to be useful in a variety of 
settings~(\S\ref{sec:ramifylib}).

\input{seplogsem_figure.tex}

\subsection{Separation Logic in Tree-Manipulating Programs}
\label{sec:seplogtrees}

Figure~\ref{fig:seplogsem} shows the standard semantic models for the separation logic connectives using a join relation $\oplus$ on an underlying separation algebra~\cite{dockins09}. In recent works \citep{o2001local, o2012primer}
that employ separation logic to give
precise specifications of tree copy programs, the spatial
representation of a binary tree is defined as a recursive predicate
with an additional parameter: the mathematical tree $\tau$.
\begin{equation}\label{def:tree}
\begin{split}
    \mathsf{tree}(x, \tau)\;\defeq\;
    &\Big(x=0 \wedge \mathsf{isatom}(\tau) \wedge \mathsf{emp}\Big)
    \vee \null \\ &\Big(\exists\,l,r,\tau_1,\tau_2.\; \tau=\langle \tau_1,
    \tau_2 \rangle \wedge (x \mapsto l,r) \scon
    \mathsf{tree}(l, \tau_1) \scon \mathsf{tree}(r, \tau_2)\Big)
    \end{split}
\end{equation}

The mathematical tree $\tau$ encodes the
shape of a binary tree. It is either an $\mathsf{atom}$ or a pair of
tree encodings. For example,
$\langle \mathsf{atom}, \langle \langle \mathsf{atom}, \mathsf{atom} \rangle, \mathsf{atom} \rangle \rangle$
is a valid encoding. A $\mathsf{tree}(x, \tau)$ is either an
$\mathsf{emp}$ or $(x \mapsto
l,r) \scon \mathsf{tree}(l, \tau_1) \scon \mathsf{tree}(r, \tau_2)$
where $\tau_1$ and $\tau_2$ are the left and right subtrees of $\tau$.
If $\tau_1$ is $\mathsf{atom}$ then $l$ must be null pointer and
$\mathsf{tree}(l, \tau_1)$ must be~$\mathsf{emp}$.
Otherwise $\mathsf{tree}(l, \tau_1)$ can be expanded recursively as above.
The left part of Figure~\ref{fig:bin_tree_graph} shows a binary tree, 
and it should be straightforward to see that the data layout matches~$\tau$ 
(the shape of the tree) exactly. In the verification of a tree
copy program, the precondition is $\mathsf{tree}(x, \tau)$ and the
postcondition is
$\mathsf{tree}(x, \tau) \scon \mathsf{tree}(y, \tau)$. 
Having the same $\tau$ in the pre- and postconditions
of the specification indicates that the program creates an exact clone
of the original tree, not an arbitrarily-shaped tree.

This is an ideal use-case for the separation logic
because the root, the left subtree, 
and the right subtree are disjoint by construction. By applying
the \textsc{Frame} rule, one can safely reason about a particular 
$\scon$-separated branch of the tree and later compose the 
conclusion back into the rest of the tree
without worrying about the effect on the rest of the tree. 
In the figure we show that manipulating the subtree under 
root~$\m{v}$ does not affect the rest of the tree.

Graphs are more complicated.
Consider the right part of Figure~\ref{fig:bin_tree_graph},
which shows a bigraph. 
Defining a recursive predicate in the style of \eqref{def:tree},
\emph{i.e.} using the separating conjunction~$\scon$, is a bad idea: 
a node can be shared arbitrarily, and so finding a suitable 
\infrulestyle{frame} is difficult. 
In the figure we show that manipulating the subgraph reachable 
from~$\m{w}$ causes an unexpected node to be affected.

\begin{figure}[b]%htbp]
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \input{bitree_bigraph.tex}
  \captionof{figure}{A Binary Tree and a Binary Graph}
  \label{fig:bin_tree_graph}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
  \vspace*{0.5em}
  \input{single_cell.tex}
  \vspace*{1em}
  \captionof{figure}{A One-Cell Graph and its Heap Layout}
  \label{fig:single:cell}
\end{minipage}
\end{figure}

\subsection{Recursive Definitions Yield Poor \p{graph} Predicates}\label{sec:fixpointfail}

\newcommand{\graphkt}{\p{graph}_T}
\newcommand{\grapham}{\p{graph}_A}


Recursive predicates are ubiquitous in separation logic---so
much so that when one writes the definition of a predicate as
\mbox{$P$ ``$\defeq$'' $\ldots P \! \ldots$}, no one raises an eyebrow despite the
dangers of circularity in mathematics. Indeed, the vast majority of the time there
is no danger thanks to the magic of the Knaster-Tarski fixpoint
$\mu_{\mathsf{T}}$ \cite{tarski:fixpoint}.  Formally, one does not define $P$ directly,
but rather defines a functional
\mbox{$F_P \defeq \lambda P.~ \ldots P \! \ldots$} and then defines $P$ itself as
\mbox{$P \defeq \mu_{\mathsf{T}} \, F_P$}.
Assuming, as one typically does without comment,
that $F_P$ is \emph{covariant}, i.e. $(P |- Q)
\Rightarrow (F \, P |- F \, Q)$, one then enjoys the fixpoint
equation $P \Leftrightarrow \ldots P \ldots$, formally justifying
the typically-written pseudodefinition (``$\defeq$'').

%Definition corec {B A: Type}  (F: (B -> pred A) -> (B -> pred A)) : B -> pred A :=
%fun x w => forall P: B -> pred A, (forall x, F P x |-- P x) -> P x w.

Suppose we define a graph predicate $\graphkt$ along the lines of the fold/unfold definition in Figure~\ref{fig:markgraph}.  Such a definition would use the overlapping conjunction $P ** Q$ (\emph{c.f.} Figure~\ref{fig:seplogsem}) as follows: %, \emph{i.e.}
\vspace{-1ex}
\[
\begin{array}{@{}l@{}l@{}}
\graphkt(x, \gamma) \; \defeq \; &\Big(x = 0 /| \p{emp}\Big) |/ \\
&\quad \Big(\exists m,l,r.~ \gamma(x)=(m,l,r) /|
\big(x |-> m,l,r ** \graphkt(l, \gamma) ** \graphkt(r, \gamma)\big)\Big)
\end{array}
\vspace{-1ex}
\]
%We have removed the alignment-related portions of equation~\eqref{eqn:bigraphintrofoldunfold} to focus on a more serious issue, even though as we will explain in~\S\ref{sec:goodgraph} alignment concerns are also necessary for the fold/unfold relationship to hold in C-like memory models.
Although we can apply Knaster-Tarski (because the functional needed to
define $\graphkt$ is covariant), the result is hard to use.
Consider the memory $m$ for a toy machine, where $m |= 100 |-> 42,100,0$.
It seems clear, however, that this
memory also represents a one-cell cyclic graph as illustrated in
Figure~\ref{fig:single:cell}, \emph{i.e.} we want
$m |= \graphkt(100,\hat{\gamma})$, where 
$\hat{\gamma}(100) = (42,100,0)$.  This is equivalent to wanting to be able to 
prove $100~|->~42,100,0~|-~\graphkt(100,\hat{\gamma})$.  Unfortunately, as 
illustrated in Figure~\ref{fig:badcycle}, this is rather difficult to do since 
applying the natural proof techniques actually strengthens the goal.
Part of the 
problem is that the recursive structure interacts very badly with $**$: if the 
recursion involved~$*$~then it \textbf{would} be provable, by induction on the 
finite memory (each ``recursive call'' would be on a strictly smaller subheap).  
This is why Knaster-Tarski works so well with list, tree, and DAG predicates in 
separation logic.  We do not know if this entailment is provable, but the 
difficulties encountered in proving what ``should be'' straightforward suggest 
that Knaster-Tarski should be treated with caution when defining spatial 
predicates for graphs.

\begin{figure}[t]%hbp]
\[
\infrule{}
{\infrule{}
  {100 |-> 42,100,0 ~ |- ~ 100 |-> 42,100,0 ** \graphkt(100,\hat{\gamma})}
  {100 |-> 42,100,0 ~ |- ~ \hat{\gamma}(100) = (42,100,0) ~ /| ~ 100 |-> 42,100,0 ** \graphkt(100,\hat{\gamma}) ** \graphkt(0,\hat{\gamma})}
  {\ddagger}
}
{100 |-> 42,100,0 ~ |- ~ \graphkt(100,\hat{\gamma})}
{\dagger}
\]
\begin{tabular}{@{}l@{$~~$}l|l@{$~~$}l}
$\dagger$ & Unfold $\graphkt$, dismiss first disjunct (contradiction), $~~$ & $~~$ $\ddagger$ &simplify using $P * \p{emp} -|- P$ \\
& introduce existentials (which must be 42,100,0) & & and remove pure conjunct
\end{tabular}
\caption{An attempt to prove a ``simple'' entailment}
\label{fig:badcycle}
\end{figure}


The other direction, \mbox{$\graphkt(100,\hat{\gamma}) |- 100 |-> 42,100,0$},
\textbf{is} true but is not easy to prove, relying on the constructions in \S\ref{sec:goodgraph} and the fact that $\mu_{\mathsf{T}}$ constructs the least fixpoint.  In contrast, $\graphkt(100,\hat{\gamma}) |- 100 |-> 42,100,0 * \top$ is easy. % to prove. % via fold/unfold.

\hide{
\cite{appel:fixpoint} defined an alternative fixpoint using a notation of \emph{contractiveness}.  Unfortunately, this alternative fixpoint also
fails to define a sensible graph predicate; see Appendix~\ref{apx:appelfixpiont}.

\subsection{Problem with Appel and McAllester's fixpoint}
\label{apx:appelfixpiont} }

Appel and McAllester proposed another fixpoint $\mu_{\mathsf{A}}$
that is sometimes used to define recursive predicates in separation
logic \cite{appel:fixpoint}.  This time the functional $F_P$ needs to be
\emph{contractive}, which to a first order of approximation means that
all recursion needs to be guarded by~$\rhd$~, the ``approximation
modality'' \cite{appel:vmm}, \emph{i.e.} our graph predicate would
look like
\begin{align*}
\grapham(x, \gamma) ~ \defeq ~~ &(x = 0 /| \p{emp}) |/ \exists m,l,r.~ \gamma(x)=(m,l,r) /| \null \\
 & x |-> m,l,r ** \rhd \grapham(l, \gamma) ** \rhd \grapham(r, \gamma)
\end{align*}
This functional is contractive, and so the fixpoint is well-defined.  
Nevertheless, this definition has a subtle flaw: the resulting graph
predicate is \textbf{not} ``precise'' in the separation logic sense:
\[
%\begin{array}{@{}l@{}l@{}}
\m{precise}(P) ~~ \defeq ~~ (\sigma_1 |= P) ~ => ~ (\sigma_2 |= P) ~ => ~ (\sigma_1 \oplus \sigma_1' \! = \! \sigma) ~ => ~ (\sigma_2 \oplus \sigma_2' \! = \! \sigma) ~ => ~ \sigma_1 \! = \! \sigma_2
%\end{array}
\]
The flaw stems from the fact that $\rhd P$ is not precise for any $P$ 
(at time zero, $\rhd P$ is just $\top$), 
so $\grapham$ is not precise either.  The approximation modality's 
universal imprecision has never been noticed before in the literature.
Accordingly, $\grapham$ is also rather difficult to use.
%Some proof strategies require 

\hide{
\section{Difficulty using $\graphkt$}
\label{apx:problemrecgraph}


See Figure \ref{fig:badcycle} for an attempt to prove the entailment $100 |-> 42,100,0 ~ |- ~ \graphkt(100,\hat{\gamma})$.  Part of the problem is that the recursive structure interacts very badly with $**$: if the recursion involved~$*$~then it \textbf{would} be provable, by induction on the finite memory (each ``recursive call'' would be on a strictly smaller subheap).  This is why Knaster-Tarski works so well with list, tree, and DAG predicates in separation logic.
}

%As explained in~\S\ref{sec:foldunfold}, this alignment is necessary in C-like memory models to prove fold-unfold \eqref{eqn:bigraphintrofoldunfold}, which is why \eqref{eqn:bigraphintrofoldunfold} includes an alignment restriction $x~\mathsf{mod}~16 = 0$ and an existentially-quantified ``blank'' second field for the root $x \mapsto m,-,l,r$.

%As shown in (\ref{eqn:bigraphintrofoldunfold}) of Section
%\ref{sec:orientation}, Hobor and Villard\cite{hobor:ramification}
%defined the separation logic graph predicate
%$\mathsf{graph}(x,\gamma)$ in direct analogy to the standard
%separation logic definition of a tree. Note that the two-neighborhood
%means $\gamma$ is a BiGraph. However, it is peculiarly challenging in
%rigorously formalizing $\p{graph}$.

%* Showing that neither traditional fixpoint method works

%Appel and McAllester proposed another fixpoint $\mu_{\mathsf{A}}$
%that is sometimes used to define recursive predicates in separation
%logic \cite{appel:fixpoint}.  This time the functional $F_P$ needs to be
%\emph{contractive}, which to a first order of approximation means that
%all recursion needs to be guarded by the ``approximation
%modality''~$\rhd$~\cite{appel:vmm}, \emph{i.e.} our graph predicate would
%look like
%\begin{align*}
%\grapham(x, \gamma) ~ &\stackrel{\Delta}{=}\\
% (x = 0 /| \p{emp}) & |/ \exists m,l,r.~ \gamma(x)=(m,l,r) /| \null \\
% x |-> m,l,r & ** \rhd \grapham(l, \gamma) ** \rhd \grapham(r, \gamma)
%\end{align*}
%
%Unfortunately, $\rhd P$ is not precise for all $P$, so $\grapham$ is not precise either.  The approximation modality's universal imprecision has never been noticed before. % in the literature.  %We must do better.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Edit0: cut down contractive recursion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Defining a Good \p{graph} Predicate}\label{sec:goodgraph}

Rather than defining \p{graph} as a recursive fixpoint,
we give it a flat structure.  Graphs in separation
logic have been defined in similar ways before, \emph{e.g.}~\citet{ilya-graphs}
and \citet{charpott19};
our innovation is that we prove---with the amount of precision
required to convince Coq---that we still enjoy fold/unfold
with our flat definition.  We start with the iterated
separating conjunction or ``big star'', which is first defined over
lists and then extended to sets as follows:

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Edit1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Edit1: Qinxiang's proposal starts
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-1em}
\[
\begin{array}{@{}l@{}}
\!\!\!\!\!\!\!\underset{\{l_1,\dots,l_n\}}{\bigstar P}\!\!\!\!\!\!\! ~~ \defeq ~~ P(l_1) *
  P(l_2) * \dots * P(l_n) \quad \vline \quad
\underset{S}{\bigstar} P ~~ \defeq ~~ \exists L.~ (\p{NoDup}\ L) /| (\forall x.~ x\ \p{in}\ L <=> x \in S) /| \underset{L}{\bigstar}P
\end{array}
\]

We are now ready to define a good \p{graph} predicate:
  \quad $\p{graph}(x, \gamma) \; \defeq \; \!\!\!\!\!\!\!\!\!\!\underset{\m{v} \in \mathit{reachable}(\gamma, x)}{\bigstar}\!\!\!\!\!\!\m{v}\mapsto\gamma(\m{v})$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Edit1: Qinxiang's proposal ends
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Edit1: Original version starts
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\iffalse
\begin{equation*}
  \underset{\{l_1, l_2,\dots,l_n\}}{\bigstar}P ~~ \defeq ~~ P(l_1) *
  P(l_2) * \dots * P(l_n).
\end{equation*}
Formally $\bigstar$ is defined over a list rather than a set and is parameterized by a predicate $P$.  It is natural to extend $\bigstar$ to a set $S$ with an existentially-quantified duplicate-free list~$L$:
\[
\underset{S}{\bigstar} P ~~ \defeq ~~ \exists L.~ (\p{NoDup}\ L) /| (\forall x.~ x\ \p{in}\ L <=> x \in S) /| \underset{L}{\bigstar}P
\]
We use the same $\bigstar$ notation since the concepts are similar, but the existential adds a little pain since we need to prove that all choices of $L$ yield equivalent predicates.

We are now ready to give a good \p{graph} predicate:
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Edit1: Original version ends
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hide{ \vspace{-1.5ex}
\begin{equation}\label{eqn:iter_def}
  \p{graph}(x, \gamma) ~~ \defeq ~~ \underset{v \in \mathit{reach}(\gamma, x)}{\bigstar} v\mapsto\gamma(v)
\vspace{-1.5ex}
\end{equation}
$\gamma$ is a GeneralGraph and ``$x |-> \gamma(x)$'' is a predicate that says how a single node fits in memory. In Figure~\ref{fig:markgraph} it was:
\[
\exists m,l,r.~\gamma(x) = (m,l,r) /| x |-> m,-,l,r /| x\ \p{mod}\ 16 = 0
\]}
The graph $\gamma$ here need not be a bigraph, but \emph{e.g.} can have many edges.

Our definition of \p{graph} is flat in the sense that there is no obvious way to follow the link structure recursively.  Happily, we can recover a general recursive fold/unfold (if $x |-> \gamma(x)$ and the GeneralGraph has the necessary properties in its soundness condition):
\vspace{-1ex}
\begin{equation}
\label{eqn:unfold_graph}
\hspace{-1em}\begin{array}{@{}lc@{\hspace{1pt}}c@{\hspace{1pt}}l@{}}
\p{graph}(x,\gamma)  <=>  x |-> \gamma(x) ** \big(\!\!\!\!\!\!\!\!\!\!\!\!\!\underset{n \in \p{neighbors}(\gamma,x)}{\bigocon}\!\!\!\!\!\!\!\!\!\!\!\! \p{graph}(\gamma,n) \big)
\quad \text{~~~ where ~~ }\underset{l_1,\dots,l_n}{\raisebox{-0.3ex}{\resizebox{0.75em}{!}{\hspace{0.05em}$\scon$}}\hspace{-2.18ex} \bigcup} \! \! P  \defeq  P(l_1) ** \ldots ** P(l_n) \end{array}
\vspace{-1ex}
\end{equation}

The proof of the $<=$ direction requires care. The difficulty is that if two nodes $x |-> \gamma(x)$ and $x' |-> \gamma(x')$ are \emph{skewed}, \emph{i.e.} ``partially overlapping'' with some---but not all---of $x$'s memory cells shared with $x'$, then the $\bigstar$ on the left hand side cannot separate them.  To avoid skewing we require that $x |-> \gamma(x)$ be \emph{alignable}. A predicate $P$ is alignable when
\[
\forall x,y.~ \Big(P(x) ** P(y) |- \big(P(x) /| x = y\big) |/ \big(P(x) * P(y)\big)\Big)
\]
That is, they overlap either completely or not at all. In a Java-like memory model this property is automatic because pointers in such a model always point to the root/beginning of an object.  In contrast, in a C-like memory model such as in VST/CompCert, this property is not automatic because pointers can point anywhere.  In such a model, alignment is most easily enforced by storing graph nodes at addresses that are multiples of an appropriate size (\emph{e.g} this size is $16$ in Figure~\ref{fig:markgraph}).

Some of our VST proofs, \emph{e.g.} for \li{find}, do not use fold/unfold, instead preferring to use the lemmas in~\S\ref{sec:ramifylib} directly.  Others, \emph{e.g.} \li{mark}, do, and it is helpful to have both options avilable. We also prove fold/unfold lemma for DAGs in which we get a clean $*$ between the root and its $**$-joined neighbors, rather than the $**$ present in \eqref{eqn:unfold_graph}.
% (On the other hand, for HIP/SLEEK fold/unfold is vital, and it is heartening to know that the recursive relationship holds.  We also prove fold/unfold lemma for DAGs in which we get a $*$ between the root and its $**$-joined neighbors. % rather than the $**$ present in \eqref{eqn:unfold_graph}.


\subsection{Ramification Libraries}\label{sec:ramifylib}

\input{libinfra_figure.tex}


Many tools (\emph{e.g.}\ Charge! \citep{bengtson:charge},
Smallfoot \citep{berdine:smallfoot}, jStar \citep{distefanop08},
HIP/SLEEK \citep{chin:hipsleek}) use the Direct Model to represent
spatial predicates on the heap, but VST employs an unusually complex
Step-Indexed heap model in order to support an unusually rich program
logic~\cite{appel:programlogics}.  Figure~\ref{fig:infra} shows the
architecture of our spatial development.  We will explain our two
interfaces momentarily, but for now observe that both heap models can
instantiate both interfaces. That is to say, we do not rely on any of the
bells, whistles, or specialized properties that are only available 
in the Step-Indexed Model.

We modularize our spatial library over 
two interfaces: Core Logic and Supplementary Logic.
Each interface defines some operators of separation logic 
along with relevant axioms to show how they work.  
For example, the definitions of $*$ and
$--*$ are in Core Logic, along with key axioms and rules such as
$(P |- Q --* R) <=> (P * Q |- R)$.  
On the other hand, lesser-used operators such as 
$**$ and $--o$ are in Supplementary Logic,
along with rules such as $P |- P ** P$. 
Generally speaking, our VST proofs only need Core properties 
(shaded in the figure) to prove our examples.

\hide{Starting from the bottom, notice that there are two underlying heap models,
VST's Step-Indexed model and the much simpler Direct Model.

To isolate our development from these unnecessary complications,
{\color{magenta}and to ensure that HIP/SLEEK can reuse our spatial
reasoning, we use two interfaces: Core Logic and Supplementary
Logic.  Both models can instantiate both interfaces, but generally
speaking our VST proofs only need the Core properties to prove
our examples, whereas HIP/SLEEK uses both Core and Supplemental.}
Each interface defines some operators of separation logic and
provides some axioms about how they work.  For example, $*$ and
$--*$ are in Core Logic, along with the axiom
$(P |- Q --* R) <=> (P * Q |- R)$.  On the other hand,
the $**$ and $--o$ operators are in Supplementary Logic,
along with rules like $P |- P ** P$.} % end hide

Above the Logic layer we have three towers, each three levels high.  The tower on the left contains basic lemmas about Logic, $\bigstar$, and \p{graph}.  For instance, in the $\bigstar$ Facts box we prove:
\begin{equation*}
\infrule{}
{A \cap B = \emptyset}
{\underset{x\in A}{\bigstar} P(x) \; * \underset{x\in B}{\bigstar} P(x) \;\, \Leftrightarrow \underset{x\in A \cup B}{\bigstar} P(x)}{}
\end{equation*}
The middle tower is more interesting in that it is entirely focused on ramification entailments.  A robust library of ramification entailments is essential to make ramification work smoothly in practice.  The Basic Ramification box in the lower layer contains lemmas like the one below, which we use to break large ramification entailments into compositionally manageable pieces. % in a compositional way. 
\begin{equation*}
%\infrule{Ramify-Q-SPLIT}
\infrule{}
{G_1 |- L_1 * \forall x.~ (L_2 --* G_2) \\
 G'_1 |- L'_1 * \forall x.~ (L_2' --* G'_2)}
{G_1 * G'_1 |- (L_1 * L'_1) * \forall x.~ \big((L_2 * L'_2)--* (G_2 * G'_2)\big)}{}
\end{equation*}
The $\bigstar$ Ramification box in the middle layer contains lemmas like the one below:
\begin{equation*}
\infrule{}
{A \cap B = \emptyset  \qquad  A' \cap B = \emptyset}
{\underset{x\in A\cup B}{\bigstar} P(x) |- \! \underset{x\in A}{\bigstar} \! P(x) * \Big( \underset{x\in A'}{\bigstar} \! P(x) \! \wand \! \! \! \! \underset{x\in A' \cup B}{\bigstar} \! \! P(x)\Big)}{}
\end{equation*}
The above lemma expresses large-scale replacement, clearing the way to 
cleanly establish a key graph-specific fact:
Lemma~\ref{ramify:bigstar}, which is 
placed in the Graph Ramification box (top layer), is used on 
lines~\ref{code:markram3} and~\ref{code:markram4} of 
Figure~\ref{fig:markgraph} to reason about smoothly replacing subgraphs. 
\begin{equation}
\label{ramify:bigstar}
%{\gamma(x_0) = \gamma'(x_0) \text{ for any } x_0 \neq x }
\frac
{n \in \p{neighbors}(\gamma,x)}
{
\p{graph}(x, \gamma) |- \p{graph}(n, \gamma) \! * \!
\forall \gamma'. \m{mark}(\gamma, n, \gamma') -> \big(\p{graph}(n, \gamma') \! --* \! \p{graph}(x, \gamma')\big)
}
\end{equation}
Similarily, the same box contains the key lemma used on line~\ref{code:markram2} in Figure~\ref{fig:markgraph} to update one node:
\begin{equation}
\label{lem:updategraphnode}
%{\gamma(x_0) = \gamma'(x_0) \text{ for any } x_0 \neq x }
\frac
{\forall x_0 \neq x.~ \gamma(x_0) = \gamma'(x_0) \\ \p{neighbors}(\gamma,x)=\p{neighbors}(\gamma',x)}
{\p{graph}(x, \gamma) \! |- \! x \! \mapsto \! \gamma(x) \! * \! \big(x \! \mapsto \! \gamma'(x) \! \wand \! \p{graph}(x, \gamma')\big)}
\end{equation}
This layered structure enables proof reuse. All of the theorems for $\p{graph}$ are proved from the properties of iterated separating conjunction, but having a modular library allows $\bigstar$ to be reused in other structures smoothly.
Further, all our verifications of different graph algorithms use the proof rules of $\p{graph}$ at the top level in the library. 

% Hiding because this very equation is the subgraph-replacing equation up above.
\hide{Taking the marking algorithm we introduced in \S\ref{sec:orientation} as an example, we prove the following theorem from the library:
{\color{red}
\begin{equation*}
\label{lem:updatesubgraph}
\frac
{n \in \p{neighbors}(\gamma,x)}
{
\p{graph}(x, \gamma) |- \p{graph}(n, \gamma) \! * \!
\forall \gamma'. \m{mark}(\gamma, n, \gamma') -> \big(\p{graph}(n, \gamma') \! --* \! \p{graph}(x, \gamma')\big)
}
\end{equation*}
}
}% end hide

The Supplementary tower contains properties not used by most of the VST examples.
This includes the fold/unfold relationship that we moved away from 
in~\S\ref{sec:goodgraph}, facts
about precision, \emph{etc}. These are currently included mostly for completeness,
but do make our library more general should we wish to accommodate an alternate
prover that needs separation logic facts about $**$,  $--o$, \emph{etc.}


% are there just because we felt they might be useful in the future.

%One benefit of the definition in (\ref{eqn:iter_def}) is that the pure
%mathematical graph $\gamma$ in $\mathtt{graph}$ is not necessarily a
%BiGraph. (\ref{eqn:iter_def}) can represent a general graph with
%variant number of neighors as long as extending the definition of
%$\gamma(x)$ to data mapped by the label function and every neighbor of
%node $x$.
%
%Moreover, it turns out that the $\bigstar$ notation is a more useful
%and fundamental concept than $\mathtt{graph}$. There are two parts of
%the $\bigstar$ in (\ref{eqn:iter_def}): one is the predicate $\mapsto$
%and the other is the node set which the $\mapsto$ iterates on. They
%both bind to $\gamma$ in (\ref{eqn:iter_def}) for $\p{graph}(x,
%\gamma)$, which is a special case. In section \ref{sec:applicable}, we
%will see the specification of a spanning tree algorithm which uses
%$\bigstar$ directly instead of $\p{graph}$ because in that
%specification, the predicate $\mapsto$ and the node set bind to
%different mathematical graphs. Furthermore, we generalize the
%ramification rules for $\p{graph}$ in \cite{hobor:ramification}, which
%uses $\bigstar$ so as to be applied in all verification examples.

%% 1.2. \li{Iter\_sepcon} and \li{pred\_sepcon} are defined. And related ramification rules are proved.
%% 1.3. The most general graph-spatial-predicate \li{vertices\_at} are defined (for all possible styles of graphs). Related ramification rules are proved. Graph and graphs are defined as special cases of vertices at.

%% 2. A minor implementation trick. There are many tactics defined in \li{msl\_ext/ramify\_tactics.v}, which can manipulate low level heaps efficiently.

%% * Separating the material into the general vs. tool-specific part.  Measurements of etc.
