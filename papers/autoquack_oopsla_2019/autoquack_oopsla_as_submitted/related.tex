\paragraph{Comparison with~\cite{hobor:ramification}.}
Our work builds on the theory of ramification by Hobor and Villiard,
who verified graph algorithms on pen-and-paper using their \infrulestyle{Ramify} rule:
\begin{equation*}
%\label{eq:ramify}
\inferrule[Ramify]
{\{ L_1 \} ~ c ~ \{ L_2 \} \\
G_1 |- L_1 * (L_2 --* G_2)}
{\{ G_1 \} ~ c ~ \{ G_2 \}} \qquad \mathit{freevars}(L_2 --* G_2) \cap \MV(c) = \emptyset
\end{equation*}
Our \textsc{Localize} rule upgrades \textsc{Ramify} to better handle modified program
variables (note the side condition and recall the discussion in \S\ref{sec:localizations})
and existential quantifiers in postconditions.  Hobor and Villard avoided these challenges
by proposing a unwieldy variant of \infrulestyle{Ramify} called \infrulestyle{RamifyAssign}, which
could reason about the special case of a single assignment $\li{x=}f(\ldots)$, assuming
the verifier can make the local program translation to $\li{x'=}f(\ldots)\li{; x=x'}$,
where \li{x'} is fresh.  This is nontrivial in large existing formal
developments, such as VST, that do not have any way to prove programs equivalent.
Hobor and Villard could not verify unmodified program code, modify program variables
inside nested localization blocks, or handle multiple assignments in a single block as
in lines~\ref{code:markbeforetripleramify}--\ref{code:markaftertripleramify} of
figure~\ref{fig:markgraph}.  Hobor and Villard avoided existentials in localized
postconditions by defining all mathematical operations (\emph{e.g.} $\m{mark}$) as
functions rather than as relations; this is fine for pen-and-paper, but painful in
a mechanized setting wherein functions must be proven to terminate.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Edit 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Edit 1: Qinxiang's proposal starts
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\iffalse
Our development is entirely machine-checked~(\S\ref{sec:development}) which revealed some
tricky technique details. Hobor and Villard fell into the trap of defining spatial graphs
recursively~(\S\ref{sec:fixpointfail}); unfortunately other members of the research
community have since followed them in.  We exposed this error and provided a sound,
general, and highly modular graph framework that works smoothly in a mechanized
context~(\S\ref{sec:mathgraph},\S\ref{sec:spacegraph}).
% and quite general
%definition for \p{graph}~(\S\ref{sec:goodgraph}) that recovers fold/unfold reasoning.
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Edit 1: Qinxiang's proposal ends
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Edit 1: Original version starts
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\iftrue
Hobor and Villard treated mathematical graphs as triples $(V,E,L)$ of
vertices, edges, and a vertex labeling function; vertices had no more than two
neighbors.  Our mathematical graph framework~(\S\ref{sec:mathgraph}) is very
modular and general and has been tuned to work smoothly in a mechanized context.

Hobor and Villard erroneously defined spatial graphs
recursively~(\S\ref{sec:fixpointfail}); unfortunately other members of the research
community have since followed them in, \emph{e.g.}~\cite{raadvg15}.  We exposed this
error and provided a sound and quite general definition for
\p{graph}~(\S\ref{sec:goodgraph}) that recovers fold/unfold reasoning.  We developed a
much more general and more modular set of related lemmas and connect our spatial
reasoning to the verification framework of CompCert/VST~(\S\ref{sec:vst}), and
our development is entirely
machine-checked~(\S\ref{sec:development}) whereas they used only pen and paper.

%two very different verification tools~(\S\ref{sec:ramifylib}),
% and HIP/SLEEK~(\S\ref{dummyref}).
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Edit 1: Original version ends
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Other verification of graph algorithms and/or $**$.}
\cite{hongseok:phd}'s verification of the Schorr-Waite algorithm is a landmark in the
early separation logic literature.  \cite{neelthesis}~provided the first separation
logic proof of union-find.  \cite{bornat:aliasing04}~gave an early attempt to
reason about graph algorithms in separation logic in a more general
way.

\cite{rey-slnotes}~was the first to document the overlapping conjunction~$**$, albeit without
any strategy to reason about it using Hoare rules.
\cite{gardnerms12}~were the first to reason about a program using $**$ in
Javascript.  \cite{raadvg15}~used $**$ to reason about a
concurrent spanning algorithm using a kind of
``concurrent localization''.  \cite{ilya-graphs} also verified a
concurrent spanning tree algorithm, and moreover developed mechanized Coq proofs.

A decade after Yang verified Schorr-Waite on paper, \cite{leino10}~automated
its verification.

%\paragraph{Alternative fixpoint constructions.}
%Appel and McAllester defined an alternative ``contractive'' fixpoint that is sometimes used to define recursive predicates in separation
%logic~\cite{appel:fixpoint}.  In Appendix~\ref{apx:appelfixpiont} we explain why Appel and McAllester's  is also unsuitable to define graphs.

\vspace{-1ex}
\paragraph{Verification tools.}
Our work interacts with the Floyd~\cite{appel:programlogics} verification
tool.  Charge! likewise uses Coq tactics to work with a shallow embedding of higher
order separation logic, but focuses on OO programs written in
Java/C\#~\cite{bengtson:charge}.  Iris Proof Mode provides a similar framework for higher-order
concurrent reasoning~\cite{krebbers:iris}.  A  more automated approach to verification of low
level programs using Coq is the Bedrock framework \cite{chlipala:bedrock}.

Many automated verification tools also use separation logic in a forward reasoning style
as does HIP/SLEEK, including Smallfoot~\cite{berdine:smallfoot},
jStar~\cite{distefanop08}, and Verifast~\cite{jacobs:verifast}.  One of HIP/SLEEK's
distinguishing features is good support for user-defined inductive predicates rather
than a library of pre-defined predicates for lists, trees etc.

Dafny~\cite{leino10} and KeY~\cite{beckert:2007} are verifiers not based
on separation logic; KeY uses an interactive verifier while Dafny pursues automation with Z3~\cite{moura2008}.

%\cite{nipkow2017}~verified functional variants of several classic tree and queue structures in Isabelle/HOL.

\vspace{-1ex}
\paragraph{Mechanized mathematical graph theory.} There is a long history,
going back at least 25 years, of mechanized reasoning about mathematical
graphs~\cite{wong1991}.  The most famous mechanically verified ``graph theorem''
is the Four Color Theorem~\cite{gonthier2005computer}; however
the development actually uses hypermaps instead of graphs.
Noschinski built a graph library in Isabelle/HOL whose formalization
is the closest to ours~\cite{noschinski2015}, \emph{e.g.} supporting
graphs with labeled and parallel arcs.
\cite{noschinski2015formalizing,dubois2015graphes}~used proof assistants to design verifiable
checkers for solutions to graph problems.
\cite{yamamoto1995formalization,bauer20025}~use an inductive
encoding of graphs to formalize planar graph theory.

\cite{gueneauetal}~formalised ``time credits'' in Separation Logic and big-$O$ notation in
Coq and then verified both the correctness
and the time complexity of the union-find data structure.
%Others, \emph{e.g.}~\cite{others2, others4, others3, others1}
%have also formally proved bounds on the resources
%used by programs. %formally in proof assistants such as Coq, Isabelle/HOL, and Why3.

\paragraph{Verification of garbage collection algorithms.}
Schism \cite{gcexample4,gcexample4a} is a certified concurrent
collector built in a Java VM that services multi-core architectures with weak memory consistency.
McCreight \emph{et al.} \cite{gcexample5, gcexample3} introduce GCminor, which is
a certified translation step added to CompCert's translation from Clight to assembly.
GCminor makes explicit the specific invariants that the garbage collector
relies upon, thus minimising errors due to the violation of invariants
between the garbage collector and the mutator.
Hawblitzel and Petrank \cite{gcexample2} annotate x86 code
for two GCs by hand, and then use Boogie and the Z3 automated theorem prover
to verify their correctness automatically.

The closest piece of work to our certified GC is probably the excellent certified GC
for the Cake ML project~\cite{cakemlgc}, since both integrate a certified GC into 
a certified compiler for a functional language.  Their GC is written closer to assembly 
than C, which is both a positive---in that they avoid undefined behaviors---and a negative, 
in that their GC is harder to understand and upgrade and cannot take advantage of the
mature CompCert compiler.  Their GC lacks some of our optimisations (\emph{e.g.} they have 
only three generations), but on the other hand handles mutation in the GC heap.  The largest 
difference, however, is that we present an integrated graph framework suitable for reasoning 
about many graph algorithms, of which our GC is merely the flagship.  In contrast, they focus 
much more narrowly on the problem of certified GCs.

%\note{has to be written with great care. They are very serious competition.}


%{\color{magenta}
%5.2. An alternative way of verifying marking program is reasoning about the whole history of marking operations. The disadvantage of it is that it currently needs more work in a Hoare logic framework. The advantage of it is that its reasoning structure are more similar with the way we understand it in our first algorithm class.
%5.3. I take some effort on garbage collector like graph structural. Though it is only connecting this special structural with 5.1.1 and 1.3, it takes much time and it is not finished yet.}


