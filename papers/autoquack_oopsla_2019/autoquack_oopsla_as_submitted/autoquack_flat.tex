\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}



\acmConference[PL'18]{ACM SIGPLAN Conference on Programming Languages}{January 01--03, 2018}{New York, NY, USA}
\acmYear{2018}
\acmISBN{} \acmDOI{} \startPage{1}

\setcopyright{none}


\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}  






\usepackage{listings}          \usepackage{stmaryrd}          \usepackage{mathtools}         \usepackage{semantic}          \usepackage{mathpartir}        \usepackage{tikz}              \usepackage{courier}           \usepackage{multicol}          \usepackage{subcaption}        \usepackage[export]{adjustbox} \usepackage{accents}
\usepackage{wrapfig}

\makeatletter
\newlength{\@mli}
\newcommand{\mli}[1]{\settowidth{\@mli}{\lstinline/#1/}
  \hspace{-.5ex}\begin{minipage}[t]{\@mli}\lstinline/#1/\end{minipage}}
\newcommand{\ostar}{\mathbin{\mathpalette\make@circled\ast}}
\newcommand{\make@circled}[2]{\ooalign{$\m@th#1\smallbigcirc{#1}$\cr\hidewidth$\m@th#1#2$\hidewidth\cr}}
\newcommand{\smallbigcirc}[1]{\vcenter{\hbox{\scalebox{0.66667}{$\m@th#1\bigcirc$}}}}
\makeatother

\newcommand{\note}[2][polish]{{\color{magenta} #2 }{\marginpar{\tiny \color{blue} #1 }}}
\newcommand{\noted}[2][new]{{\color{orange} #2 }{\marginpar{\tiny \color{blue} #1 }}}
\newcommand{\notedd}[2][blah]{#2}
\newcommand{\li}[1]{\ifmmode\mbox{\mli{#1}}\else\mbox{\lstinline/#1/}\fi}
\newcommand\hide[1]{}
\newcommand{\MV}{\ensuremath{\mathsf{ModVar}}}
\newcommand{\FV}{\ensuremath{\mathsf{FreeVar}}}
\newcommand{\pguards}[1]{\llbracket #1 \rrbracket}
\newcommand{\code}[1]{\texttt{\small #1}}

\newcommand{\minbar}{\scalebox{1.0}[1.0]{$-$}}
\newcommand{\scon}{\mathbin{\ast}} \newcommand{\ocon}{ \mathbin{\mbox{$\mathrlap{\cup}\hspace*{.09em}
      \raisebox{.04em}[0ex][0ex]{$\scon$}$\hspace*{.07em}}}}
\newcommand{\wand}{\mathrel{\mbox{$\hspace*{-0.03em}\mathord{-}\hspace*{-0.4em}
  \mathord{-}\hspace*{-0.13em}
     \mathord{\scon}$\hspace*{-0.005em}}}}
\newcommand{\septraction}{\mathrel{\mbox{$\hspace*{-0.03em}\mathord{-}\hspace*{-0.66em}
  \mathord{-}\hspace*{-0.1em}\mathord{\ostar}$\hspace*{0.05em}}}}

\colorlet{red}{red!80!black}

\let\magicwand\wand
\mathlig{--*}{\mathrel{\magicwand}}
\mathlig{--o}{\mathrel{\septraction}}
\mathlig{|->}{\mathrel{\mapsto}} \mathlig{<=>}{\mathrel{\Leftrightarrow}} \mathlig{==>}{\mathrel{\Rightarrow}} \mathlig{-|-}{\mathrel{\mathrlap{\dashv} \hspace*{0.15em} \vdash}} \mathlig{**}{\mathbin{\ocon}}
\mathlig{*}{\mathbin{\scon}}
\mathlig{/|}{\mathbin{\wedge}} \mathlig{|/}{\mathbin{\vee}} \mathlig{|-}{\mathrel{\vdash}} \mathlig{|=}{\models} \mathlig{//}{\color{black}{\sslash}} 


\newcommand{\defeq}{\mathbin{\stackrel{\Delta}{=}}}
\newcommand{\tx}[1]{\text{#1}}
\newcommand{\p}[1]{\ensuremath{\mathsf{#1}}} \newcommand{\m}[1]{\ensuremath{\mathit{#1}}} \newcommand{\ma}[1]{\ensuremath{\mathcal{#1}}} \let\ramify\lightning
\newcommand{\infrulestyle}[1]{\textsc{#1}}
\newcommand{\infrule}[4]{\inferrule*[lab=\infrulestyle{#1},right=$\mathrlap{#4}$]{#2}{#3}}
\newcommand{\medocon}{
  \raisebox{-0.3ex}{\resizebox{0.63em}{!}{$\scon$}} \hspace{-2.05ex} \bigcup}
\newcommand{\triple}[3]{\{#1\}\,#2\,\{#3\}}

\lstset{language=C,
  morecomment=[n][{\color{red}}]{/*}{*/},
  morecomment=[l][{\color{red}}]{//},
  sensitive=true, mathescape=true, showlines=true,
  basicstyle=\normalfont\footnotesize\tt,
  keywordstyle=\color{blue}, numbers=left,
  numberstyle=\tiny, numbersep=5pt, boxpos=t,
  showstringspaces=false
}
\usetikzlibrary{arrows.meta, positioning, decorations.pathmorphing, fit}
% \pgfrealjobname{autoquack}

\begin{document}

\title[Certifying Graph-Manipulating Programs]
{Certifying Graph-Manipulating C Programs via~Localizations within Data Structures}





\author{First1 Last1}
\authornote{with author1 note}          \orcid{nnnn-nnnn-nnnn-nnnn}             \affiliation{
  \position{Position1}
  \department{Department1}              \institution{Institution1}            \streetaddress{Street1 Address1}
  \city{City1}
  \state{State1}
  \postcode{Post-Code1}
  \country{Country1}                    }
\email{first1.last1@inst1.edu}          

\author{First2 Last2}
\authornote{with author2 note}          \orcid{nnnn-nnnn-nnnn-nnnn}             \affiliation{
  \position{Position2a}
  \department{Department2a}             \institution{Institution2a}           \streetaddress{Street2a Address2a}
  \city{City2a}
  \state{State2a}
  \postcode{Post-Code2a}
  \country{Country2a}                   }
\email{first2.last2@inst2a.com}         \affiliation{
  \position{Position2b}
  \department{Department2b}             \institution{Institution2b}           \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   }
\email{first2.last2@inst2b.org}         


\begin{abstract}
We develop powerful and general techniques to mechanically verify realistic programs that
manipulate heap-represented graphs and related data structures with intrinsic sharing.
We construct a modular and general setup for reasoning about abstract mathematical graphs
and use separation logic to define how such abstract graphs are represented concretely in
the heap. We upgrade Hobor and Villard's theory of ramification to support existential
quantifiers in postconditions and to smoothly handle modified program variables.
We demonstrate the generality
and power of our techniques by integrating them into the Verified Software Toolchain and
certifying the correctness of six graph-manipulating programs written in
CompCert C, including
a 400-line generational garbage collector for the CertiCoq project.
While doing so, we identify
two places where the semantics of C is too weak to define generational
garbage collectors of the
sort used in the OCaml runtime.  Our proofs are entirely machine-checked in Coq.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}



\keywords{Separation logic, Graph-manipulating programs, Coq, CompCert/VST}  


\maketitle

\section{Introduction}
\label{dummyref} \label{sec:intro}
Over the last fifteen years, separation logic has facilitated great strides
in verifying programs that manipulate tree-shaped data structures.
\citep{berdine:smallfoot,chin:hipsleek,jacobs:verifast,
chlipala:bedrock,bengtson:charge,appel:programlogics}.
Unfortunately, programs that manipulate graph-shaped data structures
(i.e. structures with \emph{intrinsic sharing}) have proved harder to verify.
Indeed, such programs were formidable enough that a number of the early
landmark results in separation logic devoted substantial effort to verifying
single examples such as Schorr-Waite~\cite{hongseok:phd} or
union-find~\cite{neelthesis} with pen and paper.
More recent landmarks have moved to a machine-checked context, but have still
been devoted to either single examples or to classes of closely-related examples
such as garbage collectors~\cite{gcexample3,cakemlgc}.
These kinds of examples tend to require a large number
of custom predicates and subtle reasoning, which generally does not carry
to the verification of other graph-manipulating programs.

In contrast, we present a general toolkit for verifying graph-manipulating programs in a
machine-checked context. Our techniques are \emph{general} in that they handle a diverse
range of graph-manipulating programs, and \emph{modular} in that they allow code
reuse (\emph{e.g.} facts about reachability) and encourage separation of concerns
(\emph{e.g.} between abstract mathematical graphs and their concrete representation
in the heap).
Our techniques are \emph{powerful} enough to reason about real C code as compiled by
CompCert~\cite{leroy:compcert}, and also
\emph{lightweight} enough to integrate into the Verified
Software Toolchain (VST)~\cite{appel:programlogics} without requiring major reengineering.
Both CompCert and VST are distributed as optional packages in the CoqIDE installer and through 
opam, so they have a sizable user base that can take advantage of our techniques. Finally, our techniques \emph{scale} well beyond short toy programs: we certify the
correctness of a generational garbage collector for the CertiCoq
project~\cite{certicoqpaper} ($\approx400$ rather devilish lines of C).

We proceed in three steps. First, we develop a ``mathematical graph library'' that is general enough to reason about a wide variety of algorithms and expressive enough to describe the behavior of these algorithms in real machines.  We modularize this library carefully so that common ideas---\emph{e.g.} subgraphs, reachability, and isomorphism---can be efficiently reused
in different algorithms.  Second, use separation logic to express how these abstract graphs
are actualized in the heap as concrete graphs in a way that facilitates the reuse of key definitions and theorems across algorithms.  Finally, we develop a notion of \emph{localization blocks} that
allows us to carry out our Hoare proofs in a modular fashion, even in the presence of the
implicit sharing intrinsic to graphs, by using our \textsc{Localize} rule:

\hide{
\begin{equation}
\label{eq:localize}
\begin{array}{@{}l@{}}
\infrule{Localize}
{G_1 |- L_1 * R \\
\{ L_1 \} ~ c ~ \{ \exists x.~ L_2 \} \\
R |- \forall x.~ (L_2 --* G_2) }
{\{ G_1 \} ~ c ~ \{ \exists x.~ G_2 \}} {(\dagger)} \\
[3pt]
(\dagger)~ \mathit{freevars}(R) \cap \MV(c) = \emptyset
\end{array}
\end{equation} \marginpar{Can we typeset this a little better?}
} 
\begin{equation}
\label{eq:localize}
\inferrule[Localize]	
{G_1 |- L_1 * R \\
\{ L_1 \} ~ c ~ \{ \exists x.~ L_2 \} \\
R |- \forall x.~ (L_2 --* G_2) }
{\{ G_1 \} ~ c ~ \{ \exists x.~ G_2 \}} \quad \FV(R) \cap \MV(c) = \emptyset \qquad
\end{equation}
\textsc{Localize} connects the ``local'' effect of a command~$c$, \emph{i.e.}
transforming~$L_1$ to~$L_2$, with its ``global'' effect, \emph{i.e.} from~$G_1$ to~$G_2$.
The key is carefully choosing a \emph{ramification frame}~$R$ that satisfies a pair of
delicately-stated entailments\footnote{Readers less familiar with the separating implication $P --* Q$, also known as \emph{magic wand}, can refer to its semantics in Figure~\ref{fig:seplogsem} (page~\pageref{fig:seplogsem}), which also models the other separation logic operators
we use in this paper.  The key proof rule for magic wand is its adjointness
with the separating conjunction:~$(P * Q |- R) \Leftrightarrow (P |- Q --* R)$.} and
the side condition on modified local program variables.
\textsc{Localize} is a more general version of the well-known \textsc{Frame} rule,
which does the same task in the simpler case when $G_i = L_i * F$
for some frame~$F$ that is untouched by~$c$.  Said differently, \textsc{Frame} works well
for tree-manipulating programs, while \textsc{Localize} handles the more subtle
graph-manipulating programs.
\textsc{Localize} upgrades the \textsc{Ramify} rule~\cite{hobor:ramification} in two key ways:
support for existential
quantifiers in postconditions and smoother treatment of modified program variables.


Our contributions are organized as follows:
\begin{itemize}
\item[\S\ref{sec:orientation}] We use the classic ``union-find'' disjoint set algorithm~\cite{clrs} to show how our three key ingredients---mathematical graphs, spatial graphs, and localization blocks---come together to verify
graph-manipulating algorithms.
To the best of our knowledge this is the first machine-checked verification of this algorithm that starts with real C code.
We introduce \emph{localization blocks} as a notation for \textsc{Localize} in decorated programs. 
\item[\S\ref{sec:localizations}] We show that \textsc{Localize} and \textsc{Frame} are equivalent,
and a delicate technique to properly handle modified local variables.  We show a mark-graph
program that explores a graph in a fold/unfold style and discuss the utility of linked 
existentials in postconditions. We also briefly discuss some additional examples
to give a sense of the breadth of algorithms we can verify: marking a DAG, an array-based 
version of union-find, and pruning a graph into a spanning tree.
\item[\S\ref{sec:mathgraph}] We develop a general framework of mathematical graphs powerful enough to support realistic verification in a mechanized context.  We give a sampling of key definitions and show how our framework is modularized to facilitate code reuse.
\item[\S\ref{sec:spacegraph}] We suggest that the Knaster-Tarski fixpoint~\cite{tarski:fixpoint} cannot define a usable separation logic graph predicate.  We propose a better definition for general spatial graphs that still enjoys a ``recursive'' fold/unfold.  We prove general theorems about spatial graphs in a way that can be utilized in multiple flavors of separation logic. \item[\S\ref{sec:certigc}] We discuss the certification of the CertiCoq garbage collector (GC). While certifying this GC we identify two places where the semantics of C is too weak to define an OCaml-style GC. We also found and fixed a rather subtle overflow error in the original C code for the GC, justifying the effort of developing the machine-checked proof.
\item[\S\ref{sec:development}] We discuss how our techniques are integrated into the
``Floyd'' module of VST, a separation-logic based engine to help users verify
CompCert~C programs, via two new Floyd tactics \li{localize} and \li{unlocalize}.
We also document statistics related to our overall development.
\item[\S\ref{sec:related}] We discuss related work.
\item[\S\ref{sec:conclusion}] We discuss directions for future work and conclude.
\end{itemize}
All of our results are machine checked in Coq and available at~\cite{github}.
 
\section{Localizations yield a tidy union-find}
\label{sec:orientation}
\begin{figure}[t]
\vspace{-1ex}
  \begin{lstlisting}[multicols=2]
struct Node { unsigned int rank; 
              struct Node * parent; }
$//$$\label{code:findstart}\{\p{uf\_graph}(\gamma) /| \tx{x}\in\m{V}(\gamma)\}$
struct Node* find(struct Node* x) {
  struct Node *p;
$//$$\label{code:ufbefram1}\left\{\!\!\!\begin{array}{l@{}} \p{uf\_graph}(\gamma) /| \tx{x}\in\m{V}(\gamma) /| \null \\ {\color{red}\exists\m{r},\m{pa}.~\gamma(\tx{x}) = (\m{r}, \m{pa})} /| {\color{red}\m{pa}\in\m{V}(\gamma)} \end{array} \right\}$
$//$$\label{code:befparentfind} \searrow \left\{\!\!\!\begin{array}{l@{}} {\color{red}\tx{x}|-> \m{r},\m{pa}} /| \tx{x}\in\m{V}(\gamma) /| \null \\ \gamma(\tx{x}) = (\m{r}, \m{pa}) /| \m{pa}\in\m{V}(\gamma) \end{array}\right\}$
$\ramify(\ref{findram1})$  p = x -> parent; $\label{code:findram1}$
$//$$\label{code:aftparentfind} \swarrow \left\{\!\!\!\begin{array}{l@{}} \tx{x}|-> \m{r},\m{pa} /| {\color{red}\tx{p} = \m{pa}} /| \tx{x}\in\m{V}(\gamma) /| \null \\ \gamma(\tx{x}) = (\m{r}, \m{pa}) /| \m{pa}\in\m{V}(\gamma)\end{array}\right\}$
$//$$\label{code:ufaftram1}\left\{\!\!\!\begin{array}{l@{}} {\color{red}\p{uf\_graph}(\gamma)} /| \tx{p} = \m{pa} /| \tx{x}\in\m{V}(\gamma) /| \null \\ \gamma(\tx{x}) = (\m{r}, \m{pa}) /| \m{pa}\in\m{V}(\gamma)\end{array}\right\}$
  if (p != x) { $\label{code:ufif}$
$//$$\label{code:ufaftpxeqcheck}\left\{\!\!\!\begin{array}{l@{}} \p{uf\_graph}(\gamma) /| \tx{p} = \m{pa} /| {\color{red}\m{pa} \neq \tx{x}} /| \null \\ \tx{x}\in\m{V}(\gamma) /| \gamma(\tx{x}) = (\m{r}, \m{pa}) /| \m{pa}\in\m{V}(\gamma)\end{array}\right\}$
    p = find(p); $\label{code:ufreccall}$
$//$$\label{code:ufbefram2}\left\{\!\!\!\begin{array}{l@{}}{\color{red}\exists \gamma',\m{rt}.~\p{uf\_graph}(\gamma')} /| {\color{red}\tx{p} = \m{rt}} /| \m{pa} \neq \tx{x} /| \tx{x}\in\m{V}(\gamma) /| \null \\ {\color{red}\m{findS}(\gamma,\m{pa},\gamma')} /| {\color{red}\m{uf\_root}(\gamma',\m{pa},\m{rt})} /|  \gamma(\tx{x})=(\m{r},\m{pa})\end{array}\right\}$
$//$$\label{code:findbeforexparent}\searrow \left\{\!\!\!\begin{array}{l@{}}{\color{red}\tx{x} |-> \m{r},{pa}} /| \tx{p} = \m{rt} /| \m{pa} \neq \tx{x} /| \m{findS}(\gamma, \m{pa}, \gamma') /| \null \\ \m{uf\_root}(\gamma',\m{pa},\m{rt}) /| \tx{x}\in\m{V}(\gamma) /| \gamma(\tx{x})=(\m{r}, \m{pa})\end{array}\right\}$
$\ramify(\ref{findram2})$   x -> parent = p; $\label{code:ufpathcompress}$
$//$$\label{code:findafterxparent}\swarrow \left\{\!\!\!\begin{array}{l@{}}\tx{x} |-> \m{r},{\color{red}\m{rt}} /| \tx{p} = \m{rt} /| \m{pa} \neq \tx{x} /| \m{findS}(\gamma, \m{pa}, \gamma') /| \null \\ \m{uf\_root}(\gamma',\m{pa},\m{rt}) /| \tx{x}\in\m{V}(\gamma) /| \gamma(\tx{x})=(\m{r}, \m{pa})\end{array}\right\}$
$//$$\label{code:ufaftram2}\left\{\!\!\!\begin{array}{l@{}} {\color{red}\exists \gamma''.~ \p{uf\_graph}(\gamma'')} /| {\color{red}\m{findS}(\gamma, \m{pa}, \gamma'')} /| \null \\ {\color{red}\m{uf\_root}(\gamma'',\tx{x},\m{rt})} /| \tx{p} = \m{rt} \end{array}\right\}$
  } return p; $\label{code:ufreturn}$
} $//$$\label{code:findend} \left\{\!\!\!\begin{array}{l@{}} \exists \gamma'',\m{rt}.~\p{uf\_graph}(\gamma'') /| \m{findS}(\gamma, \tx{x}, \gamma'') /| \null \\\m{uf\_root}(\gamma'',\tx{x},\m{rt}) /| {\color{red}\tx{ret} = \m{rt}}  \end{array}\right\}$
\end{lstlisting}
\vspace*{-1ex}
{\footnotesize
\begin{flushleft}
\begin{minipage}[c]{0.46\textwidth}
\vspace*{-1ex}
\begin{equation*}
\label{eqn:ufgraphdefn}
\begin{array}{@{}l@{}lcl@{}}
\multicolumn{2}{r}{\p{uf\_graph}(x, \gamma)} & \defeq & \underset{\m{v} \in \m{V}(\gamma)}{\bigstar} \m{v}	\mapsto\gamma(\m{v}) \\
[15pt]
\m{uf\_root}&(\gamma,\m{x},\m{rt}) & \defeq & \m{x} \accentset{\gamma}{\leadsto}^{\star} \m{rt} \; /| \null \\  
& \multicolumn{3}{@{}l}{\forall \m{rt'}.~\m{rt} \accentset{\gamma}{\leadsto}^{\star} \m{rt'} => \m{rt} = \m{rt'}}
\end{array}
\end{equation*}
\end{minipage}
\vline
\begin{minipage}[c]{0.5\textwidth}
\vspace*{-1ex}
\begin{equation*}
\begin{split}
\quad \m{findS}&(\gamma,\m{x},\gamma') \; \defeq \; \big(\forall \m{v}.~ \m{v}\in\m{V}(\gamma) <=> \m{v}\in\m{V}(\gamma') \big) /| \null \\ 
&\big(\forall \m{v}.~\m{v}\in\m{V}(\gamma) => \gamma(\m{v}).\m{rank} = \gamma'(\m{v}).\m{rank} \big) /| \null \\
&\big(\forall \m{r},\m{r'}.~\m{uf\_root}(\gamma, \m{v}, \m{r}) => \m{uf\_root}(\gamma', \m{v}, \m{r'}) => \m{r} = \m{r'} \big) /|  \null \\ 
&\big(\gamma \smallsetminus \{\m{v} \in \gamma \mid \m{x} \accentset{\gamma}{\leadsto}^{\star} \m{v}\} \cong \gamma' \smallsetminus \{\m{v} \in \gamma \mid \m{x} \accentset{\gamma}{\leadsto}^{\star} \m{v}\}\big)
\end{split}
\end{equation*}
\end{minipage}
\end{flushleft}
}









\vspace{-0.4em}
\caption{Clight code and proof sketch for find}
\label{fig:find}
\vspace{-1em}
\end{figure}
 
As an initial demonstration of our techniques, we show the decorated code of the
\texttt{find} function from the classic disjoint-set data structure in
Figure~\ref{fig:find}. The \texttt{find} function returns the root
(ultimate parent) of a \texttt{Node} \texttt{x}. A node is a root when its parent
pointer points to itself (line~\ref{code:ufif});
other than such self-loops at roots, the structure is acyclic.
For good amortised performance, \texttt{find} also performs path
compression (line~\ref{code:ufpathcompress}).
At first, \texttt{find} appears rather trivial since it only has about 5 lines
of code and a \texttt{Node} has only a single outgoing pointer.
In actual fact, the rather subtle nature of path compression and the
implicit sharing inherent in parent-pointers make the disjoint-set data
structure very difficult to reason about. Indeed, the first pen-and-paper
verification in separation logic required 20 pages~\cite{neelthesis}.

We use the following conventions in our invariants.  Pure predicates are written in
\textit{italic}.  We write~$\gamma$ to
mean a ``mathematical'' (or~``pure'') graph: roughly, a set of
labeled vertices $V(\gamma)$ and edges $E(\gamma)$.
When $\m{v} \in V(\gamma)$, we write $\gamma(\m{v}) = (r,p)$ to state that vertex $\m{v}$ has
label $r$ and parent vertex $p$ ($r$ stores the ``rank'' of a node; it is ignored
in \texttt{find}).  We detail mathematical graphs in~\S\ref{sec:mathgraph}.

Spatial predicates are written in \textsf{sans-serif}.
Each node $\m{v} \in V(\gamma)$ is
represented in the heap by $\m{v} \mapsto \gamma(\m{v})$, where we use the usual pen-and-paper
trick of writing \emph{e.g.} $\m{v} \mapsto r,p$ to mean
\mbox{$\big(\m{v} |-> r\big) * \big((\m{v} + \m{sizeof}(\li{unsigned int})) |-> p\big)$} in the character-addressed C memory model.
The whole graph (disjoint-set forest) is represented by
$\p{uf\_graph}(\gamma)$, essentially the
iterated separating conjunction of the representations
of each vertex $\m{v} \in V(\gamma)$.
We detail spatial graphs in~\S\ref{sec:spacegraph}.

The invariants at
each program point are natural despite only minor tidying from our machine-checked
proof.  We also enjoy good separation between the spatial predicates and pure
predicates.  All of this is despite verifying real C code, which entails quite a number
of grungy details. As one example, we will examine some grunginess that occurs in the
verification of line~\ref{code:ufif} shortly.

The precondition on line~\ref{code:findstart} says that we have a disjoint-set forest representing the abstract graph~$\gamma$, and that \texttt{x} is a valid vertex in~$\gamma$.  The postcondition is on line~\ref{code:findend}: the heap contains a new union-find graph~$\gamma''$, and \li{find} returns the node \m{rt}.
We specify that $\m{rt}$
is the root (ultimate parent) of \texttt{x} with the pure relation $\m{uf\_root}$.
The relation $\m{findS}$, which conservatively approximates the action of path
compression, relates the final graph~$\gamma''$ to the original graph~$\gamma$.
The formal definitions for the concepts used in $\m{uf\_root}$ and $\m{findS}$
will be given in~\S\ref{sec:mathgraph}, but briefly:
$\m{x} \accentset{\gamma}{\leadsto}^{\star} \m{y}$ expresses that~$y$ is reachable
from~$x$ in~$\gamma$, $\gamma \smallsetminus S$ expresses the result of removing the
vertices in set~$S$ from graph~$\gamma$, and~$\gamma_1 \cong \gamma_2$ expresses that the two
graphs are structurally equivalent.

Most of the verification is straightforward.  To aid human readability, we use the color {\color{red}red} to indicate the changes in the invariants line-by-line.
Each individual line of code
(\ref{code:findram1}, \ref{code:ufif}, \ref{code:ufreccall}, \ref{code:ufpathcompress},
and \ref{code:ufreturn}) is bracketed with invariants leading to relatively easy proofs
of the command (ignoring the symbols~$\searrow \text{, } \ramify(i) \text{, and }
\swarrow$ until~\S\ref{sec:localblocks}).
In addition to improving human comprehensibility, this
also aids mechanical comprehensibility---that is, straightforward
invariants help the underlying verification engine (VST, in our case) handle many grungy
details for us either automatically or with a little human guidance via suitable lemmas.

The pointer comparison in line~\ref{code:ufif} is an example of where
such lemmas are necessary.
Formally, pointer (in-)equality comparison in C is only defined under somewhat delicate
circumstances\footnote{\label{footnote:pointereq}To summarize: it is a mess. Specifically,
whenever (1) \texttt{x} and \texttt{p} are both null; or when (2) one of them is null and the
other has offset between~0 and the size of the memory block into which it is pointing;
or when (3) if \texttt{x} and \texttt{p} are from the same memory block, then both of their
offsets are between~0 and the size of that block; or when (4) \texttt{x} and \texttt{p} are
not in the same memory block and both have offsets between 0 and the size of their
respective memory blocks \emph{minus one}.}.  VST could prove the definedness of the
pointer comparison automatically if we knew
\mbox{$(\texttt{x} |-> \_) * (\texttt{p} |-> \_) * \top$}, but
unfortunately this does not follow from line~\ref{code:aftparentfind} since,
when \texttt{x} is a root, self-loop gives us $\texttt{x}=\texttt{p}$ and
$\texttt{x} |-> \_ * \texttt{x} |-> \_ \vdash \bot$.  Accordingly, we must prove a
simple lemma that states that when $\p{uf\_graph}(\gamma) /| \texttt{x}
\in V(\gamma) /| \texttt{p} \in V(\gamma)$,
the pointer comparison is defined in C.

\subsection{Localization Blocks}
\label{sec:localblocks}

It is time to explain the non-obvious jumps in reasoning bracketed by the
symbols $\searrow \text{, } \ramify(i)$, and $\swarrow$
(lines~\ref{code:ufbefram1}--\ref{code:ufaftram1} and~\ref{code:ufbefram2}--\ref{code:ufaftram2}). We call such bracketed sets of lines ``localization blocks''.
As explained above, the verification of the command itself is entirely
straightforward given its immediate neighbors
(lines~\ref{code:befparentfind}--\ref{code:aftparentfind}
and~\ref{code:findbeforexparent}--\ref{code:findafterxparent}).
What is not so straightforward is how \emph{e.g.} line~\ref{code:ufbefram1}
leads to line~\ref{code:befparentfind} or how line~\ref{code:aftparentfind}
leads to line~\ref{code:ufaftram1}.
Intuitively, a localization block allows us to zoom in from a larger
``global'' context to a smaller ``local'' one, and, after verifying some commands
locally and arriving at a local postcondition, to zoom back out to the global
context. The $\searrow$ and $\swarrow$ symbols formally indicate an application
of the \textsc{Localize} rule (equation \ref{eq:localize} from page~\pageref{eq:localize}).

Recall that \textsc{Localize} connects some ``global'' pre- and postconditions $G_1$ and $G_2$
with some ``local'' pre- and postconditions $L_1$ and $L_2$ using a ramification
frame $R$.
The lines adjacent to
the~$\searrow$ and~$\swarrow$ symbols specify~$G_1$ (\emph{e.g.} line~\ref{code:ufbefram1}),
$L_1$~(line~\ref{code:befparentfind}),
$L_2$~(line~\ref{code:aftparentfind}), and~$G_2$~(line~\ref{code:ufaftram1}).
Note that the \textsc{Localize} rule expects quantifiers in the postconditions $L_2$ and $G_2$,
but lines \ref{code:aftparentfind}--\ref{code:ufaftram1} do not have any.  We can overcome
this mismatch since $\forall P.~ (P -|- \exists x : \m{unit}.P)$ for any $x$ not free in $P$. 


What is not specified explicitly is the ramification frame $R$, which must satisfy
the entailments $G_1 |- L_1 * R$ and (again eliding the quantifier) $R |- L_2 --* G_2$.
Here things are a little delicate.  To give intuition, it is \textbf{almost} enough to choose
$R \defeq L_2 --* G_2$, which makes the second entailment trivial, and reduces the problem
to three remaining checks.

The first check is the \emph{ramification entailment}: $G_1 |- L_1 * (L_2 --* G_2)$.
Informally, this asks whether replacing $L_1$ with $L_2$ inside $G_1$ yields $G_2$.
This ramification entailment is a nontrivial proof obligation both because
we must prove $L_1$ is located inside $G_1$, and because we must prove that
``replacing'' $L_1$ with $L_2$ yields $G_2$.
When we want to refer to the ramification entailment of a localization block in
subsequent text we use the symbol $\ramify(i)$ to connect it to relevant equation
numbers.  Accordingly, $\ramify(\ref{findram1})$ refers to the ramification entailment
associated with lines~\ref{code:ufbefram1}--\ref{code:ufaftram1}:
\begin{equation}
\label{findram1}
\p{graph}(\gamma) /| x \in V(\gamma) \quad |- \quad x |-> \gamma(x) * \big(x |-> \gamma(x) --* \p{graph}(\gamma)\big)
\end{equation}
Here we have isolated the key \textbf{spatial} parts of the invariants on lines~\ref{code:ufbefram1}--\ref{code:ufaftram1}.  Notice that this lemma is stated for any whole-graph predicate $\p{graph}(\gamma)$, and not merely for the special class of ``union-find graphs'' $\p{uf\_graph}(\gamma)$ (that \emph{e.g.} have only one outgoing edge per node).  That is useful because we use the same lemma to prove similar goals in all of our examples.
Indeed, this ``unchanged vertex'' ramification entailment is used whenever we need to read from a vertex in a graph.  In~\S\ref{sec:spacegraph} we describe other generic and reusable lemmas that prove other ramification entailments.

The second check is the Hoare proof of the local
change from $L_1$ to $L_2$.  Since lines~\ref{code:befparentfind} and~\ref{code:aftparentfind}
are straightforward---indeed, the point of \textsc{Localize} is to make them
so---verifying line~\ref{code:findram1} is easy.

The third check is the side condition on the modified variables.  Here we have an irritating
problem: the free variables of $R \defeq L_2 --* G_2$ are \textbf{not} disjoint from
the local variables modified by $c$.  Inspection of lines~\ref{code:findram1}--\ref{code:ufaftram1} shows that the program variable \texttt{p} \textbf{is} modified by $c$,
and \textbf{is} free in both $L_2$ and $G_2$.
This issue is fundamental: the whole point of verifying
a read is to know something about the value that has been read.
Accordingly, our proof fails when we choose $R \defeq (L_2 --* G_2)$.
We will address this problem
head-on in~\S\ref{sec:freevars}, but for now let us content ourselves with knowing
that other than this problem, \textsc{Localize} lets us verify
lines \ref{code:ufbefram1}--\ref{code:ufaftram1}.











\hide{
one by using five predicates.  To guide intuition in \S\ref{sec:localblocks}, we will
provisionally use a simpler variant of \textsc{Localize} called \textsc{Ramify}:

\begin{equation}
\label{eq:ramify}
\inferrule[Ramify]
{\{ L_1 \} ~ c ~ \{ L_2 \} \\
G_1 |- L_1 * (L_2 --* G_2)}
{\{ G_1 \} ~ c ~ \{ G_2 \}} \mathit{freevars}(L_2 --* G_2) \cap \MV(c) = \emptyset
\end{equation}

The \emph{ramification entailment} $G_1 |- L_1 * (L_2 --* G_2)$ captures two key ideas:
first, that $L_1$ is spatially contained within $G_1$; and second, that
\emph{replacing} $L_1$ with $L_2$ inside $G_1$ yields $G_2$. \textsc{Ramify} essentially
combines the two entailments in \textsc{Localize} into one by forcing the choice of
$R \defeq L_2 --* G_2$; it also does not support the full power of existential
quantifiers (quantifiers can appear \emph{within} $L_2$ and $G_2$, but
\emph{the witnesses of such quantifiers cannot be related to each other}).
Although \textsc{Ramify} is sound\footnote{Use \textsc{Localize} with
$P -|- \exists x : \m{unit}.P$ for any $x$ not free in $P$.},
we shall soon see that these drawbacks are serious.

Using either \textsc{Localize} or \textsc{Ramify},

Unfortunately, we still have a problem: the side condition above requires that
}

The second localization block (lines~\ref{code:ufbefram2}--\ref{code:ufaftram2}) is both easier and harder than the first.  It is easier because line~\ref{code:ufpathcompress} does not modify any local program variables, so the side condition is trivially satisfied.  Moreover, although line~\ref{code:ufaftram2} does contain an existential, line~\ref{code:findafterxparent} does not, and so there is no need to ``link'' the two associated witnesses.  We will discuss this issue
in more detail in \S\ref{sec:linkedex}, but for now it is enough to
choose $R \defeq L_2 --* G_2$ exactly written in lines~\ref{code:findafterxparent}
(for $L_2$) and~\ref{code:ufaftram2} (for $G_2$).

On the other hand, the second localization block is harder than the first because there is more going on spatially. $\ramify(\ref{findram2})$ expresses an update to a single node of our graph:
\begin{equation}
\label{findram2}
\inferrule
{x \in V(\gamma') \; \qquad \gamma'' = [x -> (r,rt)]\gamma'}
{\p{graph}(\gamma') \; |- \; x |-> \gamma'(x) * \big(x |-> \gamma''(x) --* \p{graph}(\gamma'')\big)}
\end{equation}
Here we abuse notation a little bit.  The conclusion of the ``rule'' (actually, lemma) is exactly right and appropriately generic, so spatial ramification lemmas of the kind given in \S\ref{sec:spacegraph} can handle the dirty spatial work for us.  However, the second premise uses a notation for ``mathematical graph node update'' that is customized for union-find graphs, since most graphs have more than a rank and single outgoing edge.  More seriously, updating a mathematical graph cannot be done willy-nilly; it is only defined when the properties that restrict the mathematical structure of $\gamma$ are preserved. For example, in the case of union-find graphs,
the graph must be acyclic (other than at roots).
In Coq, these properties are carried around via dependent types as will explained in \S\ref{sec:mathinfra}.

In our proof of \li{find}, the bulk of the example-specific effort (as opposed to generic lemmas we reuse in other examples) is showing that this mathematical update can be done properly, \emph{i.e.} from
\[
\texttt{x} \in V(\gamma) /| \gamma(\texttt{x}) = (r,\m{pa}) \quad \text{ and } \quad
\texttt{x} \neq \m{pa} /|
\m{findS}(\gamma,\m{pa},\gamma') /| \m{uf\_root}(\gamma',\m{pa},\m{rt})
\]
we can prove
\[
\exists \gamma''.~ \gamma'' = [x -> (r,rt)]\gamma' /| \m{uf\_root}(\gamma'',\texttt{x},\m{rt}) /| \m{findS}(\gamma,\texttt{x},\gamma'')
\]


This lemma captures the essence of both finding the root and doing path compression: after compressing your parent and finding its root, you can path compress yourself by rerouting your own parent pointer to your (soon-to-be former) parent's root.  The existential in the goal is nontrivial
exactly because the update $[x -> (r,rt)]\gamma'$ is not always kosher.
This lemma requires some effort to prove, but is completely isolated from the grungy details of C.

With the second localization block complete, the remainder of the verification is straightforward.



\hide{
(Assume until~\S\ref{sec:existentials} that $L_2$ and $G_2$ do not contain ``fancy'' existentials; in this case the explicit existentials in \textsc{Localize} can be ,
which effectively makes them trivial.)  What then remains is to choose a predicate $R$ and prove the two entailments in \textsc{Localize}.  If one ignores the side condition about modified local variables

Turning to the body of the verification (lines~\ref{code:inmark}--\ref{code:outmark}), readers may already have noticed our new notation: blocks of proof sketch bracketed

, such as lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}.  We call a bracketed set of lines like this a ``localization block''; localization blocks were inspired by our new \li{localize} $\searrow$ and \li{unlocalize} $\swarrow$ tactics in Floyd (\S\ref{sec:vst}).


In lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}, imagine unfolding the \p{graph} predicate in line~\ref{code:globalbeforerootmark} using equation \eqref{eqn:bigraphintrofoldunfold} and then zooming in to the root node \li{x} for lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}, before zooming back out in line~\ref{code:globalafterrootmark}.

To define localization blocks formally we need to first understand the \infrulestyle{Frame} and \infrulestyle{Ramify} rules.
}

\hide{



In lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}, imagine unfolding the \p{graph} predicate in line~\ref{code:globalbeforerootmark} using equation \eqref{eqn:bigraphintrofoldunfold} and then zooming in to the root node \li{x} for lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}, before zooming back out in line~\ref{code:globalafterrootmark}.

To define localization blocks formally we need to first understand the \infrulestyle{Frame} and \infrulestyle{Ramify} rules.

\subsection{Frames and ramifications are localizations}


The key rule of separation logic is \infrulestyle{Frame}~\cite{rey02}:
\[
\infrule{Frame}
{\{ P \} ~ c ~ \{Q \}}
{\{P * F \} ~ c ~ \{ Q * F \}}
{\begin{array}{c}F \textrm{ ignores } \MV(c) \end{array}} \qquad \qquad
\vspace{-0.75ex}
\]
The reason \infrulestyle{Frame} is so important is because it enables local verifications.  That is, a verifier can focus on the portions of the heap that are relevant to command $c$ and ``frame away'' the rest.  The side condition ``$F \textrm{ ignores } \MV(c)$'' relates to modified program variables and will be discussed in \S\ref{sec:freevars}.

Hobor and Villard observed that \infrulestyle{Frame} is bit rigid because it forces verifiers to split program assertions into syntactically $*$-separated parts~\cite{hobor:ramification}.  This rigidity is particularly troublesome when verifying programs that manipulate data structures with intrinsic unspecified sharing such as DAGs and graphs.  Hobor and Villard proposed the \infrulestyle{Ramify} rule to circumvent this rigidity:
\vspace{-1.5ex}
\[
\infrule{Ramify}
{\{L_1\} ~ c ~ \{L_2\} \\ G_1 |- L_1 * (L_2--* G_2)}
{\{G_1\} ~ c ~ \{G_2\}}
{\begin{array}{c}(L_2 --* G_2) \\ \textrm{ignores} \\ \MV(c) \end{array}} \qquad \qquad \qquad
\vspace{-1.5ex}
\]

}


\hide{


\subsection{Marking a graph in VST}
\label{sec:vstgraphmark}



In Figure~\ref{fig:markgraph} we put the code and proof sketch of the classic \li{mark} algorithm that visits and colors every reachable node in a heap-represented graph.  The \li{mark} algorithm is good to start with because it is complex enough to require some care to verify while being simple enough that the invariants are straightforward.  In \S\ref{sec:application} we will discuss more complex examples that \emph{e.g.} add/change/remove edges and/or vertices.

The code in Figure~\ref{fig:markgraph} is written in Clight~\cite{blazy:clight}, an input language to the CompCert certified compiler~\cite{leroy:compcert}, which compiles our code exactly as written.
The paper-format verification sketch for \li{mark} in Figure~\ref{fig:markgraph} is extracted from
a Floyd proof in VST, with only minor cleanup to aid the presentation.
Accordingly, there is an unbroken certified chain from our specification of \li{mark} all the way to the assembly code.  In \S\ref{sec:hipsleek} we use HIP/SLEEK~\cite{chin:hipsleek} to verify a Java version of \li{mark}; the program invariants generated by HIP/SLEEK are slightly different due to HIP/SLEEK's heavier automation.


The specification we certify (lines \ref{code:markstart} and \ref{code:markend}) is
\vspace*{-1ex}
\[
\{\p{graph}(\li{x},\gamma)\}~\li{mark(x)}~\{\exists \gamma'.~ \p{graph}(\li{x},\gamma') /| \m{mark}(\gamma, \li{x}, \gamma')\}
\vspace*{-1ex}
\]
The specification is for full functional correctness, stated using \emph{mathematical} graphs~$\gamma$; until \S\ref{sec:mathgraph} consider $\gamma$ to be a function that maps a vertex $v \in V$ to triples $(m,l,r)$, where $m$ is a ``mark'' bit (0 or 1) and $\{l,r\} \subseteq V \uplus \{0\}$ are the neighbors of $v$.
The \emph{spatial} \p{graph} predicate describes how the mathematical graph $\gamma$ is implemented in the heap.  Until~\S\ref{sec:spacegraph} it is enough to know that \p{graph} satisfies the fold/unfold relationship in
equation~\eqref{eqn:bigraphintrofoldunfold}, located just under the code in Figure~\ref{fig:markgraph}.

This fold/unfold relationship deserves attention.
First, as we explain in~\S\ref{sec:fixpointfail}, it is probably a mistake to write~\eqref{eqn:bigraphintrofoldunfold} as a definition using $\stackrel{\Delta}{=}$ rather than as a biimplication using $<=>$.  Second, \eqref{eqn:bigraphintrofoldunfold} uses the ``overlapping conjunction'' $\ocon$ of separation logic; informally $P ** Q$ means that $P$ and $Q$ may overlap in the heap (\emph{e.g.}, nodes in the left subgraph can also be in the right subgraph or even be the root $x$).  The presence of the unspecified sharing indicated by the $\ocon$ connective is exactly why graph-manipulating algorithms are so hard to verify (\emph{e.g.}, it is hard to apply the \infrulestyle{Frame} rule).  The standard semantics of the separation logic connectives used in this paper are in Figure~\ref{fig:seplogsem}.
Third, \eqref{eqn:bigraphintrofoldunfold} illustrates how industrial-strength settings complicate verification.  Lines~\mbox{\ref{code:nodedefstart}--\ref{code:nodedefend}} define the data type \li{Node} used by \li{mark}.  The \li{_Alignas($n$)} directives tell CompCert to align fields on $n$-byte boundaries.  As explained in~\S\ref{sec:goodgraph}, this alignment is necessary in C-like memory models to prove fold-unfold \eqref{eqn:bigraphintrofoldunfold}, which is why \eqref{eqn:bigraphintrofoldunfold} includes an alignment restriction $x~\mathsf{mod}~16 = 0$ and an existentially-quantified ``blank'' second field for the root $x \mapsto m,-,l,r$.


Notice that the postcondition of \li{mark} is specified \emph{relationally}, \emph{i.e.} $\{\exists \gamma'.~ \p{graph}(\li{x},\gamma') /| \m{mark}(\gamma, \li{x}, \gamma')\}$ instead of \emph{functionally}, \emph{i.e.} $\{\p{graph}\big(\li{x},\m{mark}(\gamma, \li{x})\big)\}$. In the first case $\m{mark}$ is a relation that specifies that~$\gamma'$ is the result of correctly marking~$\gamma$ from~\li{x}, whereas in the second $\m{mark}$ is a function that \textbf{computes} the result of marking~$\gamma$ from~\li{x}. For both theoretical and practical reasons a relational approach is better.
Theoretically, relations are preferable because they are more general.  For example, relations allow ``inputs'' to have no ``outputs'' (\emph{i.e.} be partial) or alternatively have many outputs (\emph{i.e.} be nondeterministic).  Our graph \li{copy} algorithm is specified nondeterministically to avoid specifying how \li{malloc} allocates fresh blocks of memory.  Relations are also preferable to functions because they are more compositional.
We take advantage of compositionality by using $\m{mark}(\gamma,x,\gamma') /| \ldots$ to specify both our ``spanning tree'' and ``graph copy'' algorithms in~\S\ref{sec:application}, which also mark nodes while carrying out their primary tasks.

\begin{figure}
\[
\begin{array}{lcl}
\sigma |= P * Q & \defeq & \exists \sigma_1, \sigma_2.~ \sigma_1 \oplus \sigma_2 = \sigma /| \null \\ && ~~ (\sigma_1 |= P) /| (\sigma_2 |= 2)\\
[-2pt]
\sigma |= P ** Q & \defeq & \exists \sigma_1, \sigma_2, \sigma_3.~ \sigma_1 \oplus \sigma_2 \oplus \sigma_3 = \sigma /| \null \\ && ~~ (\sigma_1 \oplus \sigma_2 |= P) /| (\sigma_2 \oplus \sigma_3 |= Q) \\
[-2pt]
\sigma |= P --* Q & \defeq & \forall \sigma_1, \sigma_2.~ \sigma_1 \oplus \sigma = \sigma_2 /| \null \\ && ~~
(\sigma_1 |= P) => (\sigma_2 |= Q) \\
[-2pt]
\sigma |= P --o Q & \defeq & \exists \sigma_1, \sigma_2.~ \sigma_1 \oplus \sigma = \sigma_2 /| \null \\ && ~~
(\sigma_1 |= P) /| (\sigma_2 |= Q)
\end{array}
\]
\vspace*{-1.5em}
\caption{Separation logic connectives; $\oplus$ is the join operation on states, usually some kind of disjoint union on heaps}
\label{fig:seplogsem}
\vspace*{-1em}
\end{figure}

Practically, it is painful to define computational functions over graphs in a proof assistant like Coq, and portions of this pain are overkill.  For example, Coq requires that all functions terminate, a nontrivial proof obligation over cyclic structures like graphs, but our verification of \li{mark} is only for partial correctness.  Defining relations is much easier because \emph{e.g.} one can use quantifiers and does not have to prove termination.
The $\m{mark}$ and $\m{mark1}$ relations we use are defined straightforwardly at the bottom of Figure~\ref{fig:markgraph}.

Turning to the body of the verification (lines~\ref{code:inmark}--\ref{code:outmark}), readers may already have noticed our new notation: blocks of proof sketch bracketed by the symbols $\searrow$ and $\swarrow$, such as lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}.  We call a bracketed set of lines like this a ``localization block''; localization blocks were inspired by our new \li{localize} $\searrow$ and \li{unlocalize} $\swarrow$ tactics in Floyd (\S\ref{sec:vst}).
The intuitive idea is that we zoom in from a larger ``global'' context to a smaller ``local'' one.  After verifying some commands locally to arrive at a local postcondition, we zoom back out to the global context.  Although we do not do so in Figure~\ref{fig:markgraph}, localization blocks can safely nest.
}  
\section{Linking Existentials in Localizations}
\label{sec:localizations}
In this section we (\S\ref{sec:rulessound}) first ensure our feet are solidly planted by proving why \textsc{Localize} is sound, and indeed equivalent to \textsc{Frame}.  Second (\S\ref{sec:freevars}), 
we address the bug from \S\ref{sec:localblocks} and show that \textsc{Localize} is indeed 
strong enough to robustly handle modified local program variables.  Third (\S\ref{sec:linkedex}), 
we showcase two additional features of our framework, linked existentials and a fold/unfold style
for spatial graphs, by covering the verification of a program that marks a cyclic graph.
Finally (\S\ref{sec:application}), we briefly discuss some additional examples we have handled.
Our flagship example, the garbage collector for the CertiCoq project, will be covered in~\S\ref{sec:certigc}.







\subsection{Soundness of $\infrulestyle{Localize}$}
\label{sec:rulessound}

\begin{figure*}
\[
\hspace{-1em}
\infrule{}{
  G_1 |- L_1 * R \\
  \infrule{}{\{L_1\}~c~\{L_2\}}{\{L_1 * R\}~c~\{(\exists x.~ L_2) * R\}}{\infrulestyle{Frame}} \\
  \quad \infrule{}{\infrule{}{\vdots}{(\exists x.~ L_2) * (\forall x.~ (L_2 --* G_2)) |- \exists x.~ G_2}{\infrulestyle{Tauto}}}{(\exists x.~ L_2) * R |- \exists x.~ G_2}{\infrulestyle{Cut}}
  }
  {\{G_1\}~c~\{\exists x.~ G_2\}}{\textsc{Cons}}
\]

\[
\hspace{-1em}
\infrule{}{
\infrule{}{
\infrule{}{\{P\}~c~\{Q\} \\ Q |- \exists x_f.~ Q}{\{P\}~c~\{\exists x_f.~ Q\}}{\infrulestyle{Cons}} \\
  \quad F |- \forall x_f.~(Q --* (Q * F))
}
  {\{P * F\}~c~\{\exists x_f.~(Q * F)\}}{\textsc{Localize}} \\
  \qquad \exists x_f.~(Q * F) |- Q * F
  }
  {\{P * F\}~c~\{Q * F\}}{\textsc{Cons}}  
\]
\caption{Proving \infrulestyle{Localize} from \infrulestyle{Frame}, and conversely \infrulestyle{Frame} from \infrulestyle{Localize}}
\label{fig:rampqproofs}
\end{figure*}

In Figure~\ref{fig:rampqproofs} we put the proof sketches that show that 
\infrulestyle{Localize} and \infrulestyle{Frame} are equivalent.  They require a 
little care with quantifiers, but are in essence straightforward.
In the latter proof set $R \defeq F$, choose $x_f$ fresh, and range the quantifiers
over the unit type.  Notice that in both directions the restriction on modified
program variables is satisfied: in the first proof, \textsc{Localize}'s side
condition that $\FV(R) \cap \MV(c) = \emptyset$ is exactly what \textsc{Frame} needs;
in the second, \textsc{Frame}'s side condition that $\FV(F) \cap \MV(c) = \emptyset$
is exactly what \textsc{Localize} needs (since $R \defeq F$).
The equivalence between \textsc{Frame} and \textsc{Localize} means that our techniques will be sound in any separation logic.

\paragraph{Notes on notation.} Although we do not do so in Figure~\ref{fig:find}, localization blocks can safely nest.  When the ramification entailment is not noteworthy we can omit the $\ramify(i)$ reference in pen-and-paper proofs.  When we wish to save vertical space we can write $\{ G_1 \} \searrow \{ L_1 \}$ and $\{ G_2 \} \swarrow \{ L_2 \}$.
We also note that since \infrulestyle{Localize} can derive \infrulestyle{Frame}, our notation for localization blocks clarifies pen-and-paper uses of \infrulestyle{Frame}, especially in multi-line contexts with nontrivial $F$.
\hide{, for which the current popular notation to express \infrulestyle{Frame} involves a liberal use of
ellipses, \emph{e.g.}:

\vspace{5pt}

\begin{minipage}{.25\textwidth}
Old notation:
\begin{lstlisting}
// $\{ P_1 * F_1 * F_2 * F_3 \}$
   $c_1$;
// $\{ P_2 * \ldots \}$
   $c_2$;
// $\{ P_3 * \ldots \}$
   $c_3$;
// $\{ P_4 * F_1 * F_2 * F_3 \}$
\end{lstlisting}
\end{minipage} \quad \vline \; ~~~
\begin{minipage}{.3\textwidth}
New notation:
\begin{lstlisting}[numbers=none]
// $\{ P_1 * F_1 * F_2 * F_3 \} \searrow \{ P_1 \}$
      $c_1$;
//    $\{ P_2 \}$
      $c_2$;
//    $\{ P_3 \}$
      $c_3$;
// $\{ P_4 * F_1 * F_2 * F_3 \} \swarrow \{ P_4 \}$
\end{lstlisting}
\end{minipage}
\vspace{-0.75ex}
}

\hide{
\subsection{Forward ramification}
\marginpar{\tiny \color{blue} What to do about this now that H/S has been cut?}

{\color{magenta}The forward style of reasoning employed by HIP/SLEEK uses the existential wand $--o$ to express ramifications instead of the more typical universal wand $--*$.  The standard $--*$ form of ramification is weaker, but the strongest postcondition style using $--o$ can also get the job done without too much extra work since:}
\vspace*{5.25ex}
\vspace*{-6ex}
\[
\inferrule[WandToEwand]
{G_1 |- L_1 * (L_2 --* G_2)}
{(L_1 --o G_1) * L_2 |- G_2} \m{precise}(L_1)
\]
\[
\begin{array}{@{}l@{}l@{}}
\m{precise}(P) ~ \defeq ~ & (\sigma_1 |= P) => (\sigma_2 |= P) => \\
& ~~ (\sigma_1 \oplus \sigma_1' \! = \! \sigma) => (\sigma_2 \oplus \sigma_2' \! = \! \sigma) => \sigma_1 \! = \! \sigma_2
\end{array}
\]
In \S\ref{sec:ramifylib} we will discuss the ``supplemental'' spatial libraries, which ensures
the preciseness of our key predicates.
}

\subsection{Smoothly handling modified program variables}
\label{sec:freevars}

Consider using \textsc{Localize} to verify the program
\vspace{-1ex}
\begin{lstlisting}[numbers=none]
$// \{ \tx{x} = 5 /| A \} \searrow \{\tx{x} = 5 /| B \}$
  ...; x = x + 1; ...;
$// \{ \tx{x} = 6 /| D \} \swarrow \{\tx{x} = 6 /| C \}$
\end{lstlisting}
\vspace{-1ex}
Suppose that other (elided) lines of the program make localization desirable, even though it is overkill for a single assignment.  The key issue is that if one sets $R \defeq L_2 --* G_2$, as 
we tried to do in \S\ref{sec:localblocks}, then the program variable {\li{x}} appears in all four positions in the ramification entailment
\vspace{-1ex}
\[
\overbrace{(\li{x} \! = \! 5 /| A)}^{G_1} |- \overbrace{(\li{x} \! = \! 5 /| B)}^{L_1} * \big(\overbrace{(\li{x} \! = \! 6 /| C)}^{L_2} --* \overbrace{(\li{x} \! = \! 6 /| D)}^{G_2}\big)
\vspace{-1ex}
\]
For the sake of simplicity, assume that in the above snippet only \texttt{x} is modified
and that \texttt{x} does not appear free in $A$, $B$, $C$ or $D$.  Let us further assume
that, modulo the local variable issue we are trying to solve, the entailment holds.
In other words, let us assume that $A |- B * (C --* D)$.

Turning to the local variable issue itself, in~\S\ref{sec:localblocks} we observed 
that $L_2 --* G_2$ does \textbf{not} ignore the modified program variable \tx{x}, 
preventing us from meeting \infrulestyle{Localize}'s side condition\footnote{There is 
another problem: in the standard model for local variable treatment in separation logic, 
the separating implication is vacuously true since \tx{x} cannot simultaneously be 
both $5$ and $6$.  But since two fatal problems are overkill, let us move on.}.  
Intuitively, the side condition on \infrulestyle{Localize} seems to be a bit too strong 
since it prevents us from mentioning variables in the postconditions that have been modified 
by code $c$.  As in other cases when life gets tough, what we need is an elegant little dance, and as with most dances one should lead by example.

First, define $\hat{L_2}(x_f) \defeq (x_f \! = \! 6 /| C)$ and
$\hat{G_2}(x_f) \defeq (x_f \! = \! 6 /| D)$, \emph{i.e.} replace the troublesome program variable \tx{x} in $L_2$ and $G_2$ with a harmless fresh metavariable $x_f$.  Next, notice that with a carefully chosen existential quantifier, we can express the original $L_2$ with the new $\hat{L_2}$
while keeping the troublesome program variable \tx{x} isolated and shift the above decorated program
into the form
\begin{lstlisting} $// \{ \tx{x} \! = \! 5 /| A \} \searrow \{\tx{x} \! = \! 5 /| B \}$
  ...; x = x + 1; ...;
  $\, // \{\tx{x} \! = \! 6 /| C\}$
$\label{code:locexamplepresw}\swarrow // \{\exists x_f.~ (x_f = \tx{x}) /| (x_f \! = \! 6 /| C) \} $
$\label{code:locexamplepostsw}// \{ \exists x_f.~ (x_f = \tx{x}) /| (x_f \! = \! 6 /| D) \}  \}$
$// \{ \tx{x} \! = \! 6 /| D \}  \}$
\end{lstlisting}
Notice that lines~\ref{code:locexamplepresw} and~\ref{code:locexamplepostsw}
are exactly in the form $\exists x_f. \hat{\hat{L_2}}(x_f)$ and $\exists x_f. \hat{\hat{G_2}}(x_f)$, \emph{i.e.} exactly in the format permitted by \textsc{Localize}, where $\hat{\hat{L_2}}(x_f) \defeq (x_f = \tx{x}) /| \hat{L_2}(x_f)$, \emph{i.e.} $(x_f = \tx{x}) /| (x_f \! = \! 6 /| C)$ and $\hat{\hat{G_2}}(x_f)$ is similar. Now apply \textsc{Localize} with $R \defeq \forall x_f.~\hat{L_2}(x_f) --* \hat{G_2}(x_f)$, \emph{i.e.} $\forall x_f.~(x_f \! = \! 6 /| C) --* (x_f \! = \! 6 /| D)$.  By construction, $R$
is free from all program variables modified by $c$, so \textsc{Localize}'s side condition is
satisfied.  All that remains is to prove \textsc{Localize}'s two entailments.  Let us consider
them in reverse order.  The second one is $R |- \forall x_f.~ \big(\hat{\hat{L_2}}(x_f) --* \hat{\hat{G_2}}(x_f)\big)$, \emph{i.e.}
\[
\forall x_f.~\big(\hat{L_2}(x_f) --* \hat{G_2}(x_f)\big) |- \forall x_f.~\Big(\big((\tx{x} = x_f) /| \hat{L_2}(x_f)\big) --* \big((\tx{x} = x_f) /| \hat{G_2}(x_f)\big)\Big)
\]
This turns out to be just a long-winded tautology, and can be done automatically in a tool.

The first of \textsc{Localize}'s entailments is $G_1 |- L_1 --* R$, \emph{i.e.}
\[
(\li{x} \! = \! 5 /| A) |- (\li{x} \! = \! 5 /| B) * \big(\forall x_f.~ (x_f \! = \! 6 /| C) --* (x_f \! = \! 6 /| D) \big)
\]
This can be broken into the ``variable-related'' part $\li{x} \! = \! 5 |- (\li{x} \! = \! 5) * \big(\forall x_f.~ (x_f \! = \! 6 --* x_f \! = \! 6)\big)$, which is also a tautology, and the ``spatial'' part $A |- B * (C --* D)$, which was true by assumption above.

With carefully engineering, all of the modified-variable dance above can be done fully automatically, and in a way that is completely hidden to end-users.  The only remaining proof
goal is the spatial part, which captures the key action of the localization block.  To solve
these in practice, we end up applying generic lemmas from \S\ref{sec:spacegraph}.

\paragraph{Discussion.} The delicacy and detail in the dance above may seem to be making
mountains out of molehills, since a careful treatment of modified program variables is 
hardly a sexy topic.  Indeed, in pen-and-paper systems they are molehills, with any
number of workarounds including: making local program transformations to introduce 
fresh variables and arguing for program equivalence, using 
variables-as-resource~\cite{bornat:var}, or even just sweeping the issue under the rug.

In a mechanized context, working with existing toolsets, these kinds of solutions are
not viable.  Either we must reinvent a \textbf{very, very} large wheel---combined, 
VST and CompCert contain about 840k LOC---or we must dance within their constraints.
VST does not use variables as resource, nor does it have modules to reason about program equivalence.  Moreover, it is hardly unique in these respects: most other mechanized verification systems do not support these solutions either~\cite{beckert:2007,distefanop08,bengtson:charge,chin:hipsleek}.  By respecting the design
decisions taken by most existing tools, our solutions can be incorporated more easily; in~\S\ref{sec:development} we will see that our additions to VST are less than 1\% of its codebase.

\subsection{Linked existentials}
\label{sec:linkedex}

\colorlet{stash}{red!80!black}
\colorlet{red}{black}

\begin{figure}[t]
\begin{lstlisting}[multicols=2]
struct Node {int  _Alignas(16) m; $\label{code:nodedefstart}$
  struct Node * _Alignas(8) l, * r };$\label{code:nodedefend}$
void mark(struct Node * x){$//$$\label{code:markstart}\{\p{graph}(\tx{x},\gamma)\}$
  struct Node * l, * r; int root_mark; $\label{code:inmark}$
  if (x == 0) return;
$//$$\label{code:globalbeforerootmarkwithex}\{\p{graph}(\tx x,\gamma) /| {\color{red}\exists m,l,r. \gamma(\tx{x}) = (m,l,r)}\}$
$//$$\label{code:globalbeforerootmark}\{\p{graph}(\tx x,\gamma) /| \gamma(\tx{x}) = (m,l,r)\}$
$//$$\label{code:beforerootmark}\searrow \{{\color{red}\tx x|-> m,-,l,r}\}$
$\label{code:markram1}$      root_mark = x -> m;
$//$$\label{code:afterrootmark}\swarrow \{\tx x|-> m,-,l,r /| {\color{red}m = \tx{root\_mark}}\}$
$//$$\label{code:globalafterrootmark}\{{\color{red}\p{graph}(\tx x,\gamma)} /| {\color{red}\gamma(\tx{x}) = (m,l,r)} /| m = \tx{root\_mark} \}$
  if (root_mark == 1) return;
$//$$\{\p{graph}(\tx x,\gamma) /| \gamma(\tx{x}) = ({\color{red}0},l,r) \}$
$//$$\label{code:markbeforetripleramify}\searrow \{{\color{red}\tx x|-> 0,-,l,r} /| \gamma(\tx{x}) = (0,l,r)\}$
$\label{code:markram2}\ramify(\ref{lem:updategraphnode})$  l = x -> l; r = x -> r; x -> m = 1;
$//$$\label{code:markaftertripleramify}\swarrow \left\{\!\!\!\begin{array}{l@{}}\tx x|-> {\color{red}1},-,\tx{l},\tx{r} /| \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \null \\ {\color{red}\exists \gamma'. \m{mark1}(\gamma, \tx{x}, \gamma')}\end{array}\right\}$
$//$$\{{\color{red}\exists \gamma'. \p{graph}(\tx x,\gamma')} /| \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{mark1}(\gamma, \tx{x}, \gamma')\}$
$//$$\label{code:beforemarkl}\{\p{graph}(\tx x,\gamma') /| \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{mark1}(\gamma, \tx{x}, \gamma')\}$
$//$$\searrow \{{\color{red}\p{graph}(\tx l, \gamma')}\}$
$\label{code:markram3}\ramify(\ref{lem:updatesubgraph})$      mark(l);
$//$$\label{code:postmark1}\swarrow \{{\color{red}\exists \gamma''. \p{graph}(\tx l, \gamma'')} /| {\color{red}\m{mark}(\gamma', \tx{l}, \gamma'')}\}$
$//$$\label{code:aftermarkl}\left\{\!\!\!\begin{array}{l@{}}\exists \gamma''. \p{graph}(\tx x,\gamma'') /| \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \null \\ \m{mark1}(\gamma, \tx{x}, \gamma') /| \m{mark}(\gamma', \tx{l}, \gamma'')\end{array}\right\}$
$//$$\left\{\!\!\!\begin{array}{l@{}}\p{graph}(\tx x,\gamma'') /| \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \null \\ \m{mark1}(\gamma, \tx{x}, \gamma') /| \m{mark}(\gamma', \tx{l}, \gamma'')\end{array}\right\}$
$//$$\searrow \{\p{graph}(\tx r, \gamma'')\}$
$\label{code:markram4}\ramify(\ref{lem:updatesubgraph})$      mark(r);
$//$$\swarrow \{\exists \gamma'''. \p{graph}(\tx r, \gamma''') /| \m{mark}(\gamma'', \tx{r}, \gamma''')\}$
$//$$\label{code:outmark}\left\{\!\!\!\begin{array}{l@{}}\exists \gamma'''. \p{graph}(\tx x,\gamma''') /| \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \null \\ \m{mark1}(\gamma, \tx{x}, \gamma') /| \m{mark}(\gamma', \tx{l}, \gamma'') /| \m{mark}(\gamma'', \tx{r}, \gamma''')\end{array}\right\}$
}$//$$\label{code:markend}\{\exists \gamma'''. \p{graph}(\tx x,\gamma''') /| \m{mark}(\gamma, \tx{x}, \gamma''')\}$
\end{lstlisting}

{\footnotesize
\begin{flushleft}
\begin{minipage}[c]{0.5\textwidth}
\begin{equation}
\label{eqn:bigraphintrofoldunfold}
\begin{split}
\quad \p{graph}&(x, \gamma) ~ <=> ~ (x = 0 /| \p{emp}) |/ \null \\
& \exists m,l,r.~ \gamma(x)=(m,l,r) /| x~\mathsf{mod}~16 = 0 /| \null \\
& \qquad ~~ x |-> m,-,l,r ** \p{graph}(l, \gamma) ** \p{graph}(r, \gamma)
\end{split}
\end{equation}
\begin{equation*}
\begin{array}{l@{\hspace{2pt}}c@{\hspace{2pt}}l}
\quad \m{mark1}(\gamma,x,\gamma') & \defeq & \forall \m{v}. \gamma'(v) = \! \begin{cases}
(1,l,r) \! & \begin{array}{@{}l@{}}\text{when } x = \m{v} /| \null \\[-3pt] \gamma(\m{v}) = (0,l,r) \end{array} \\
\gamma(\m{v}) & \text{otherwise}
\end{cases}
\end{array}
\end{equation*}
\end{minipage}
~~ \vline
\begin{minipage}[c]{0.4\textwidth}
\begin{equation*}
\begin{split}
\m{v_1} \accentset{\gamma}{\leadsto}_0 \m{v_2} \defeq \exists l,r.~ \gamma(\m{v}_1) = (0,l,r) /| \m{v}_2 \in \{ l,r\} \\
\m{v_1} \accentset{\gamma}{\leadsto}^{\star}_0 \m{v_2} \defeq \text{reflexive, transitive closure of ``}\mathrel{{\stackrel{\gamma}{\leadsto}}_{0}}\text{''}
\\
\quad \m{mark}(\gamma,x,\gamma') \defeq
\forall \m{v}. \gamma'(\m{v}) = \!
\begin{cases}
(1,l,r) \!
\begin{array}{@{}l@{}}\text{when }
\m{x} \accentset{\gamma}{\leadsto}^{\star}_0 \m{v} /| \null \\[-3pt] \gamma(\m{v}) = (-,l,r)
\end{array}\\
\gamma(\m{v}) \text{otherwise}
\end{cases}
\end{split}
\end{equation*}
\end{minipage}
\end{flushleft}
}

\vspace{-0.4em}
\caption{Clight code and proof sketch for bigraph mark.}
\label{fig:markgraph}
\vspace{-1em}
\end{figure}

\colorlet{red}{stash}
 
We have already seen that allowing existentials in postconditions lets us handle modified program
variables properly.  However, these ``linked existentials''---recall that our previous technique
hinged on the fact that the existential witness to the variable $x_f$ in the local postcondition 
$L_2$ was carried over to the corresponding existential witness in the global postcondition---have
other uses as well.  To illustrate them, and to demonstrate other aspects of our system, in particular our ability to explore a graph recursively via fold/unfold, we consider another example.

In Figure~\ref{fig:markgraph} we put the code and proof sketch of the classic \li{mark} algorithm that visits and colors every reachable node in a heap-represented graph.  The \li{mark} example contrasts from \li{find} in several respects.  First, it modifies the labels of nodes instead of the edges.  Second, each node has two outgoing edges rather than one, so the graph can have a more complex shape.  Third, the graph can be nontrivially cyclic.  Lastly, the specification we certify (lines \ref{code:markstart} and \ref{code:markend}) is \emph{local} rather than \emph{global}:
\vspace*{-1ex}
\[
\{\p{m\_graph}(\li{x},\gamma)\}~\li{mark(x)}~\{\exists \gamma'.~ \p{m\_graph}(\li{x},\gamma') /| \m{mark}(\gamma, \li{x}, \gamma')\}
\vspace*{-1ex}
\]
The specification is again stated with mathematical $\gamma$, although in this case $\gamma(x)$ maps to triples $(m,l,r)$, where $m$ is a ``mark'' bit (0 or 1) and $\{l,r\} \subseteq V(\gamma) \uplus \{\mathtt{null}\}$ are the neighbors of $v$.  By ``local'', we mean that the predicate $\p{m\_graph}(\li{x},\gamma)$ says that the heap represents \emph{only the nodes in $\gamma$ that are reachable from \li{x}}.  Rather than passing the entire graph around as \li{find} does, \li{mark} will use the fold/unfold relationship given in equation~\eqref{eqn:bigraphintrofoldunfold}, located just under the code in Figure~\ref{fig:markgraph}, to ``unfold'' the graph as if it were an inductive predicate.

This fold/unfold relationship deserves attention.
First, \eqref{eqn:bigraphintrofoldunfold} uses the ``overlapping conjunction''~$\ocon$ of separation logic; informally $P ** Q$ means that $P$ and $Q$ may overlap
in the heap (\emph{e.g.}, nodes in the left subgraph can also be in the right subgraph
or even be the root $x$).  The presence of the unspecified sharing indicated by the
$\ocon$ connective\footnote{Recall that the
standard semantics of the separation logic connectives used in this paper are in
Figure~\ref{fig:seplogsem} on page~\pageref{fig:seplogsem}.} is part of why graph-manipulating algorithms are so hard to verify
(\emph{e.g.}, it is hard to apply the \infrulestyle{Frame} rule).
Second, \eqref{eqn:bigraphintrofoldunfold} illustrates how industrial-strength settings complicate verification.  Lines~\mbox{\ref{code:nodedefstart}--\ref{code:nodedefend}} define the data type \li{Node} used by \li{mark}.  The \li{_Alignas($n$)} directives tell CompCert to align fields on $n$-byte boundaries.
As explained in~\S\ref{sec:goodgraph}, this alignment is necessary in C-like memory models to prove fold-unfold \eqref{eqn:bigraphintrofoldunfold}, which is why \eqref{eqn:bigraphintrofoldunfold} includes an alignment restriction $x~\mathsf{mod}~16 = 0$ and an existentially-quantified ``blank'' second field for the root $x \mapsto m,-,l,r$.
(In our Floyd proofs the alignment restriction and blank second field are nicely hidden ``behind the scenes''.)

Just as with \li{find}, the postcondition of \li{mark} is specified \emph{relationally}, \emph{i.e.} $\{\exists \gamma'.~ \p{graph}(\li{x},\gamma') /| \m{mark}(\gamma, \li{x}, \gamma')\}$ instead of \emph{functionally}, \emph{i.e.} $\{\p{graph}\big(\li{x},\m{mark}(\gamma, \li{x})\big)\}$. In the first case $\m{mark}$ is a relation that specifies that~$\gamma'$ is the result of correctly marking~$\gamma$ from~\li{x}, whereas in the second $\m{mark}$ is a function that \textbf{computes} a new graph, which is the result of marking~$\gamma$ from~\li{x}. A relational approach is better for both theoretical and practical reasons.
Theoretically, relations are preferable because they are more general.  For example, relations allow ``inputs'' to have no ``outputs'' (\emph{i.e.} be partial) or alternatively have many outputs (\emph{i.e.} be nondeterministic).  Nondeterminism can be quite useful when specifying programs; for example, the CertiCoq garbage collector (\S\ref{sec:certigc}) is specified nondeterministically to avoid, among other things, specifying how \li{malloc} allocates fresh blocks of memory.  Relations are also preferable to functions because they are more compositional.


Practically, it is painful to define computational functions over graphs in a proof assistant like Coq.  For example, Coq requires that all functions terminate, a nontrivial proof obligation over cyclic structures like graphs, but our verification of \li{mark} is only for partial correctness.  Defining relations is much easier because \emph{e.g.} one can use quantifiers and does not have to prove termination.
The $\m{mark}$ and $\m{mark1}$ relations we use are defined straightforwardly at the bottom of Figure~\ref{fig:markgraph}.

The highlights of the proof are as follows.
In lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}, imagine unfolding the \p{graph} predicate in line~\ref{code:globalbeforerootmark} using equation \eqref{eqn:bigraphintrofoldunfold} and then zooming in to the root node \li{x} for lines~\ref{code:beforerootmark}--\ref{code:afterrootmark}, before zooming back out in line~\ref{code:globalafterrootmark}.
\hide{\color{magenta}Here we upgrade the \infrulestyle{Ramify} rule in two important respects.  The first is the treatment of modified program variables.  Although prosaic, a robust treatment of modified variables is essential to verifying programs of any length.  The second is better handling of existential variables in the postconditions of localization blocks, which occur frequently when using relations in specifications.}
Lines~\ref{code:beforemarkl}--\ref{code:aftermarkl} of Figure~\ref{fig:markgraph} contain an example where we use the power of linked existentials in the \textsc{Localize} rule to ``extract'' the existentially-quantified~$\gamma''$ from inside the localization block to outside it.
The rest of the proof is relatively routine.



\hide{
\subsection{Modified program variables}
\label{sec:freevars}

\infrulestyle{Frame}'s side condition ``$F \text{ ignores } \MV(c)$'' can be defined in two ways.
In the more traditional syntactic style, it means that $\FV(F) \cap \MV(c) = \emptyset$.
By ``syntactic style'' we mean that the side condition is written using a function $\FV(F)$ that takes an arbitrary formula and returns the set of free variables within that formula.  To define this $\FV(F)$ function
we need a fixed inductive \textbf{syntax} for formulas.  In contrast, in this paper we follow a ``semantic style'' in which formulas are not given a fixed syntax in advance but can be defined \textbf{semantically} on the fly using an appropriate model~\cite{appel:programlogics}.  In a semantic style, the side condition on the frame rule is defined as:
\[
\begin{array}{ll}
\sigma \stackrel{S}{\cong} \sigma' & \stackrel{\Delta}{=} ~~ \sigma \text{ and } \sigma' \text{ coincide everywhere except } S\\
P \text{ ignores } S & \stackrel{\Delta}{=} ~~ \forall \sigma, \sigma'.~ \sigma \stackrel{S}{\cong} \sigma' => \big( (\sigma |= P) <=> (\sigma' |= P) \big)
\end{array}
\]
That is, we consider two program states $\sigma$ and $\sigma'$ equivalent up to program variable set~$S$ when they agree everywhere except on the values of $S$ (typically, a state $\sigma$ is a pair of a heap $h$ and program variables $\rho$).  A predicate $P$ ignores~$S$ when its truth is independent of all program variables in $S$.  


Now consider using ramification to verify this program:
\vspace{-1ex}
\begin{lstlisting}
// $\{ \tx{x} = 5 /| A \} \searrow \{\tx{x} = 5 /| B \}$
      ...; x = x + 1; ...;
// $\{ \tx{x} = 6 /| D \} \swarrow \{\tx{x} = 6 /| C \}$
\end{lstlisting}
\vspace{-1ex}
Suppose that other (elided) lines of the program make localization desirable, even though it is overkill for a single assignment.  The key issue is that the program variable {\li{x}} appears in all four positions in the ramification entailment
\vspace{-1ex}
\[
\overbrace{(\li{x} \! = \! 5 /| A)}^{G_1} \vdash \overbrace{(\li{x} \! = \! 5 /| B)}^{L_1} * \big(\overbrace{(\li{x} \! = \! 6 /| C)}^{L_2} --* \overbrace{(\li{x} \! = \! 6 /| D)}^{G_2}\big)
\vspace{-1ex}
\]
One problem is that $L_2 --* G_2$ does \textbf{not} ignore the modified program variable \tx{x}, preventing us from applying \infrulestyle{Ramify}.  Intuitively, the side condition on the \infrulestyle{Ramify} rule is a bit too strong since it prevents us from mentioning variables in the postconditions that have been modified by code $c$.

We could weaken the side condition in \infrulestyle{Ramify} to $\big(\FV(G_2) \cap \MV(c)\big) \subseteq \FV(L_2)$, with the hope that information about modified program variables mentioned in the local postcondition $L_2$ can be carried to the global postcondition $G_2$.  Unfortunately, this idea is unsound because \li{x} cannot simultaneously be both~5 and~6, \emph{i.e.} the above entailment is vacuous.  A better idea is: \[
\inferrule[Ramify-P (Program variables)]
{\{ L_1 \} ~ c ~ \{L_2 \} \\
 G_1 \vdash L_1 * \pguards{c}  (L_2 --* G_2)}
{\{ G_1 \} ~ c ~ \{ G_2 \}}
\]
The ramification entailment now incorporates a new (universal/boxy) modal operator $\pguards{c}$.  The intuitive meaning of $\pguards{c}$ is that program variables modified by command $c$ can change value inside its scope.    Note that it is vital that $L_2$ appears as the antecedent of a (spatial) implication since the change in program variables is universally quantified.  This means that if we want to say anything specific about modified program variables in the global postcondition $G_2$ then we had better say something about them in the local postcondition $L_2$.

Let us return to our earlier entailment:
\[
\begin{array}{l}
(\li{x} = 5 /| A) \vdash (\li{x} = 5 /| B) *
\pguards{\li{...; x = x + 1; ...;}} \big((\li{x} = 6 /| C) --* (\li{x} = 6 /| D)\big)
\end{array}
\]
Since \li{x} is modified, its value can change from the first line, in which \li{x} must be 5, to the second, in which \li{x} must be 6.

Here is the definition of $\pguards{c}$, writing $\langle c \rangle$ for $\MV(c)$:
\vspace{-1ex}
\[
\sigma |= \pguards{c} P ~~ \stackrel{\Delta}{=} ~~ \forall \sigma'.~ (\sigma \stackrel{\langle c \rangle}{\cong} \sigma') => (\sigma' |= P)\vspace{-1ex}
\]
In other words, $\pguards{c}$ is exactly the universal modal operator~$\Box$ over the relation that considers equivalent all states that differ only on program values modified by $c$.  Since $\stackrel{\langle c \rangle}{\cong}$ is an equivalence relation, $\pguards{c}$ forms an S5 modal logic.

Note that \infrulestyle{Ramify-P} has no free variable side condition, which is unnecessary because \\ $\forall P.~ \pguards{c}P \text{ ignores } \MV(c)$. However, in practice this side condition reappears because to actually prove a ramification entailment containing $\pguards{c}$ one typically applies the following \infrulestyle{Solve Ramify-P} rule:
\[
\inferrule[Solve Ramify-P]
{G_1 |- L_1 * F \\ F |- L_2 --* G_2}
{G_1 \vdash L_1 * \pguards{c}  (L_2 --* G_2)}
F \textrm{ ignores } \MV(c)
\]
We can handle the $\pguards{c}$ by breaking apart the single entailment into a pair.  Using two entailments allows modified program variables to change between the preconditions and postconditions\footnote{Entailment procedures for separation logic may prefer to use $F * L_2 |- G_2$ as the second premise of \infrulestyle{Solve Ramify-P} because it is free from $--*$.}.  To connect the pair, we must choose a suitable predicate~$F$ that ignores modified variables in~$c$.

With \infrulestyle{Ramify-P} and \infrulestyle{Solve Ramify-P} we can prove the \infrulestyle{Frame} rule with its canonical side condition as follows:
\vspace{-2ex}
\[
\infrule{}{\raisebox{1.4ex}{$\infrule{}{P * F |- P * F \\ F |- Q --* (Q * F)}
{\raisebox{-4pt}[0pt][0pt]{$P * F |- P * \pguards{c}\big(Q --* (Q * F)\big)$}}
{\hspace{-1.1ex}\raisebox{0.9ex}{$\begin{array}{c}F \textrm{ ignores} \MV(c)\end{array}$}}$}
\\ \{P\}~c~\{Q\}}
{\{P * F\}~c~\{Q * F\}}
{}
\vspace{-2ex}
\]
This justifies our point in \S\ref{sec:localizations} that our new localization notation can also be used for frames.

The choice of $F$ in a concrete setting is delicate. In our example, we replace\footnote{In a semantic setting, substitution is defined with a modal operator and not textual replacement, but the effect is the same.}~\li{x} with~$6$ in $L_2 --* G_2$:
\[
F ~~ \defeq ~~ (6 = 6 /| [\li{x} |-> 6]C) --* (6 = 6 /| [\li{x} |-> 6]D)
\]
The first premise of \infrulestyle{Solve Ramify-P} is
\[
\begin{array} {l}
\li{x} = 5 /| A ~ |- ~ (\li{x} = 5 /| B) * \big((6 = 6 /| [\li{x} |-> 6]C) --* (6 = 6 /| [\li{x} |-> 6]D)\big)
\end{array}
\]
This entailment is the key proof that our localization was sound.  To solve it we first substitute away the remaining program variables (\emph{e.g.} replace \li{x} with 5) to obtain a program-variable-free and modality-free entailment and then apply our ramification library (\S\ref{sec:ramifylib}); as previously explained we sometimes use $\ramify(n)$ to explicitly reference a library lemma.

The second premise, shown below, is a tautology using $(P * Q |- R) <=> (P |- Q --* R)$:
\vspace*{-0.75ex}
\begin{equation}
\label{eqn:sndpremisetauto}
\begin{array}{l}
(6 = 6 /| [\li{x} |-> 6]C) --* (6 = 6 /| [\li{x} |-> 6]D) ~ |- (\li{x} = 6 /| C) --* (\li{x} = 6 /| D)
\end{array}
\vspace*{-0.75ex}
\end{equation}

\iffalse
This strategy is sufficient to handle all of the localization blocks in Figure~\ref{fig:markgraph}.  For example, in lines~\ref{code:markbeforetripleramify}--\ref{code:markaftertripleramify}, choose $F \defeq \null$
\vspace*{-0.75ex}
\[
\begin{array}{@{}l@{}}
\big(\li{x} |-> 1,-,l,r /| \gamma(\li{x}) = (0,l,r) /| \exists \gamma'.~ \m{mark1}(\gamma, \li{x}, \gamma')\big) \\ \null --* \big(\exists \gamma'.~ \p{graph}(\li{x},\gamma') /| \gamma(\li{x}) = (0,l,r) /| \m{mark1}(\gamma, \li{x}, \gamma') \big)
\end{array}
\vspace*{-0.75ex}
\]
Note the use of the metavariables $l$ and $r$ rather than \li{l} and \li{r} in $F$, added to the metacontext in lines~\ref{code:globalbeforerootmarkwithex}--\ref{code:globalbeforerootmark} using Floyd's \infrulestyle{Existential extraction} rule~\cite{floydlogic}:
\vspace*{-0.75ex}
\[
\infrule{Existential extraction}
{\forall x.~ \big(\{ P \} ~ c ~ \{Q \}\big)}
{\{ \exists x. P \} ~ c ~ \{ \exists x.~ Q \}}{}
\vspace*{-0.75ex}
\]
Pen and paper Hoare proofs are often a little casual with existentials, \emph{e.g.} omitting line~\ref{code:globalbeforerootmarkwithex}; we wrote it because we wanted to be clear that the metavariables $l$ and $r$ were properly ``in scope'' over the localization blocks.
\fi



\subsection{Existential quantifiers in postconditions}
\label{sec:existentials}

What happens when we \textbf{cannot} calculate a substitution using globally-scoped metavariables?  Consider the following: \begin{lstlisting}
// $\{ A \} \searrow \{ B \}$
      ...; x = malloc(sizeof(int));
      if (x == 0) then y = 0 else y = 1; ...;
// $\label{toycode:localpost}\swarrow \{ \big((\tx{x} |-> {-} /| \tx{y} = 1) |/ (\tx{x} = 0 /| \tx{y} = 0)\big) * C \}$
// $\label{toycode:globalpost}\{ (\tx{y} = 1 /| D_1) |/  (\tx{y} = 0 /| D_2) \}$
\end{lstlisting}
\vspace*{-1.5ex}
Within a localization block we call the nondeterministically specified function \li{malloc} and use the program variable~\li{y} as a flag to keep track of whether the allocation succeeded.  Call the postconditions in lines~\ref{toycode:localpost} and~\ref{toycode:globalpost} just above $L_2$ and $G_2$. 

Now the choice of $F$ is not very straightforward because we do not know the values to substitute for \li{x} or \li{y}: $[\li{x} |-> ?][\li{y} |-> ?] (L_2 --* G_2)$. \label{eqn:unclearsubst}

\hide{
\vspace*{-1.5ex}
\begin{equation}
\label{eqn:unclearsubst}
[\li{x} |-> ?][\li{y} |-> ?] (L_2 --* G_2)
\vspace*{-1.5ex}
\end{equation}
} 

We proceed as follows.  First, rewrite the postconditions in lines~\ref{toycode:localpost} and~\ref{toycode:globalpost} just above to introduce fresh existentially-quantified  variables $x$ and $y$ and bind them to \li{x} and \li{y}:
\begin{lstlisting}[firstnumber=4]
//   $\;\{ L_2 \}$
// $\label{code:L2p}\swarrow \{\exists x,y. ~ x = \tx{x} /| y = \tx{y} /| [\tx{x} |-> x][\tx{y} |-> y] L_2 \}$
// $\label{code:G2p}\{\exists x,y. ~ x = \tx{x} /| y = \tx{y} /| [\tx{x} |-> x][\tx{y} |-> y] G_2\}$
// $\{ G_2 \}$
\end{lstlisting}
Call these equivalent postconditions $L_2'$ and $G_2'$ (lines~\ref{code:L2p} and
\ref{code:G2p}).




Next apply \infrulestyle{Ramify-P} and \infrulestyle{Solve Ramify-P} with
$F \defeq \forall x, y.~ [\tx{x} |-> x][\tx{y} |-> y](L_2 --* G_2)$.
In other words, replace the ``?'' from the unclear substitution in
\S\ref{eqn:unclearsubst} with universally-quantified metavariables $x$ and $y$ scoped over the entire $--*$.

Now consider the first premise of \infrulestyle{Solve Ramify-P}:
\[
\begin{array}{@{}l|l@{}}
G_1 \! |- \! L_1 \! * \! F & A |- B * \forall x, y.~ [\tx{x} |-> x][\tx{y} |-> y](L_2 --* G_2)
\end{array}
\]
This is essentially the same ramification entailment we had before, and so the general strategy is to apply the ramification library~\S\ref{sec:ramifylib}.  The second premise is more interesting:
\[
\begin{array}{@{}l|l@{}}
F |- & \big(\forall x, y.~ [\tx{x} |-> x][\tx{y} |-> y](L_2 --* G_2) \big) |- \null \\
(L_2' --* & ~~ (\exists x,y.~ x = \tx{x} /| y = \tx{y} /| [\tx{x} |-> x][\tx{y} |-> y] L_2) --* \null \\
G_2') & \quad (\exists x,y. ~ x = \tx{x} /| y = \tx{y} /| [\tx{x} |-> x][\tx{y} |-> y] G_2)
\end{array}
\]
Like equation~\eqref{eqn:sndpremisetauto}, this turns out to also be a tautology, albeit a more complicated one.
Since $L_2$ and $G_2$ are equivalent to $L_2'$ and $G_2'$, we can therefore verify the specification all the way from $A$ to $G_2$ despite the presence of the existentially-quantified modifications to the program variables \li{x} and \li{y}.

We package all of this reasoning into the following rule:
\[
\inferrule[Ramify-PQ (Program variables and Quantifiers)]
{\{ L \} ~ c ~ \{ \exists x.~ L_2 \} \\
 G_1 \vdash L_1 * \pguards{c} \big(\forall x.~ (L_2 --* G_2)\big) }
{\{ G_1 \} ~ c ~ \{ \exists x.~ G_2 \}}
\]
Essentially \infrulestyle{Ramify-PQ} allows us to shift existential variables from the local context to the global one in a smooth way, especially in conjunction with the following rule:
\[
\inferrule[Solve Ramify-PQ]
{G_1 |- L_1 * F \\ F |- \forall x.~ (L_2 --* G_2)}
{G_1 \vdash L_1 * \pguards{c}  \big(\forall x.~ (L_2 --* G_2)\big)}
F \textrm{ ignores} \MV(c)
\]
We were more explicit about existentials in \emph{e.g.} lines~\ref{code:beforemarkl}--\ref{code:aftermarkl} than is typical so that we could prove that we handle them correctly.  Fortified by the \infrulestyle{Ramify-PQ} rule, we could reasonably (albeit less formally) have \emph{e.g.} written line~\ref{code:postmark1} as below, allowing us to omit line~\ref{code:aftermarkl} entirely.
 \begin{lstlisting}[firstnumber=25]
// $\swarrow \{\p{graph}(\tx l, \gamma'') /| \m{mark}(\gamma', \tx{l}, \gamma'')\}$
\end{lstlisting}



Although our technique to handle modified program variables is rather intricate, it is handled mechanically by our \li{localize} and \li{unlocalize} tactics, which use \infrulestyle{Ramify-PQ}.
}

\subsection{Additional verified examples}
\label{sec:application}

In addition to the proof of \texttt{find} shown above, we do a proof of \texttt{union} 
in the same style.  We also do a \emph{second} version of union-find, this time using
arrays rather than \texttt{malloc}-allocated nodes.  The mathematical definitions, 
\emph{e.g.} for $\m{findS}$, are entirely shared, demonstrating that we have 
separated the concerns of abstract algorithmic reasoning from the nitty-gritty details
of heap representation. 

We also have done a version of \texttt{mark} for DAGs (acyclic).  In general, using DAGS 
are both easier and harder than cyclic graphs.  On the one hand, we get genuine separation 
between the root and its children; on the other hand, we need to maintain acyclicity if
we modify the link structure.
As a more aggressive example of modifying the link structure of a graph, we have verified 
\li{spanning}, which prunes a graph into its spanning tree; for space reasons we put
this example in Appendix~A\hide{\ref{apx:spanning}}.
Our flagship example, the CertiCoq garbage collector, will be discussed in~\S\ref{sec:certigc}.



 
\section{A Reusable Library of Formalized Graph Theory}
\label{sec:mathgraph}
\hide{
In order to verify the functional correctness of graph
algorithms, we need to first reason about mathematical graphs.
Our graph library is powerful and expressive, allowing
us to verify realistic algorithms that work in an end-to-end
system. One of its strengths is its modularity,
which allows us to intuitively reuse and compose our proofs when
mechanising our verifications. In this section, we present our
mathematical graph framework with an emphasis on this modularity.
{\color{magenta} We continue to use Union-Find from }
} 

To verify the functional correctness of graph algorithms it is natural
to want to use graph theory to describe
program behavior. As discussed in \S\ref{sec:related},
25 years of research into mechanized graph theory can
be succinctly summarized as ``it is a little tricky''.
Accordingly, an essential component of our
work is a library of formalized graph theory that is actually powerful enough, and
expressive enough, to mechanically verify realistic algorithms written in C.
As will be shown in \S\ref{sec:development}, our mathematical
graph constructions comprise a considerable fraction of our
codebase, so it is vital that our framework be highly modular to
enable reuse of definitions and proofs from one
example to the next. We present our mathematical graph
framework with an emphasis on this modularity.

\hide{\color{magenta} We continue to use Union-Find from
\S\ref{sec:orientation} as our motivating example.} 

\hide{As will be shown in \S\ref{sec:development}, our mathematical
graph constructions comprise a considerable fraction of our
codebase. Indeed, as discussed in \S\ref{sec:related},
25 years of research into mechanized graph theory can
be summarized as ``it is a little tricky''.
First, as demonstrated in \S\ref{sec:orientation},
our development is expressive and powerful enough to verify realistic
algorithms---that is, it actually works in an end-to-end system.
Second, we have taken considerable care to develop a modular and
general-purpose framework for such mathematical graphs to allow
such verifications to be mechanized without undue pain.
Accordingly, in this section we will present our framework
at a high level to communicate the overall architecture rather
than focusing on the nitty-gritty details.} 

\subsection{Definitions of graphs}\label{sec:mathinfra}



\begin{adjustbox}{scale=0.80}	
  \begin{minipage}[t]{0.68\textwidth}
  \centering
  % \beginpgfgraphicnamed{variousgraph}
\begin{tikzpicture}
[->/.style={thick,arrows={-Stealth}},
-->/.style={thick,arrows={-Stealth}, decorate, decoration={snake, amplitude=.4mm,segment length=2mm,post length=2mm}},
   realG/.style={shape=rectangle, rounded corners=4pt, draw, fill=gray!40},
   propG/.style={shape=rectangle, rounded corners=4pt, draw}]
\node[realG] (PG) at (0, 0) {\small PreGraph};
\node[realG] (LG) [right=0.8 of PG] {\small LabeledGraph};
\node[realG] (GG) [right=2 of LG] {\small GeneralGraph};
\draw [double, ->] (PG) -- (LG) node [pos=0.5, above] {\small Label} ;
\draw [double, ->] (LG) -- (GG) node (SC) [pos=0.5, above, align=center]
{\small Soundness \\ \small Condition};
\node[propG] (Prop) [below=0.6 of SC] {\small Property};
\node[propG] (PropL) [below=0.4 of Prop] {\small Property Lemmas};
\node[propG] (PGL) [below=2 of PG, align=center] {\small PreGraph \\\small Lemmas};
\node[propG] (LGL) [below=2 of LG, align=center] {\small LabeledGraph \\\small Lemmas};
\node[propG] (GGL) [below=2 of GG, align=center] {\small GeneralGraph \\\small Lemmas};
\draw [double, ->] (PGL) to (LGL);
\draw [->] (PG) to (PGL);
\draw [->] (Prop) to (PropL);
\draw [-->] (Prop) to (SC);
\coordinate [left=0.2 of LG.south] (LGs1);
\coordinate [left=0.2 of LGL.north] (LGLn1);
\draw [->] (LGs1) to (LGLn1);
\coordinate [right=0.2 of LG.south] (LGs2);
\coordinate [right=0.2 of LGL.north] (LGLn2);
\draw [->] (LGs2) |- (Prop);
\draw [double, ->] (LGLn2) |- (PropL);
\coordinate [right=0.2 of GG.south] (GGs);
\coordinate [left=0.2 of GGL.north] (GGLn1);
\coordinate [right=0.2 of GGL.north] (GGLn2);
\draw [double, ->] (PropL) -| (GGLn1);
\draw [->] (GGs) to (GGLn2);
\node [draw=red, thick, rectangle, dashed, fit=(Prop) (PropL)] {};
\node (legend1) [below right=0.2 and -0.3 of PGL] {\small Depends};
\coordinate[left=0.8 of legend1]  (l1);
\draw [->] (l1) to (legend1);
\node (legend2) [right=1 of legend1] {\small Inherits};
\coordinate[left=0.8 of legend2]  (l2);
\draw [double, ->] (l2) to (legend2);
\node (legend3) [right=1 of legend2] {\small Instantializes};
\coordinate[left=0.8 of legend3]  (l3);
\draw [-->] (l3) to (legend3);
\end{tikzpicture}
% \endpgfgraphicnamed
\vspace{1ex}
\captionof{figure}{Structure of the Mathematical Graph Library}\label{fig:graphs}
\end{minipage}
  ~
  \begin{minipage}[t]{0.52\textwidth}
\centering
% \beginpgfgraphicnamed{pregraphexp}
\begin{tikzpicture}
[vad/.style={circle, fill=black, inner sep=0pt, minimum size=4pt},
 inv/.style={circle, draw=red, thick, inner sep=0pt, minimum size=4pt},
 ->/.style={thick, arrows={-Stealth}}]
\node[vad] (n1) at (0, 0) {};
\node at (1, 1.3) {$\m{v}_1$}; \node[inv] (n2) at (1, 1) {};
\node[inv] (n3) at (1, -1) {}; \node at (-2,2.25) {$\m{v}_0$}; \node[vad] (n4) at (-2,2) {}; 
\node[inv] (n5) at (-2,-2) {};
\node[vad] (n6) at (-1.7,0) {};
\node[inv] (n7) at (2.5,1.8) {};
\node[inv] (n8) at (3,-1.5) {};
\draw[->] (n1) to (n2);
\draw[->] (n1) to (n3);
\draw[->,dashed,red] (n3) to (n5);
\draw[->,dashed,red] (n2) to (n3);
\draw[->,dashed,red] (n2) to (n7);
\draw[->,dashed,red] (n2) to (n8);
\draw[->,dashed,red] (n3) to (n8);
\draw[->] (n4) to (n1);
\draw[->] (n1) to (n5);
\draw[->] (n4) to [bend left=20] (n2);
\draw[->] (n1) to [bend left=20] (n6);
\draw[->] (n6) to (n5);
\draw[->,dashed,red] (n8) to (n7);
\draw[->] (n4) to [bend right=35] (n1);
\node at (-0.6, 1.7) {$\m{e}$};
\node[vad] (n9) at (3.6, 1) {};
\node[inv] (n10) at (3.6, 0.5) {};
\draw[->] (3.4, 0) -- (4, 0);
\draw[->,dashed,red] (3.4, -0.5) -- (4, -0.5);
\node at (3.9, 1) [right=1.5pt] {\small Valid vertex};
\node at (3.9, 0.5) [right=1.5pt] {\small Invalid vertex};
\node at (3.9, 0) [right=1.5pt] {\small Valid edge};
\node at (3.9, -0.5) [right=1.5pt] {\small Invalid edge};

\end{tikzpicture}
% \endpgfgraphicnamed
\vspace{1ex}
\captionof{figure}{A PreGraph with valid/invalid vertices and edges.}\label{fig:pregraph}
\end{minipage}
\end{adjustbox}
 \begin{figure}
	\begin{gather*}
     	\begin{aligned}
    	\mathrm{path} \; \defeq \; &(\m{v}_0, [e_0, e_1, \dots, e_k]) \\ 
    	\mathtt{s\_evalid}(\gamma, e) \; \defeq \; & \mathtt{E}_{\gamma}(e) /| 
    	\mathtt{V}_{\gamma}(\mathtt{src}_{\gamma}(e)) /| 
    	\mathtt{V}_{\gamma}(\mathtt{dst}_{\gamma}(e)) \\
		\mathtt{valid\_path}\big(\gamma, (\m{v},[])\big) \;\defeq \; & \mathtt{V}_{\gamma}(\m{v})\\
		\mathtt{valid\_path}\big(\gamma, (\m{v},[e_1,e_2,\dots,e_n])\big) \; \defeq \; &\m{v}=\mathtt{src}_{\gamma}(e_1) \wedge \mathtt{s\_evalid}(\gamma,e_1) \wedge \null \\
    &\mathtt{dst}_{\gamma}(e_1)=\mathtt{src}_{\gamma}(e_2) \wedge \null\\
    &\mathtt{s\_evalid}(\gamma, e_2) \wedge \dots /| \mathtt{dst}_{\gamma}(e_{n-1})=\mathtt{src}_{\gamma}(e_n) \\ 
        \mathtt{end}\big(\gamma, (\m{v}, [])\big)\;\defeq\;& \m{v}\\
      	\mathtt{end}\big(\gamma, (\m{v},[e_1,e_2,\dots,e_n])\big)\;\defeq\;&
      	\mathtt{dst}_{\gamma}(e_{n})\\
      	\gamma \vDash s \overset{\m{p}}{\leadsto} t \;\defeq\; &
        \mathtt{valid\_path}(\gamma, p)\wedge
        \mathtt{fst}(p)=s \wedge \mathtt{end}(\gamma,p)=t \\
        \gamma_1 \cong \gamma_2 \; \defeq \; & 
        	\forall e.~\mathtt{E}_{\gamma_1}(e) <=> \mathtt{E}_{\gamma_2}(e) /| \forall \m{v}.~\mathtt{V}_{\gamma_1}(\m{v}) <=> \mathtt{V}_{\gamma_1}(\m{v}) /| \null \\
        	&\forall e.~\mathtt{E}_{\gamma_1}(e) ==> \mathtt{src}_{\gamma_1}(e) = \mathtt{src}_{\gamma_2}(e) /| \mathtt{dst}_{\gamma_1}(e) = \mathtt{dst}_{\gamma_2}(e) \\
       	\gamma \smallsetminus S \; \defeq \; 
       	 	&{\mathcal{V}}_{\gamma'} = {\mathcal{V}}_{\gamma} /| 
          {\mathcal{E}}_{\gamma'} = {\mathcal{E}}_{\gamma} /| \null \\
          &{\mathtt{src}}_{\gamma'} = {\mathtt{src}}_{\gamma} /|
          {\mathtt{dst}}_{\gamma'} = {\mathtt{dst}}_{\gamma} /| \null \\
       	 	&\gamma'_{\mathtt{V}} = \Big(\lambda x.~ \gamma_{\mathtt{V}}(x) /| \lnot S_{\mathtt{V}}(x)\Big) /| \null \\ 
       	 	&\gamma'_{\mathtt{E}} = \Big(\lambda x.~ \gamma_{\mathtt{E}}(x) /| \lnot S_{\mathtt{E}}(x)\Big)\\
\mathrm{MathGraph}(\gamma)\,\defeq\,\Big\{
          \mathtt{null}:\; & V\\ 
          \mathtt{valid\_graph}:\;& \forall e\,.\,\mathtt{evalid}(\gamma, e) \Rightarrow
          \mathtt{vvalid}\big(\gamma, \mathtt{src}(\gamma, e)\big)\wedge \null \\
          & \qquad \big(\m{e} = \mathtt{null} \vee \mathtt{vvalid}(\gamma, \m{e})\big)\\
          \mathtt{valid\_not\_null}:\;& \forall \m{v}\,.\,\mathtt{vvalid}(\gamma, \m{v})
          \Rightarrow \m{v} \neq \mathtt{null} \Big\} \\
        \mathrm{LstGraph}(\gamma)\,\defeq\, \Big\{
          \mathtt{out}:\; & V \rightarrow E\\
          \mathtt{only\_one\_edge}:\; & \forall \m{v},\,e\,.\,
          \mathtt{vvalid}(\gamma, \m{v}) \Rightarrow \\
          & \Big(\mathtt{src}(\gamma, e) =\m{v} \wedge
          \mathtt{evalid}(\gamma, e)\Big) \Leftrightarrow
          e = \mathtt{out}(\m{v})\\
         \mathtt{acyclic\_path}:\; & \forall \m{v},\,p\,.\,
         \gamma \vDash \m{v} \overset{p}{\leadsto} \m{v} \Rightarrow p = (\m{v},[])\Big\} \\
       	\mathrm{FiniteGraph}(\gamma)\,\defeq\, \Big\{
          \mathtt{finite\_\m{v}}:\;&\exists\, S_\m{v},\, M_\m{v}\;\text{s.t.}\;\lvert S_\m{v}\rvert
          \leq M_\m{v} \wedge
          \forall \m{v}\,.\, \mathtt{vvalid}(\gamma,\m{v})\Rightarrow \m{v}\,\in\,S_\m{v}\\
          \mathtt{finite\_e}:\;&\exists\, S_e,\, M_e\;\text{s.t.}\;\lvert S_e\rvert
          \leq M_e \wedge
          \forall e\,.\, \mathtt{evalid}(\gamma,e)\Rightarrow e\,\in\,S_e \Big\}
    	\end{aligned}
    \end{gather*}
\caption{Some Graph definitions}
\label{fig:graphdefns}
\vspace{-1em}
\end{figure} 
Our first challenge is that graph theory is usually based on
\emph{set theory} but our formalization in Coq is
based on \emph{type theory}. We choose to formalize graph theory
directly in Coq instead of formalizing set theory and then building
graph theory atop it to take advantage of Coq's built-in
support for type-related constructions.
To balance the dichotomy between
the generality and the speciality of the library, we divide the
concept of graph into three structures,
PreGraph, LabeledGraph and GeneralGraph, arranged in a hierarchy.
Figure~\ref{fig:graphs} shows the
architecture of the library.

\hide{The most basic kind of graph is PreGraph, out of which we build
LabeledGraph, and which in turn are used
to build GeneralGraphs. Each kind has some lemmas and also inherits the lemmas of the
previous kind.  The dashed box represents a ``plugin'' system for attaching arbitrary
properties to LabeledGraphs (\ref{subsec:graphplugins}). } 

\paragraph{PreGraph.}
A PreGraph is a hextuple $(\mathcal{V}, \mathcal{E}, \mathtt{V}, \mathtt{E}, \mathtt{src}, \mathtt{dst})$.  $\mathcal{V}$ and $\mathcal{E}$ are the underlying
carrier types of vertices and edges.  $\mathtt{V}$ and $\mathtt{E}$ are predicates over
$\mathcal{V}$ and $\mathcal{E}$ that specify the notion
of \emph{validity} in the graph.  Finally, $\mathtt{src}$ and $\mathtt{dst}$ map each edge to
its source and destination.


The benefits of introducing validity are twofold. The first is a
neat resolution of the incompatibility between type theory and set theory.
In set theory, one
element can belong to multiple sets, and
adding or removing vertices or edges is as easy as altering
the set directly to represent the result of the operation.
In type theory, however, a term can only belong
to one type, which makes it difficult\hide{if not impossible}
to analogously change the
type to represent the result. As is common practice, the
predicates $\mathtt{V}$ and $\mathtt{E}$ specify whether a vertex/edge is \emph{valid}
(in the graph) or \emph{invalid} (out). Adding or removing vertices/edges
is as simple as weakening or strengthening these two predicates.

The second benefit is the ability to represent incomplete graphs.
Consider starting from a graph $\gamma$ and then removing a subgraph; the remaining
``doughnut'' structure is \textbf{not} necessarily a graph, since there may be dangling
edges pointing into the ``hole''.  Figure \ref{fig:pregraph} shows just such a situation,
where a connected graph (everything is reachable from $\m{v}_0$) has had the connected
subgraph reachable from $\m{v}_1$ removed; \emph{e.g.}, the edge $e$ is dangling.
The last conjunct in the $\m{findS}$ relation from Figure~\ref{fig:find} is an example
of where a real verification needs to reason about just such a doughnut, in particular
to specify that the unreachable portion of a graph has not changed.


\hide{an incomplete graph,
where vertices $v_0$ and $v_1$
are the source and destination of a valid edge $e_0$. Both
vertices are in $\mathcal{V}$, but $v_0$ is valid
and $v_1$ is not, meaning $v_1$ is not in the
graph. Drawing $v_1$ in Figure \ref{fig:pregraph} only indicates
that $d(e_0) = v_1$.
Incomplete graphs of this sort are needed, \emph{e.g.}, by programs
that traverse selective portions of graphs and manipulate them under
certain criteria.
After the traversal, the graph $g$ can be partitioned into two parts: the subgraph
$g_1$, which is composed of vertices and edges processed by the algorithm,
and the residue $g_2$, which is the difference $g - g_1$. In
the specification of the program, it may be necessary to state that
$g_2$ is unchanged. However, $g_2$ is not guaranteed to be a ``well-formed''
graph in the conventional sense:
if $g$ is an undirected graph,
$g_2$ is just a collection of \note[disconnected?]{connected} components,
and if $g$ is a directed graph, then $g_2$ may contain dangling edges or
vertices. PreGraph is accommodating enough to permit reasoning
about~$g_2$ in either case.}

We define many fundamental graph concepts on PreGraphs,
including structures like \emph{path}$^{*}$, predicates
such as \emph{is\_cyclic} and \emph{reachable}$^{*}$,
operations such as \emph{add\_vertex}
and \emph{remove\_edge}, and relations between PreGraphs such
as \emph{structurally\_identical}$^{*}$ and \emph{subgraph}.
Definitions of the concepts marked with asterisks are
shown in Figure \ref{fig:graphdefns} to give a flavor
of the subtleties involved in getting definitions that
really work.
These general concepts, together with around 500 derived lemmas,
provide a
solid foundation for more specific theorems needed in concrete
verifications.

\hide{
In {\color{magenta}Figure \ref{fig:pregraph}}, valid vertices satisfy
$V$ and invalid vertices are just of type $VT$ but do not satisfy
$V$. Importantly, both kinds of vertices are legally part of the
PreGraph. Finally, $s$ and $d$ are functions that map an edge to its
source and destination respectively; {\color{orange}this means that
PreGraphs model directed graphs.}  With an eye to flexibility, we make
no further requirements of a legal PreGraph, not even a specific
notion of how the four sets are related.  Indeed, the PreGraph in
Figure \ref{fig:pregraph} contains invalid vertices and edges in an
arbitrary configuration.

Many graph concepts such as \emph{path}, \emph{reachability}, and \emph{subgraph} are
defined on PreGraphs. In \S\ref{fig:find} we saw \emph{reachable}, written
{\color{orange}
$\m{a} \mathrel{{\stackrel{\gamma~}{\leadsto^{1}}}} \m{b}$. It means that a and b are in $V(\gamma)$ and that there exists an edge (in $E(\gamma)$)
that goes from a to b.}
The reflexive, transitive closure on \emph{reachable} is written
$\m{a} \accentset{\gamma}{\leadsto}^{\star} \m{b}$, and
$\neg (\m{a} \accentset{\gamma}{\leadsto}^{\star} \m{b})$
is written
$\m{a} \accentset{\gamma}{\not\leadsto}^{\star} \m{b}$
$\m{a} \mathrel{{\stackrel{\gamma~}{\not\leadsto^{\star}}}} \m{b}$.

PreGraph's ability to reason about missing vertices and edges is convenient when
verifying real programs. Suppose some $\gamma$ satisfied some stronger notion of
``well-formed'', in the sense that valid vertices have only valid edges and
vice versa. Could we then subtract some vertices and edges from it and reason about the
resulting structure? This is precisely what we needed to do in \ref{fig:find}, where
we argued for a condition of congruence on
$\gamma \smallsetminus (v \in \gamma \mid \m{x}
\mathrel{{\stackrel{\gamma~}{\leadsto^{\star}}}} \m{v})$.
A strong notion of well-formedness may have stopped us short at this point,
declaring the structure ill-formed because of the dangling edges
pointing to recently-removed vertices.
A PreGraph is more accommodating, since
it produces a fresh PreGraph after this selective subtraction
and then allows us to go ahead and reason about congruence as we need to.
}

\hide{
For example, consider the difference of two graphs, $\gamma_1
- \gamma_2$.  Even if both of these graphs are ``well-formed'' to begin with, in the
sense that valid vertices have only valid edges and vice versa, their difference
may not be since there may be dangling edges pointing to the
now-removed vertices of $\gamma_2$.} 

\hide
{In \S\ref{sec:spacegraph} we will tie a mathematical graph $\gamma$ to
a spatial graph predicate
$\p{graph}(x, \gamma)$.   As we will see, a $\p{graph}$ ``owns'' only the
spatial portion of $\gamma$ that is reachable
from $x$ even though $\gamma$ may have other valid vertices.
} 




\vspace{-0.75ex}

\paragraph{LabeledGraph.}
A LabeledGraph is septuple $(\mathrm{PreGraph},\ma{L_{V}},\ma{L_{E}},\ma{L_{G}}, \mathtt{vl},\mathtt{el},\mathtt{gl})$ that augments a PreGraph with \emph{labels} on
vertices, edges, and/or the graph as a whole. $\ma{L_{V}}$, $\ma{L_{E}}$, and $\ma{L_{G}}$
are the associated carrier types; $\mathtt{vl}$, $\mathtt{el}$, and $\mathtt{gl}$
are the labeling functions themselves.
The need for such labels is that many classic graph problems from union-find (node ranks)
to Dijkstra (edge weights) require them.  The need for a label on the graph as a whole
is a little more subtle; in \S\ref{sec:certigc} we use one in the garbage collector
to keep track of \emph{e.g.} the number of generations and their boundaries.
Since LabeledGraph is built on PreGraph, it inherits all PreGraph lemmas via
Coq's \emph{type coercion} mechanism, while enabling additional lemmas involving labels.



\hide{\paragraph{LabeledGraph.}
A LabeledGraph is a PreGraph with the addition of \emph{labels} on
vertices, edges, and/or the graph as a whole. The need for such labels
is fairly clear; the bare structure of a graph can only
contain so much information, and many classic graph problems
such as graph coloring, shortest path, and network flow rely on
additional information in the form of labels. In our architecture, a
LabeledGraph inherits any lemmas proved about its associated PreGraph.
In addition, we can define additional lemmas that use labels,
\emph{e.g.} the union-find graph has an integer label denoting \emph{rank}.
We could prove a lemma that running \texttt{find} does not alter
any vertex's rank.
\hide{add string labels to edges and reason about a trie.}}




\vspace{-0.75ex}
\paragraph{GeneralGraph.}
PreGraphs and LabeledGraphs let us state
and prove many useful lemmas that follow essentially by the nature
of our graph constructions. However, when proving the correctness of graph
algorithms, we often need more specificity in our mathematical graphs
so that we may model the real program's behaviors closely.
For example, the \p{uf\_graph} used in \texttt{find}
restricted each vertex to having exactly one out-edge.
On the other hand, these restrictions vary greatly by algorithm, so we do not
want to bake them into our core definitions.
We achieve this flexibility using GeneralGraphs, which augment
LabeledGraphs by adding arbitrarily complex ``soundness conditions'', indicated in
Figure~\ref{fig:graphs} with a dashed border.
Further, the type coercion we described earlier continues to apply,
meaning that a GeneralGraph can seamlessly behave like a
LabeledGraph or a PreGraph, thereby inheriting their lemmas.
This combination of specificity and generality is
what makes GeneralGraphs versatile. Moreover, we can
compose complicated soundness conditions from reusable pieces,
further enabling code sharing between algorithms.







\subsection{Composing soundness plugins}
\label{subsec:graphplugins}

\hide{Our entire library of formal
graph theory is developed around the
three graph structures above. The theorems about the first two
are universal, while some theorems about GeneralGraph
are developed on demand because soundness conditions vary by
algorithm.}
Soundness conditions are often specific to each algorithm, but they feature some recurring themes.
We take advantage of this pattern by developing \emph{soundness plugins}, \emph{i.e.} definitions of soundness
conditions along with related lemmas.  By combining these plugins
we can describe the soundness condition we need for a particular
algorithm.  When proving lemmas about the resulting combination,
we can use known facts about the separate plugins, in addition to
lemmas that emerge due to the various combinations.  This complexity
is managed smoothly by Coq's typeclass system, increasing the
compositionality of the system.
Consider the following oft-used graph properties:

\begin{itemize}
\vspace{-1ex}
\item $\p{MathGraph}^{*}$: all valid edges must have a valid source vertex; the destination
vertex must either be valid or be a special invalid node called \p{null}
\item $\p{FiniteGraph}^{*}$: the sets of valid vertices and edges are both finite
\hide{More subtly, consider that many real data structures use special null values to
represent unused nodes.  The  property introduces this concept---
\emph{i.e.} some special invalid nodes are allowed to appear as
destinations for valid edges.} \item $\p{LstGraph}^{*}$: the graph is list-like: each vertex has only one outgoing edge; no nontrivial loops
\item \p{BiGraph}: there are exactly two outgoing edges per node
\end{itemize}
Definitions of the concepts marked with asterisks are
shown in Figure~\ref{fig:graphdefns} for illustration.

\hide{As a first step, we can prove many general, reusable lemmas
about these properties. However, these properties are still
too general to model a real program. The next step is to compose
these plugins to arrive at a more specific set of restrictions
that more closely models our particular graph.}
We can compose
\p{LstGraph}, \p{MathGraph}, and \p{FiniteGraph}
together into a new plugin called \p{LiMaFin}, which, incidentally, is
the soundness condition of mathematical \p{uf\_graph}
we used to verify \texttt{find} in
Figure~\ref{fig:find}.  In our verification of \texttt{mark} in
Figure~\ref{fig:markgraph}, we use a similar soundness condition
\p{BiMaFin}, which uses \p{BiGraph} instead of \p{LstGraph}.
The commonalities and differences between \p{LiMaFin}
and \p{BiMaFin} are readily apparent from their construction.


\iffalse
\marginpar{\tiny \color{blue} Maybe move this somewhere.}
{\color{magenta}Coq also handles our notion of inherited
lemmas seamlessly: in our verfication of Find, we
work directly with a \p{LiMaFin} GeneralGraph, but, as
we saw, we still use properties such as reachability
and operations such as selective subtraction, which are defined on the
embedded PreGraph, not the GeneralGraph.
Coq handles the appropriate coercions with
remarkable elegance.}
\fi

\iffalse
\subsection{Reasoning about relations between graphs} 

\marginpar{\color{blue} \tiny Needs revised examples based on new Orientation.}

{\color{magenta} In Figure~\ref{fig:markgraph} we defined the relation
$\m{mark}(\gamma, \tx x, \gamma')$
for the graph marking algorithm.  Similarly, we define $\m{span}$ for the
spanning tree program
and $\m{copy}$ for the graph copy program.
These relations all capture how the graph has changed from before to after the program
execution.  By specifying $\m{copy}$ relationally
rather than functionally we avoid explicitly modeling how the memory
allocator works, a major advantage.

As previously mentioned, we reuse $\m{mark}$ and its
related lemmas to prove facts about spanning tree and graph copy
because the latter two programs mark nodes as they work.
Accordingly, we can reuse facts such as the following:
\[
\begin{array}{@{}l@{}}
\text{if } \gamma(x)=(0, v_1, \dots,v_n), \m{mark1}(\gamma, x, \gamma_1),
\text{ and } \forall i, \m{mark}(\gamma_i,v_i,\gamma_{i+1}) \text{ then } \m{mark}(\gamma,x,\gamma_{n+1}).
\end{array}
\]
}
\fi
 
\section{Defining and reasoning about spatial graphs}
\label{sec:spacegraph}
\begin{figure}
\[
\begin{array}{lcl}
\sigma |= P * Q & \defeq & \exists \sigma_1, \sigma_2.~ (\sigma_1 \oplus \sigma_2 = \sigma) /| (\sigma_1 |= P) /| (\sigma_2 |= 2)\\
\sigma |= P --* Q & \defeq & \forall \sigma_1, \sigma_2.~ (\sigma_1 \oplus \sigma = \sigma_2) /| (\sigma_1 |= P) => (\sigma_2 |= Q) \\
\sigma |= P --o Q & \defeq & \exists \sigma_1, \sigma_2.~ (\sigma_1 \oplus \sigma = \sigma_2) /| (\sigma_1 |= P) /| (\sigma_2 |= Q) \\
\sigma |= P ** Q & \defeq & \exists \sigma_1, \sigma_2, \sigma_3.~ (\sigma_1 \oplus \sigma_2 \oplus \sigma_3 = \sigma) /| (\sigma_1 \oplus \sigma_2 |= P) /| (\sigma_2 \oplus \sigma_3 |= Q)
\end{array}
\]
\caption{Separation logic connectives; $\oplus$ is the join operation on states, \emph{e.g.} a disjoint union on heaps}
\label{fig:seplogsem}
\vspace*{-1em}
\end{figure}  
To prove the functional correctness of graph-manipulating algorithms implemented in a real language, we need to connect the heap representation of graphs, the memory model of the programming language, and the mathematical properties of graphs from \S\ref{sec:mathgraph}.  The first of these turns out to be surprisingly subtle as we shall see in \S\ref{sec:fixpointfail} and \S\ref{sec:goodgraph}.  The main challenge for the others is to engineer a framework that is generic enough and modular enough to be useful in practice in a variety of settings; we cover it in~\S\ref{sec:ramifylib}.

\subsection{Recursive definitions yield poor \p{graph} predicates}\label{sec:fixpointfail}

\newcommand{\graphkt}{\p{graph}_T}
\newcommand{\grapham}{\p{graph}_A}


Recursive predicates are ubiquitous in separation logic---so
much so that when one writes the definition of a predicate as
\mbox{$P$ ``$\defeq$'' $\ldots P \! \ldots$}, no one raises an eyebrow despite the
dangers of circularity in mathematics. Indeed, the vast majority of the time there
is no danger thanks to the magic of the Knaster-Tarski fixpoint
$\mu_{\mathsf{T}}$ \cite{tarski:fixpoint}.  Formally, one does not define $P$ directly,
but rather defines a functional
\mbox{$F_P \defeq \lambda P.~ \ldots P \! \ldots$} and then defines $P$ itself as
\mbox{$P \defeq \mu_{\mathsf{T}} \, F_P$}.
Assuming, as one typically does without comment,
that $F_P$ is \emph{covariant}, i.e. $(P \vdash Q)
\Rightarrow (F \, P \vdash F \, Q)$, one then enjoys the fixpoint
equation $P \Leftrightarrow \ldots P \ldots$, formally justifying
the typically-written pseudodefinition (``$\defeq$'').



Suppose we define a graph predicate $\graphkt$ this way, \emph{e.g.} along the lines of the fold/unfold definition in Figure~\ref{fig:markgraph}: \vspace{-1ex}
\[
\begin{array}{@{}l@{}l@{}}
\graphkt(x, \gamma) \stackrel{\Delta}{=} \; &\Big(x = 0 /| \p{emp}\Big) |/ \\
&\quad \Big(\exists m,l,r.~ \gamma(x)=(m,l,r) /|
\big(x |-> m,l,r ** \graphkt(l, \gamma) ** \graphkt(r, \gamma)\big)\Big)
\end{array}
\vspace{-1ex}
\]
Although we can apply Knaster-Tarski (because the functional needed to
define $\graphkt$ is covariant), the result is hard to use.
Consider the following memory $m$ for a toy machine:


\begin{wrapfigure}{r}{.39\textwidth}
\vspace{-2em} \begin{minipage}{.20\textwidth}
\qquad \[
\begin{array}{c|c}
\textrm{address} & \textrm{value} \\
\hline
102 & 0 \\
101 & 100 \\
100 & 42 \\
\end{array}
\]
\end{minipage}
\begin{minipage}{.19\textwidth}
\centering
% \beginpgfgraphicnamed{selfref}
\begin{tikzpicture}
[->/.style={thick,arrows={-Stealth}},
   propG/.style={shape=circle, draw}]
   \path[use as bounding box] (-1, -1) rectangle (0.5, 0.5);
   \node[propG] (P) at (0, 0) {42};
   \draw[->] (P.west) .. controls (-1.5, 0) and (0, -1.5) .. (P.south);
\end{tikzpicture}
% \endpgfgraphicnamed
\end{minipage}
\vspace{-0.5em} \end{wrapfigure}

\noindent Clearly $m |= 100 |-> 42,100,0$.  But it seems also clear that this memory represents a one-cell cyclic graph as illustrated in the accompanying diagram, \emph{i.e.} we want $m |= \graphkt(100,\hat{\gamma})$, where $\hat{\gamma}(100) = (42,100,0)$.  This is equivalent to wanting to be able to prove $100~|->~42,100,0~|-~\graphkt(100,\hat{\gamma})$.  Unfortunately, as explained in Appendix~C\hide{\ref{apx:problemrecgraph}}, this is rather difficult to do since applying the natural proof techniques actually strengthens the goal. In fact we do not know if this entailment is provable, but the difficulties encountered in proving what ``should be'' straightforward suggest that Knaster-Tarski should be treated with caution when defining spatial predicates for graphs.

The other direction, \mbox{$\graphkt(100,\hat{\gamma}) |- 100 |-> 42,100,0$},
\textbf{is} true but is not easy to prove, relying on the constructions in \S\ref{sec:goodgraph} and the fact that $\mu_{\mathsf{T}}$ constructs the least fixpoint.  In contrast, $\graphkt(100,\hat{\gamma}) |- 100 |-> 42,100,0 * \top$ is easy. 












\subsection{Defining a good \p{graph} predicate}\label{sec:goodgraph}

Rather than trying to define \p{graph} as a recursive fixpoint,
we will instead give it a flat structure.  Graphs in separation
logic have been defined in similar ways before, \emph{e.g.}~\cite{ilya-graphs};
our innovation is that we prove---with the amount of precision
required to convince Coq---that we can still enjoy fold/unfold
with our flat definition.  Our path starts with the iterated
separating conjunction or ``big star'', which is first defined over
lists and then extended to sets as follows:

\vspace{-1em}
\[
\begin{array}{@{}l@{}}
\underset{\{l_1, l_2,\dots,l_n\}}{\bigstar}P ~~ \defeq ~~ P(l_1) *
  P(l_2) * \dots * P(l_n) \quad \vline \quad
\underset{S}{\bigstar} P ~~ \defeq ~~ \exists L.~ (\p{NoDup}\ L) /| (\forall x.~ x\ \p{in}\ L <=> x \in S) /| \underset{L}{\bigstar}P
\end{array}
\]

We are now ready to define a good \p{graph} predicate:
  \quad $\p{graph}(x, \gamma) \; \defeq \; \underset{v \in \mathit{reach}(\gamma, x)}{\bigstar} v\mapsto\gamma(v)$
\iffalse
\begin{equation*}
  \underset{\{l_1, l_2,\dots,l_n\}}{\bigstar}P ~~ \defeq ~~ P(l_1) *
  P(l_2) * \dots * P(l_n).
\end{equation*}
Formally $\bigstar$ is defined over a list rather than a set and is parameterized by a predicate $P$.  It is natural to extend $\bigstar$ to a set $S$ with an existentially-quantified duplicate-free list~$L$:
\[
\underset{S}{\bigstar} P ~~ \defeq ~~ \exists L.~ (\p{NoDup}\ L) /| (\forall x.~ x\ \p{in}\ L <=> x \in S) /| \underset{L}{\bigstar}P
\]
We use the same $\bigstar$ notation since the concepts are similar, but the existential adds a little pain since we need to prove that all choices of $L$ yield equivalent predicates.

We are now ready to give a good \p{graph} predicate:
\fi


\hide{ \vspace{-1.5ex}
\begin{equation}\label{eqn:iter_def}
  \p{graph}(x, \gamma) ~~ \defeq ~~ \underset{v \in \mathit{reach}(\gamma, x)}{\bigstar} v\mapsto\gamma(v)
\vspace{-1.5ex}
\end{equation}
$\gamma$ is a GeneralGraph and ``$x |-> \gamma(x)$'' is a predicate that says how a single node fits in memory. In Figure~\ref{fig:markgraph} it was:
\[
\exists m,l,r.~\gamma(x) = (m,l,r) /| x |-> m,-,l,r /| x\ \p{mod}\ 16 = 0
\]}
The graph $\gamma$ here need not be a bigraph, but \emph{e.g.} can have many edges.

Our definition of \p{graph} is flat in the sense that there is no obvious way to follow the link structure recursively.  Happily, we can recover a general recursive fold/unfold (if $x |-> \gamma(x)$ and the GeneralGraph has the necessary properties in its soundness condition):
\vspace{-1ex}
\begin{equation}
\label{eqn:unfold_graph}
\hspace{-1em}\begin{array}{@{}lc@{\hspace{1pt}}c@{\hspace{1pt}}l@{}}
\p{graph}(x,\gamma)  <=>  x |-> \gamma(x) ** \big(\!\!\!\!\!\!\!\!\!\!\!\!\!\underset{n \in \p{neighbors}(\gamma,x)}{\raisebox{-0.3ex}{\resizebox{0.75em}{!}{$\scon$}} \hspace{-2.18ex} \bigcup}\!\!\!\!\!\!\!\!\!\!\!\! \p{graph}(\gamma,n) \big)
\quad \text{~~~ where ~~ }\underset{l_1,\dots,l_n}{\raisebox{-0.3ex}{\resizebox{0.75em}{!}{$\scon$}}\hspace{-2.18ex} \bigcup} \! \! P  \defeq  P(l_1) ** \ldots ** P(l_n) \end{array}
\vspace{-1ex}
\end{equation}

The proof of the $<=$ direction requires care. The difficulty is that if two nodes $x |-> \gamma(x)$ and $x' |-> \gamma(x')$ are \emph{skewed}, \emph{i.e.} ``partially overlapping'' with some---but not all---of $x$'s memory cells shared with $x'$, then the $\bigstar$ on the left hand side cannot separate them.  To avoid skewing we require that $x |-> \gamma(x)$ be \emph{alignable}. A predicate $P$ is alignable when
\[
\forall x,y.~ \Big(P(x) ** P(y) |- \big(P(x) /| x = y\big) |/ \big(P(x) * P(y)\big)\Big)
\]
That is, they overlap either completely or not at all. In a Java-like memory model this property is automatic because pointers in such a model always point to the root/beginning of an object.  In contrast, in a C-like memory model such as in VST/CompCert, this property is not automatic because pointers can point anywhere.  In such a model, alignment is most easily enforced by storing graph nodes at addresses that are multiples of an appropriate size (16 in Figure~\ref{fig:markgraph}).

Some of our VST proofs, \emph{e.g.} for \texttt{find}, do not use fold/unfold, instead preferring to use the lemmas in~\S\ref{sec:ramifylib} directly.  Others, \emph{e.g.} \texttt{mark}, do---and it is helpful to have both options avilable. We also prove fold/unfold lemma for DAGs in which we get a $*$ between the root and its $**$-joined neighbors, rather than the $**$ present in \eqref{eqn:unfold_graph}.



\subsection{Ramification Libraries}\label{sec:ramifylib}

\begin{figure}
\centering
% \beginpgfgraphicnamed{infrastructure}
\begin{tikzpicture}[
->/.style={thick, arrows={-Stealth}},
ent/.style={shape=rectangle, rounded corners=4pt, draw, on grid},x=33pt]
\node[ent] (SM) at (0, 0) {\small Step-Indexed Model};
\node[ent] (DM) [right=4.4 of SM] {\small Direct Model};
\node[ent] (CL) [above=1 of SM] {\small Core Logic};
\node[ent] (SL) [above=1 of DM] {\small Supplementary Logic};
\node[ent] (LF) [above left=1 and 1.2 of CL] {\small Logic Facts};
\node[ent] (RF) [above right=1 and 1.2 of CL] {\small Basic Ramification};
\node[ent] (BF) [above=1 of LF] {\small $\bigstar$ Facts};
\node[ent] (BR) [above=1 of RF] {\small $\bigstar$ Ramification};
\node[ent] (GF) [above=1 of BF] {\small Graph Facts};
\node[ent] (GR) [above=1 of BR] {\small Graph Ramification};
\node[ent] (SLF) [above=1 of SL] {\small Supplementary Logic Facts};
\node[ent] (SBF) [above=1 of SLF] {\small Supplementary $\bigstar$ Facts};
\node[ent] (SGF) [above=1 of SBF] {\small Supplementary Graph Facts};
\draw [double, ->] (SM) to (CL);
\draw [double, ->] (SM) to (SL);
\draw [double, ->] (DM) to (CL);
\draw [double, ->] (DM) to (SL);
\draw [->] (CL) to (LF);
\draw [->] (CL) to (RF);
\draw [->] (CL) to (SL);
\draw [->] (SL) to (SLF);
\draw [->] (SLF) to (SBF);
\draw [->] (SBF) to (SGF);
\draw [->] (LF) to (RF);
\draw [->] (LF) to (BF);
\draw [->] (RF) to (SLF);
\draw [->] (RF) to (BR);
\draw [->] (BF) to (BR);
\draw [->] (BF) to (GF);
\draw [->] (GF) to (GR);
\draw [->] (GR) to (SGF);
\draw [->] (BR) to (GR);
\draw [->] (BR) to (SBF);
\node (legend1) [below right=0.2 and -1.2 of SM] {\small Dependence};
\coordinate[left=0.8 of legend1]  (l1);
\draw [->] (l1) to (legend1);
\node (legend2) [right=1 of legend1] {\small Instantialization Choices};
\coordinate[left=0.8 of legend2]  (l2);
\draw [double, ->] (l2) to (legend2);
\end{tikzpicture}
% \endpgfgraphicnamed
\caption{Infrastructure of ramification library}\label{fig:infra}
\end{figure}


VST employs a somewhat unusual Step-Indexed heap model to represent
spatial predicates, and uses it to support an unusually rich program
logic.~\cite{appel:programlogics} However, the spatial representation
of our graph library does not rely on any of its bells and whistles.
To isolate our development from these unnecessary complications,
we use two interfaces: Core Logic and Supplementary
Logic, where Supplementary Logic is built upon the much simpler
and more universal Direct Model of heap representation.
We present the architecture of our spatial development in
Figure~\ref{fig:infra}, where it should be straighforward to see
that both models can instantiate both interfaces.

Generally speaking, our VST proofs only need the Core properties to prove
our examples. Each interface defines some operators of separation logic and
provides some axioms about how they work.  For example, $*$ and
$--*$ are in Core Logic, along with the axiom
$(P |- Q --* R) <=> (P * Q |- R)$.  On the other hand,
the $**$ and $--o$ operators are in Supplementary Logic,
along with rules like $P |- P ** P$.


\hide{Starting from the bottom, notice that there are two underlying heap models,
VST's Step-Indexed model and the much simpler Direct Model.

To isolate our development from these unnecessary complications,
{\color{magenta}and to ensure that HIP/SLEEK can reuse our spatial
reasoning, we use two interfaces: Core Logic and Supplementary
Logic.  Both models can instantiate both interfaces, but generally
speaking our VST proofs only need the Core properties to prove
our examples, whereas HIP/SLEEK uses both Core and Supplemental.}
Each interface defines some operators of separation logic and
provides some axioms about how they work.  For example, $*$ and
$--*$ are in Core Logic, along with the axiom
$(P |- Q --* R) <=> (P * Q |- R)$.  On the other hand,
the $**$ and $--o$ operators are in Supplementary Logic,
along with rules like $P |- P ** P$.} 

Above the Logic layer we have three towers, each three levels high.  The tower on the left contains basic lemmas about Logic, $\bigstar$, and \p{graph}.  For instance, in the $\bigstar$ Facts box we prove:
\[
\infrule{}
{A \cap B = \emptyset}
{\underset{x\in A}{\bigstar} P(x) \; * \underset{x\in B}{\bigstar} P(x) \;\, \Leftrightarrow \underset{x\in A \cup B}{\bigstar} P(x)}{}
\]

The middle tower is more interesting in that it is entirely focused on ramification entailments.  A robust library of ramification entailments is essential to make ramification work smoothly in practice.  The Basic Ramification box in the lower layer contains lemmas like:
\[
\infrule{}
{G_1 \vdash L_1 * \forall x.~ (L_2 --* G_2) \\
 G'_1 \vdash L'_1 * \forall x.~ (L_2' --* G'_2)}
{G_1 * G'_1 \vdash (L_1 * L'_1) * \forall x.~ \big((L_2 * L'_2)--* (G_2 * G'_2)\big)}{}
\]
We use this lemma to break large ramification entailments into more manageable pieces in a compositional way. The $\bigstar$ Ramification box in the middle layer contains lemmas like:
\begin{equation*}
\label{ramify:bigstar}
\infrule{}
{A \cap B = \emptyset  \qquad  A' \cap B = \emptyset}
{\underset{x\in A\cup B}{\bigstar} P(x) \vdash \! \underset{x\in A}{\bigstar} \! P(x) * \Big( \underset{x\in A'}{\bigstar} \! P(x) \! \wand \! \! \! \! \underset{x\in A' \cup B}{\bigstar} \! \! P(x)\Big)}{}
\end{equation*}

The Graph Ramification box in the top layer is focused lemmas such as the following ``update one node'' lemma, which was used on line~\ref{code:markram2} in Figure~\ref{fig:markgraph}:
\begin{equation*}
\label{lem:updategraphnode}
\infrule{}
{\forall x_0 \neq x.~ \gamma(x_0) = \gamma'(x_0) \\ \p{neighbors}(\gamma,x)=\p{neighbors}(\gamma',x)}
{\p{graph}(x, \gamma) \! \vdash \! x \! \mapsto \! \gamma(x) \! * \! \big(x \! \mapsto \! \gamma'(x) \! \wand \! \p{graph}(x, \gamma')\big)}{}
\end{equation*}

This layered structure enables proof reuse. All of the theorems for $\p{graph}$ are proved from the properties of iterated separating conjunction, but having a modular library allows $\bigstar$ to be reused in other structures smoothly.
Further, all our verifications of different graph algorithms use the proof rules of $\p{graph}$ at the top level in the library. Taking the marking algorithm we introduced in \S\ref{sec:orientation} as an example, we prove the following theorem from the library:
\begin{equation*}
\label{lem:updatesubgraph}
\frac
{n \in \p{neighbors}(\gamma,x)}
{
\mbox{
$\begin{array}{@{}l@{}l@{}}
\p{graph}(x, \gamma) \vdash \p{graph}(n, \gamma) \! * \!
\big(\forall \gamma'. \m{mark}(\gamma, n, \gamma') \! /| \! \p{graph}(n, \gamma') \! --*
\m{mark}(\gamma, n, \gamma') \! /| \! \p{graph}(x, \gamma')\big)
\end{array}$
}
}
\end{equation*}

The Supplementary tower contains properties not used by most of the VST examples.
This includes the fold/unfold relationship from \S\ref{sec:goodgraph}, facts
about precision, \emph{etc}. These are currently included mostly for completeness,
but do make our library more general should we wish to accommodate an alternate
prover that uses the Direct Model.










 
\section{Certifying a Garbage Collector for CertiCoq}
\label{sec:certigc}


\hide{The GC is our most complicated example,
and we will discuss some of its key proofs, but the larger
point here is that we completed this certification using
exactly the framework and principles we have discussed
thus far.

We enjoyed significant code
reuse from our prior certifications, and when we stated
new lemmas for the GC, we filed them away at the appropriate
``layers'' so that they may be reused in the future.
}

\subsection{Background}
\label{sec:gcbackground}

The CertiCoq compiler \cite{certicoqpaper} translates Gallina code to
Clight, which CompCert compiles to assembly~\cite{leroy:compcert}.
CertiCoq's garbage collector (GC) is written in Clight and 
supports Gallina's assumption of infinite memory.
CertiCoq aims to be end-to-end certified, so the GC
must be too.

The $12$-generation collector, written in the spirit of the OCaml GC,
is relatively realistic and sophisticated, though by no means
industrial-strength.
Because CertiCoq borrows OCaml's representation of blocks and
values \cite{realworldocaml}, the GC must support features such as
variable-length memory objects, object fields that may be boxed
or unboxed and must be disambiguated at runtime, pointers to places
outside the GC-managed heap, etc.
The CertiCoq GC's task is a little easier than the OCaml GC's because
its mutator is purely functional\footnote{That is: Gallina is purely functional, and
the Clight code generated by CertiCoq preserves this behavior.}. 
The mutator maintains an \code{args} array of
local variables, which the GC scans to
calculate the root set. When called, the GC collects the first generation
into the second using Cheney's algorithm \cite{cheney:gc}.
This collection may trigger the collection of the second generation
into the third, etc., and the GC completes this potential cascade
before returning control to the mutator. A
fuller explanation of GC's operation is in Appendix \ref{apx:gcstructure}.

The mutator's \code{args} array of local variables is critical in the GC's specification. 
The GC must ensure that all memory objects that the mutator can reach by recursively 
following the fields of \code{args} \emph{before} the collection can still be reached, 
via the same steps, \emph{after} the collection.  This problem can be abstracted into 
mathematical graphs, where we must prove graph isomorphism.

\subsection{From C to Mathematical Graphs}
\label{sec:movetomathgraph}
In the code, the metainformation of the 12 generations is stored as an
12-element array \code{heap}. Each generation, as a memory segment,
is represented as a \code{struct} \code{space}, which contains
three pointers: \code{start} marking the start address of a
generation, \code{next} representing the next available address in a
generation, and \code{limit} marking the last address of a
generation. The basic unit manipulated by the garbage collector is a
chunk of memory called a block. Blocks can be of different sizes;
the size of a particular block is stored in its
header (using 22 bits of the word stored at offset $-\m{sizeof}(\code{void*})$), and the remainder of the block is a continuous array of fields. 
Each field is either an unboxed integer data value, or a pointer, which may be
either within the GC or to external structures.  To disambiguate the two,
we follow OCaml's practice of requiring that all pointers are even-aligned and 
that all integers to be odd (essentially, to be only 31 bits long)~\cite{realworldocaml}.


From the perspective of the algorithm, the 12 generations can be seen
as a graph $\gamma$. Each block can be can be seen as a
vertex and pointers to other blocks indicate edges between 
vertices. More formally, we decide to encode each vertex of this graph
as a pair of natural numbers $(\m{v}_g, \m{v}_i)$ which means the vertex is
the $\m{v}_i$th block in the $\m{v}_g$th generation. We encode each edge
as a pair of vertex and index $(\m{v}, i)$ which means this edge is from
vertex $v$ and the associated pointer is in the $i$th field of the
corresponding block.  The source function always satisfies
$\mathsf{src}(\gamma, (\m{v}, i)) = \m{v}$.
Each vertex is labeled with the integer data items and the indices of pointers in the
fields. There is also a global label of $\gamma$ which has the
start/limit addresses and number of vertices of each generation. We
can reconstruct the 12 generations in memory from $\gamma$ under this
setting without redundancy. For example, to determine the \code{next} pointer of
a generation, we can sum the sizes of each vertex in that generation using its label,
and then add the \code{start} address.

\hide
{\color{red} TODO

The graph model changed not at all. We added label to the whole graph. Quite happy to add this change to our model; it doesn't change the other proofs at all. We are genuinely not isomorphic so this label helps.

What was challenging:
	- We were very aggressive in dealing with complex C-light code, right at the edge of undefined behavior
	- Interface between C-light and mathgraph... the top level theorems and forward are exploring the graph in a connected way, but do scan is making a linear array survey. We needed proofs about these two views being okay. Complex labels, edges, etc
	- Exposing these proofs to a compiler and making sure that the compiler's own invariants can use the GC. eg: compiler will never take an item from an older gen and point it to a newer gen.
}

\subsection{Forward}
\label{sec:gcforward}
The function \code{forward} is the GC's workhorse.
When correctly given the spaces \code{from} and \code{to} and a pointer
\code{p} to a memory block in \code{from},
it copies the memory block to the next
available location in the \code{to} space.
The function is robust: if passed a ``pointer'' argument
that is actually a data value, or that points outside of
\code{from}, it behaves appropriately by taking no action.
As we will see in \S\ref{sec:gcissues}, these checks are nontrivial.
The function is also versatile: it is used to collect the
mutator's \code{args} (which are $*$-separated from the heap)
and also to collect the blocks \emph{in} the heap that are reachable via
\code{args}. Its behavior needs to be subtly different in these
two cases.
Figure~\ref{fig:forward} shows a decorated proof sketch of \code{forward}
in the latter case, which is harder to verify. 

Two abstractions of \code{struct} \code{thread\_inf}
and \code{file\_info}---\m{finf} and \m{tinf}---together allow us to
extract the mutator's \code{args} array, and The
proposition \m{super\_compatible} encapsulates various checks
about \emph{e.g.} legal bounds that avoid some overflow issues.  For
concision, the facts known to us in
\emph{e.g.} line $1$ are represented by $\phi_1$, and then $\phi_1$ 
can feature as a fact \emph{e.g.} in line $8$. 

Line \ref{code:alreadyforwarded} shows
the case when the block passed to the function was already forwarded.
This may seem strange, but is vital because the same block may be 
reachable from the \code{args} via different paths.
Such a block's header is zeroed out and its $0$th field holds 
the address of its 
copy\footnote{These guarantees are set up by \code{forward} itself. 
Refer to lines \ref{code:zeroingheader} and 
\ref{code:copyinfirstfield} of Figure~\ref{fig:forward} to see this being done.}, 
so we simply reroute to that copy. 
Line \ref{code:postconafterredirect} shows that this operation 
gives us a new graph, $\gamma'=\m{upd\_edge}(\gamma, \m{e}, \m{copy}(\gamma, \m{v'}))$.
This means to reroute the edge $e$ in $\gamma$ and make it point at
$\m{copy}(\gamma, \m{v'})$.

Lines \ref{code:copyhead} to \ref{code:copyfields} show
how a block is copied over to the next-available spot in the 
\code{to} space. Some of the grungy details having to do with
variable-sized memory blocks being to show up in the C code,
but the verification looks relatively clean 
thanks to our mathematical graph framework.
This is just the copying of a vertex, and so our new graph after the change is
$\gamma' = \m{copy\_vertex}(\gamma, \m{to}, \m{v'}, \m{v''})$. 
The final step (line \ref{code:ridirect}) is to reroute to this 
new copy, and this is done just as in line~\ref{code:alreadyforwarded}. The
resultant graph is $\gamma'' = \m{upd\_edge}(\gamma', \m{e}, \m{v''})$.

The postcondition is a little different from those of \code{find}
and \code{mark} seen earlier, in that it does not provide a relation
saying that \code{forward} has been functionally correct. Rather, we
defined the relation to reflect the result of operations
in \code{forward}, such as a vertex is copied, an edge is redirected,
and etc,. For a taste, we put the complete definition
of \m{forward\_relation} in Appendix~\ref{apx:forwardrelation}. We
have relations of this sort for all the key functions in our GC, and
we show that the composition of these correctly corresponds to the C
code of our garbage collector. The final functional correctness is
derived from these relations.

\newcommand{\finf}{finf}
\newcommand{\tinf}{tinf}
\newcommand{\out}{out}
\newcommand{\braces}[1]{\left\{\!\!\!\begin{array}{l@{}} #1 \end{array}\right\}}
\newcommand{\ga}{\gamma}
\newcommand{\Eg}{E_\ga}
\newcommand{\Vg}{V_\ga}

\begin{figure*}[!ht]
\vspace{-1ex}
  \begin{lstlisting}[multicols=2]
$//$$\braces{\forall \ga, \m{\finf}, \m{\tinf}, \m{from}, \m{to}, \m{v}, \m{n}.~\null \\ \p{gc{\_}graph}(\ga) * \p{\finf}(\m{\finf}) * \p{\tinf}(\m{\tinf}) /| \null \\ \m{compat}(\ga, \m{\finf}, \m{\tinf}, \m{from}, \m{to}) /| \null \\ \tx{s} = \m{start}(\ga, \m{from}) /| \tx{l} = \tx{s} + \m{gensize}(\ga, \m{from}) \\ \null /| \tx{n} = \m{naddr}(\m{\tinf}, \m{to}) /| \tx{p} = \m{vaddr}(\ga, \m{v}) + \m{n}} \defeq \phi_1 $
void forward (value *s, *l, **n, *p, 
              int depth) {
 value * v; value va = *p; 
 if(Is_block(va)) {$// \textit{is ptr}$
  v = (value*)((void *)va); 
  if(Is_from(s, l, v)) {$ // \textit{in from}$
$//$$\braces{\phi_1 /| \exists \m{e}, \m{v'}.~\m{lab}(\ga, \m{v})[\m{n}] = \m{e} /| \null \\ \m{dst}(\ga, \m{e}) = \m{v'} /| \tx{v} = \m{vaddr}(\ga, \m{v'})} \defeq \phi_8 $
$//$$\searrow$$\braces{\exists \m{flds'}, \m{hdr'}.~\m{flds'} = \m{lab}(\ga, \m{v'}) /| \null \\ \m{v'} |-> \m{flds'} /| \m{hdr'} = \m{flds'}[-1]} \defeq \phi_9 $
   header_t hd = Hd_val(v);
$//$$\swarrow$$\braces{\phi_9 /| \tx{hd} = \m{val}(\m{hdr'})}$
$//$$\braces{\phi_8 /| \tx{hd} = \m{val}(\m{hdr'})}$ 
   if(hd == 0) {$// \textit{already forwarded}$
$//$$\braces{\phi_8 /| \tx{hd} = 0} \defeq \phi_{14}$ 
$//$$\searrow$$\braces{\exists \m{flds}, \m{flds'}.~\m{v} |-> \m{flds} /| \m{v'} |-> \m{flds'} /| \null \\ \m{flds} = \m{lab}(\ga, \m{v}) /| \m{flds'} = \m{lab}(\ga, \m{v'}) /| \null \\ \m{flds'}[0] = \m{vaddr}(\gamma, \m{copy}(\ga, \m{v'})) /| \null \\ \tx{p} = \tx{\&}\m{flds}[n]} \defeq \phi_{15} $
    *p = Field(v,0); $\label{code:alreadyforwarded}$
$//$$\swarrow$$\braces{\phi_{15} /| \m{flds}[n] := \m{flds'}[0]}$
$//$$\braces{\phi_{31} /| \exists \ga'.~\p{gc{\_}graph}(\ga') /| \null \\ \ga' = \m{upd\_edge}(\ga, \m{e}, \m{copy}(\ga, \m{v'})) /| \null \\ \m{postcondition}(\ga, \ga', \m{\tinf}, \m{\finf}, \m{from}, \m{to})}$ $\label{code:postconafterredirect}$
   } else {$// \textit{not yet forwarded}$
$//$$\braces{\phi_8 /| \tx{hd} \neq 0}  \defeq \phi_{20} $
    int i; int sz; value *new;
    sz = size(hd); new = *n+1; *n = new+sz;
$//$$\braces{\phi_{20} /| \tx{sz} = \m{blocksize}(\tx{hd}) /| \null \\ \tx{new} = \m{start}(\gamma,\m{to}) + \m{used}(\gamma, \m{to}) + 1 /| \tx{n} = \tx{new} + \tx{sz}}  \defeq \phi_{23} $      
    Hd_val(new) = hd; $\label{code:copyhead}$
    for(i = 0; i < sz; i++) 
     Field(new, i) = Field(v, i); $\label{code:copyfields}$
$//$$\braces{\phi_{23} /| \exists \ga', \m{v''}, \m{\tinf'}.~\p{gc\_graph}(\ga') /| \null \\ 
\m{v''} = \m{newly\_copied\_vertex(\ga, \m{to})} /| \null \\ \ga' = \m{copy\_vertex}(\gamma, \m{to}, \m{v'}, \m{v''}) /| \null \\ 
\m{compat}(\ga', \m{\finf}, \m{\tinf'}, \m{from}, \m{to})} \defeq \phi_{27} $
    Hd_val(v) = 0; $\label{code:zeroingheader}$
    Field(v, 0) = (value)((void *)new); $\label{code:copyinfirstfield}$
$//$$\braces{\phi_{27} /| \m{val}(\m{hdr'}) = 0 /| \m{flds'}[0] = \m{copy}(\ga, \m{v'})} \defeq \phi_{30}$
$//$$\searrow$$\braces{\exists \m{flds}.~\m{v} |-> \m{flds} /| \m{flds} = \m{lab}(\ga', \m{v})} \defeq \phi_{31}$
    *p = (value)((void *)new); $\label{code:ridirect}$
$//$$\swarrow$$\braces{\phi_{31} /| \m{flds}[0] := \m{vaddr}(\ga, \m{v''})}$
$//$$\braces{\phi_{30} /| \exists \ga''.~\p{gc\_graph}(\ga'') /| \ga'' = \m{upd\_edge}(\ga', \m{e}, \m{v''})}$
}}}}
$//$$\braces{\m{postcondition}(\gamma', \gamma'', \m{tinf'}, \m{finf}, \m{from}, \m{to})}$
\end{lstlisting}
\footnotesize{
\vspace{-0.8em}
\begin{equation*}
\begin{split}
\m{postcondition}(\gamma, \ga', \m{tinf'}, &\m{finf'}, \m{from}, \m{to}) \; \defeq \; 
   \p{gc{\_}graph}(\ga') * \p{\finf}(\m{\finf'}) * \p{\tinf}(\m{\tinf'}) /| \null \\
   &\m{compat}(\ga', \m{\finf'}, \m{\tinf'}, \m{from}, \m{to}) /|
   \m{forward\_relation}(\ga, \ga', \m{from}, \m{to})
\end{split}
\end{equation*}

}
\vspace{-0.4em}
\caption{Clight code and proof sketch for forward}
\label{fig:forward}
\vspace{-1em}
\end{figure*}

 
\subsection{Performance and Overflows and Undefined Behaviours, Oh My!} \label{sec:gcissues}

\subsubsection*{Bugs in the GC code.}
We discovered and fixed two bugs in the source code during our verification.
The first was a performance bug we discovered when developing the key invariants.
The original GC code executed Cheney's algorithm too conservatively,
scanning the entire~\code{to} space for backward pointers into \code{from}. We
showed that scanning a subset of \code{to} suffices.  Performance doubled.

The second bug was an overflow when subtracting two pointers
to calculate the size of a space, as below. Pointers \code{start} and \code{limit}
point to the beginning and end of the \code{i}$^{\text{th}}$ space of the
heap \code{h}.
\begin{lstlisting}[numbers=none]
  int w = h->spaces[i].limit - h->spaces[i].start;
\end{lstlisting}
This subtraction is defined in C and Clight, but
will overflow if the difference equals
or exceeds~$2^{31}$. We adjusted the size of the largest generation to avoid this overflow.

\subsubsection*{Undefined behavior in C} We found two places where the semantics of Clight was unable to specify an OCaml-style GC.
The first involved double-bounded pointer comparisons.
As mentioned in \S\ref{sec:gcforward}, \code{forward} needs to
check whether the object it is considering, which it already knows to be a pointer,
is in fact pointing into the \code{from} space. It uses this function:
\begin{lstlisting}[numbers=none]
int Is_from(value * from_start, value * from_limit, value * v) {
  return (from_start <= v && v < from_limit); }
\end{lstlisting}
Here, the \code{start} and \code{limit} pointers are in the same
memory block. If \code{v} is also in the same block, \code{Is{\_}from}
correctly computes whether it is in bounds.
However, if \code{v} is in a different block, the comparison gets stuck rather than 
returning \code{false}.
Although the Clight code is undefined, we used CompCert's ``extcall{\_}properties''
to prove that CompCert's compiler transformations will preserve the necessary invariants
because the comparison is bounded both above and below (in contrast, single-bounded 
comparisons need not be semantically preserved in CompCert).

The second area of undefined behavior results from our GC's use of the well-established
31-bit integer trick to allow both boxed and unboxed data in block fields~\cite{realworldocaml}.
To distinguish them, \texttt{forward} calls \texttt{Is\_block} ({\color{red} line~5}), which
in turn calls
\begin{lstlisting}[numbers=none]
int test_int_or_ptr (value x) /* returns 1 if int, 0 if aligned ptr */ {
    return (int)(((intnat)x)&1); }
\end{lstlisting}
When \texttt{x} is an int, this is indeed well-defined, but it is undefined to take the
logical and of a pointer, so the code again gets stuck.  Here the situation is messier,
since CompCert does \textbf{not} guarantee that the alignment of a pointer is stable during 
compilation: in particular, stack-allocated local variables of type \texttt{char} may be packed
tightly while assembling the stack frame, thus shifting their alignment.  Informally, of course,
this cannot occur in the GC since we do not store stack-allocated local variables in the GC-managed
heap.  We have discussed this issue with the CompCert team \cite{leroy_email}, and believe that
a stronger specification of the extcall{\_}properties (essentially, guaranteeing that non-\texttt{char} pointers do not change alignment) should allow us to prove that CompCert
will respect \texttt{test\_int\_or\_ptr}'s behavior.  The CompCert team understands the 
issue~{\color{red}\cite{where}} and wants OCaml-style GCs to have defined behavior in Clight.

Other than these two items, the GC is fully defined in Clight---we were even able to 
prove that all casts (\emph{e.g.} {\color{red} line~6}) were well-defined.
As a concluding thought, Coq itself is written in OCaml with a similar-style garbage collector.
Thus, our GC is at least as well-defined as Coq itself.
 
\section{Engineering our Techniques}
\label{sec:development}
\label{sec:vst}

CompCert is a fully machine-checked verified compiler for~C~\cite{leroy:compcert}.
The Verified Software Toolchain consists of a series of machine-checked modules written in Coq
to reason about (CompCert) C programs~\cite{appel:programlogics}.
Floyd is VST's module for verifying such programs using separation logic.
VST's modules interlock so there are no ``gaps'' in the end-to-end certified results;
accordingly all of the rules employed by Floyd have been proved sound with respect to
the underlying semantics used by CompCert.  Floyd is written in Ltac and Gallina and is
designed to help users verify the full functional correctness of their programs.
We added two tactics, \li{localize} and \li{unlocalize}, to
integrate the \textsc{Localize} rule into Floyd as described in \S\ref{sec:orientation}--\S\ref{sec:localizations}.




\subsection{Localizations in VST with \li{localize} and \li{unlocalize}}
\label{sec:vstlocalunlocal}
\vspace{-0.75ex}
Floyd presents users with a pleasant ``decorated program'' visualization for Hoare proofs, in which users work from the top of the program to the bottom even though the formal proof is maintained as applications of inference rules.  For example, suppose the proof goal is $\triple{P_1}{c_1\li{;}c_2}{P_5}$ and VST's user tells Floyd to apply a Hoare rule for $c_1$, \emph{e.g.}~$\triple{P_1}{c_1}{P_2}$.  Floyd will then automatically apply the \infrulestyle{Sequence} rule and show the user $\triple{P_2}{c_2}{P_5}$ as the remaining goal.
When the user is in the middle of a verification, the decorated program is partially done (\emph{i.e.} the proof is finished from the top to ``the current program point'') and the inference tree is also partially done (\emph{i.e.} with holes that are represented by the remaining proof goals in Coq).

We wish to preserve this ``decorated program'' view while extending Floyd to support localization.  Our task therefore is to construct a proof in Coq's underlying logic that allows a localization block to be constructed in this manner---that is, we wish to enter a localization block without requiring the user to specify the ``exit point'' in advance.  The engineering is tricky because the proof Floyd is constructing (\emph{i.e.} applications of inference rules) has holes in places where the user's ``top to bottom'' view of things has not yet arrived.

\begin{figure}
\begin{minipage}{.15\textwidth}
\begin{lstlisting}[basicstyle=\linespread{0.8}\normalfont\footnotesize\tt]
$\{\ \ P_1 \ \ \}$
    c1
$\{\ \ P_2 \ \ \}\label{code:localglobalin}$
$\searrow \{\ \ P_3 \ \ \}\label{code:locallocalin}$
      c2;
  $\,\{\ \ P_4 \ \ \}\label{code:localsndcmd}$

    ...


\end{lstlisting}
\centerline{\footnotesize(front)}
\end{minipage} \vline ~
\begin{minipage}{.15\textwidth}
\begin{lstlisting}[numbers=none, basicstyle=\linespread{0.8}\normalfont\footnotesize\tt]
$\{\ \ P_1 \ \ \}$
    c1
$\{\ \ P_2 \ \ \}$
$\{\ \ ?F * P_3 \ \}$
    c2;
$\{\ \ ?F * P_4 \ \}$

  ...


\end{lstlisting}
\centerline{\footnotesize(back)}
\end{minipage} \vline ~
\begin{minipage}{.15\textwidth}
\begin{lstlisting}[numbers=none, basicstyle=\linespread{0.8}\normalfont\footnotesize\tt]
$\{\ \ P_1 \ \ \}$
    c1
$\{\ \ P_2 \ \ \}$
$\searrow \{\ \ P_3 \ \ \}$
      c2;
  $\,\{\ \ P_4 \ \ \}$
      c3;
$\swarrow\{\ \ P_5 \ \ \}$
$\{\ \ P_6 \ \ \}$
    ...
\end{lstlisting}
\centerline{\footnotesize(front)}
\end{minipage} \vline ~
\begin{minipage}{.15\textwidth}
\begin{lstlisting}[numbers=none, basicstyle=\linespread{0.8}\normalfont\footnotesize\tt]
$\{\ \ P_1 \ \ \}$
    c1
$\{\ \ P_2 \ \ \}$
$\{\ \ ?F * P_3 \ \}$
    c2;
$\{\ \ ?F * P_4 \ \}$
    c3;
$\{\ \ ?F * P_5 \ \}$
$\{\ \ P_6 \ \ \}$
  ...
\end{lstlisting}
\centerline{\footnotesize(back)}
\end{minipage}
\caption{Front and back ends of \li{localize} and \li{unlocalize}}
\label{figure:backend}
\end{figure}

Figure~\ref{figure:backend} has four partially-decorated ``proofs in progress'', from both the user's (front end) and Floyd's (back end) points of view.  In the first column, from the user's point of view, they saw the assertion $P_2$ (line~\ref{code:localglobalin}) and decided to use the \li{localize} tactic to zoom into $P_3$ (line~\ref{code:locallocalin}).  They then applied some proof rules to move past $c_2$ to reach the assertion $P_4$ (line~\ref{code:localsndcmd}).  At this point, Floyd does not know when the corresponding \li{unlocalize} tactic will execute, so it does not know which commands will be inside the block or what the final local and global postconditions will be.

Accordingly, the \li{localize} tactic builds an incremental proof in the underlying program logic by applying \infrulestyle{Frame} with an uninstantiated metavariable.
The second column of Figure~\ref{figure:backend} shows the back end with the unknown frame $?F$, which will eventually be instantiated by \li{unlocalize}.

In the third column, the user has advanced past $c_3$ to reach the local postcondition $P_5$ and now wishes to \li{unlocalize} to~$P_6$.  Afterwards, the internal state looks like the fourth column, and so to a first approximation, \li{unlocalize} can instantiate $?F$ with $P_5 \wand P_6$.  In truth, $?F$ is chosen more subtly to properly handle both existential variables and modified program variables; \li{unlocalize} then automatically simplifies the goals to present a cleaner interface to the user.  These transformations require the additional theory given in \S\ref{sec:localizations}.

\subsection{Statistics related to our development}

\begin{table}[b]
\centering
\begin{tabular}{c|c|c|c|c|c}
Component & Section & Files & Size (in lines) & Definitions & Theorems\\\hline
Common Utilities & & 10 & 3,578 & 44 & 289 \\
Math Graph Library & \S\ref{sec:mathgraph} & 20 & 10,585 & 216 & 581 \\
Spatial Graph Library & \S\ref{sec:spacegraph} & 3 & 2,328 & 59 & 110 \\
Integration into VST & \S\ref{sec:localizations},\S\ref{sec:development} & 11 & 2,783 & 17 & 172 \\
\hline
Marking (graph and DAG) & \S\ref{sec:localizations} & 6 & 775 & 9 & 20 \\
Spanning Tree & \S\ref{sec:localizations} & 5 & 2,723 & 17 & 92 \\
Union-Find (heap and array) & \S\ref{sec:orientation} & 18 & 3,193 & 107 & 135 \\
Garbage Collector & \S\ref{sec:certigc} & 16 & 13,858 & 235 & 712 \\
\hline & & & & & \\
[-2.2em] \\
\hline & & & & & \\
[-1em]
Total Development & & 89 & 39,823 & 704 & 2,111 \\
\end{tabular}
\caption{Statistics for our code base}
\label{tab:codebase}
\end{table}

All our results in this paper have been machine-checked.
Although the size of a development does not perfectly match with that development's importance or implementation difficulty, we present the size nonetheless in Table~\ref{tab:codebase}.
Our proof script is written in a very
dense style.
For comparison, verifying a simple 39-line list-based merge sort in VST takes 600 lines.
At $\approx400$ LOC, the garbage collector is much larger, and is very complicated both
mathematically and spatially, in many places teetering on the edge of what can be defined
in~C.  For context, CompCert has 217k LOC, 5,687 definitions, and 6,694 theorems;
VST has 623k LOC, 14,038 definitions, and 21,442 theorems.


\hide{
\paragraph{Size of Coq mathgraph \S\ref{sec:mathgraph}.}
Graph folder has 18 files in total with 10,919 lines in total

\paragraph{Size of Coq spacegraph \S\ref{sec:spacegraph}.}

not including the connection to H/S or VST

include \li{Graph.v} and \li{GraphBi.v} from \li{msl_application} since they do not depend on the underlying VST model?

What is in \li{ramification_lemmas}?  
\paragraph{Integration into Floyd (\S\ref{sec:vst}).}: ?
Size of additions to VST logic model: ?

\paragraph{Modifications to HIP/SLEEK.}
H/S code: approximately 2,500 lines of code across 51 files
Size of extra H/S memory model:
\li{alg_seplog_direct.v}  52 lines
\li{overlapping_direct.v} 442 lines  {\color{magenta}How do we handle alignment?}
\li{precise_direct.v} 111 lines
other files?

\paragraph{Size of VST examples~\S\ref{sec:application}.}

Note: graph, graphbi (in space), graphmark, graphbimark are shared in \li{msl_application}

mark graph  19 + 402 + 161 + 246 = 828
mark dag  19 + 402 + 161 + 210
Note: mark dag shares 19 + 402 + 161 with mark graph

copy   459 + 19 + 161 + 388 = 1,027 (need to add files from \li{msl_applicatin})
dispose   475 + 18 + 544 = 1,037 (need to add files from \li{data_structure})
What do copy or dispose share with mark or with each other?

total: 1,038 (marks) + 2,064 (copy/dispose, assuming no duplication) = 3,102 lines.  12 files, assuming no sharing for copy/dispose (with each other or with mark)

\paragraph{Size of H/S example.}
main file: 54 lines (Figure~\ref{fig:hipmarkgraph}), \li{Module Type} generated by H/S (Figure~\ref{fig:hipcoqfile}) is 30 lines, Coq \li{Module} matching this \li{Module Type} is 358 lines.
total: 2 human-generated files, 429 lines

\paragraph{Size of total development.} ?
}
 
\section{Related work}
\label{sec:related}
\paragraph{Comparison with~\cite{hobor:ramification}.}
Our work builds on the theory of ramification by Hobor and Villiard,
who verified graph algorithms on pen-and-paper using their \infrulestyle{Ramify} rule:
\begin{equation*}
\inferrule[Ramify]
{\{ L_1 \} ~ c ~ \{ L_2 \} \\
G_1 |- L_1 * (L_2 --* G_2)}
{\{ G_1 \} ~ c ~ \{ G_2 \}} \qquad \mathit{freevars}(L_2 --* G_2) \cap \MV(c) = \emptyset
\end{equation*}
Our \textsc{Localize} rule upgrades \textsc{Ramify} to better handle modified program
variables (note the side condition and recall the discussion in \S\ref{sec:localizations})
and existential quantifiers in postconditions.  Hobor and Villard avoided these challenges
by proposing a unwieldy variant of \infrulestyle{Ramify} called \infrulestyle{RamifyAssign}, which
could reason about the special case of a single assignment $\li{x=}f(\ldots)$, assuming
the verifier can make the local program translation to $\li{x'=}f(\ldots)\li{; x=x'}$,
where \li{x'} is fresh.  This is nontrivial in large existing formal
developments, such as VST, that do not have any way to prove programs equivalent.
Hobor and Villard could not verify unmodified program code, modify program variables
inside nested localization blocks, or handle multiple assignments in a single block as
in lines~\ref{code:markbeforetripleramify}--\ref{code:markaftertripleramify} of
figure~\ref{fig:markgraph}.  Hobor and Villard avoided existentials in localized
postconditions by defining all mathematical operations (\emph{e.g.} $\m{mark}$) as
functions rather than as relations; this is fine for pen-and-paper, but painful in
a mechanized setting wherein functions must be proven to terminate.

\iffalse
Our development is entirely machine-checked~(\S\ref{sec:development}) which revealed some
tricky technique details. Hobor and Villard fell into the trap of defining spatial graphs
recursively~(\S\ref{sec:fixpointfail}); unfortunately other members of the research
community have since followed them in.  We exposed this error and provided a sound,
general, and highly modular graph framework that works smoothly in a mechanized
context~(\S\ref{sec:mathgraph},\S\ref{sec:spacegraph}).
\fi


\iftrue
Hobor and Villard treated mathematical graphs as triples $(V,E,L)$ of
vertices, edges, and a vertex labeling function; vertices had no more than two
neighbors.  Our mathematical graph framework~(\S\ref{sec:mathgraph}) is very
modular and general and has been tuned to work smoothly in a mechanized context.

Hobor and Villard erroneously defined spatial graphs
recursively~(\S\ref{sec:fixpointfail}); unfortunately other members of the research
community have since followed them in, \emph{e.g.}~\cite{raadvg15}.  We exposed this
error and provided a sound and quite general definition for
\p{graph}~(\S\ref{sec:goodgraph}) that recovers fold/unfold reasoning.  We developed a
much more general and more modular set of related lemmas and connect our spatial
reasoning to the verification framework of CompCert/VST~(\S\ref{sec:vst}), and
our development is entirely
machine-checked~(\S\ref{sec:development}) whereas they used only pen and paper.

\fi


\paragraph{Other verification of graph algorithms and/or $**$.}
\cite{hongseok:phd}'s verification of the Schorr-Waite algorithm is a landmark in the
early separation logic literature.  \cite{neelthesis}~provided the first separation
logic proof of union-find.  \cite{bornat:aliasing04}~gave an early attempt to
reason about graph algorithms in separation logic in a more general
way.

\cite{rey-slnotes}~was the first to document the overlapping conjunction~$**$, albeit without
any strategy to reason about it using Hoare rules.
\cite{gardnerms12}~were the first to reason about a program using $**$ in
Javascript.  \cite{raadvg15}~used $**$ to reason about a
concurrent spanning algorithm using a kind of
``concurrent localization''.  \cite{ilya-graphs} also verified a
concurrent spanning tree algorithm, and moreover developed mechanized Coq proofs.

A decade after Yang verified Schorr-Waite on paper, \cite{leino10}~automated
its verification.



\vspace{-1ex}
\paragraph{Verification tools.}
Our work interacts with the Floyd~\cite{appel:programlogics} verification
tool.  Charge! likewise uses Coq tactics to work with a shallow embedding of higher
order separation logic, but focuses on OO programs written in
Java/C\#~\cite{bengtson:charge}.  Iris Proof Mode provides a similar framework for higher-order
concurrent reasoning~\cite{krebbers:iris}.  A  more automated approach to verification of low
level programs using Coq is the Bedrock framework \cite{chlipala:bedrock}.

Many automated verification tools also use separation logic in a forward reasoning style
as does HIP/SLEEK, including Smallfoot~\cite{berdine:smallfoot},
jStar~\cite{distefanop08}, and Verifast~\cite{jacobs:verifast}.  One of HIP/SLEEK's
distinguishing features is good support for user-defined inductive predicates rather
than a library of pre-defined predicates for lists, trees etc.

Dafny~\cite{leino10} and KeY~\cite{beckert:2007} are verifiers not based
on separation logic; KeY uses an interactive verifier while Dafny pursues automation with Z3~\cite{moura2008}.



\vspace{-1ex}
\paragraph{Mechanized mathematical graph theory.} There is a long history,
going back at least 25 years, of mechanized reasoning about mathematical
graphs~\cite{wong1991}.  The most famous mechanically verified ``graph theorem''
is the Four Color Theorem~\cite{gonthier2005computer}; however
the development actually uses hypermaps instead of graphs.
Noschinski built a graph library in Isabelle/HOL whose formalization
is the closest to ours~\cite{noschinski2015}, \emph{e.g.} supporting
graphs with labeled and parallel arcs.
\cite{noschinski2015formalizing,dubois2015graphes}~used proof assistants to design verifiable
checkers for solutions to graph problems.
\cite{yamamoto1995formalization,bauer20025}~use an inductive
encoding of graphs to formalize planar graph theory.

\cite{gueneauetal}~formalised ``time credits'' in Separation Logic and big-$O$ notation in
Coq and then verified both the correctness
and the time complexity of the union-find data structure.


\paragraph{Verification of garbage collection algorithms.}
Schism \cite{gcexample4,gcexample4a} is a certified concurrent
collector built in a Java VM that services multi-core architectures with weak memory consistency.
McCreight \emph{et al.} \cite{gcexample5, gcexample3} introduce GCminor, which is
a certified translation step added to CompCert's translation from Clight to assembly.
GCminor makes explicit the specific invariants that the garbage collector
relies upon, thus minimising errors due to the violation of invariants
between the garbage collector and the mutator.
Hawblitzel and Petrank \cite{gcexample2} annotate x86 code
for two GCs by hand, and then use Boogie and the Z3 automated theorem prover
to verify their correctness automatically.

The closest piece of work to our certified GC is probably the excellent certified GC
for the Cake ML project~\cite{cakemlgc}, since both integrate a certified GC into 
a certified compiler for a functional language.  Their GC is written closer to assembly 
than C, which is both a positive---in that they avoid undefined behaviors---and a negative, 
in that their GC is harder to understand and upgrade and cannot take advantage of the
mature CompCert compiler.  Their GC lacks some of our optimisations (\emph{e.g.} they have 
only three generations), but on the other hand handles mutation in the GC heap.  The largest 
difference, however, is that we present an integrated graph framework suitable for reasoning 
about many graph algorithms, of which our GC is merely the flagship.  In contrast, they focus 
much more narrowly on the problem of certified GCs.







 
\section{Future work and conclusion}
\label{sec:future}
\label{sec:conclusion}
In the future we plan to improve the pure reasoning of graphs and
similar data structures, in particular to add automation.  We have
also begun to investigate integrating our techniques into the 
HIP/SLEEK toolchain~\cite{chin:hipsleek}, which as compared to VST 
provides more automation at the cost of lower expressivity.  We
are also interested in investigating better ways to handle the
kinds of undefined behavior upon which real~C systems code sometimes
relies.

\hide{\color{magenta}We are in the process of verifying a garbage
collector for the ``CertiCoq'' project, which is building
a certified compiler from Gallina to Clight. We would like to investigate
using our externally verified lemmas in HIP/SLEEK to verify code such as fast
exponentiation and more graph algorithms. We also would like to make
the interface between Coq and H/S simpler and cleaner.
One final direction we would like to investigate is using our new
connection to Coq to have H/S output certificates as it
verifies programs so that the system becomes more trustworthy.}

Our main contributions were as follows.  We developed a mathematical
graph library that was powerful enough to reason about graph-manipulating
algorithms written in real~C code.  We connected these mathematical graphs
to spatial graphs in the heap via separation logic.  We developed 
localization blocks to smoothly reason about a local action's effect on
a global context in a mechanized context, including a robust treatment
of modified program variables and existential quantifiers in postconditions.
We demonstrated our techniques on several nontrivial examples, including union-find
and spanning tree.  Our flagship example is the verification of the garbage collector 
for the CertiCoq project, during which we found two places in which the~C semantics
is too weak to define an OCaml-style GC.  We integrated our techniques into the
VST toolset. 

 
\begin{acks}                            This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


\bibliography{autoquack.bib}



\appendix

\section{Spanning and Copying}
\label{apx:spanning}

\begin{figure}[t]
  \begin{lstlisting}
struct Node {
    int m;
    struct Node * l;
    struct Node * r; };
// We use $R$ to represent $\p{reachable}(\gamma,\tx x)$
void spanning(struct Node * x) { 
// $\{\p{graph}(\tx{x},\gamma)/|\gamma(\tx{x}).1=0\}$ 
    struct Node * l, * r; int root_mark;
// $\{\p{graph}(\tx x,\gamma) /| \exists l,r.~ \gamma(\tx{x}) = (0,l,r)\}$
// $\{\p{graph}(\tx x,\gamma) /| \gamma(\tx{x}) = (0,l,r)\}$
// $\{\p{vertices\_at}(\p{reachable}(\gamma,\tx x), \gamma) /| \gamma(\tx{x}) = (0,l,r)\}$
// $\{\p{vertices\_at}(R, \gamma) /| \gamma(\tx{x}) = (0,l,r)\}$
// $\searrow \{\tx x|-> 0,l,r /| \gamma(\tx{x}) = (0,l,r)\}$
    l = x -> l; r = x -> r; x -> m = 1;
// $\swarrow \{\tx x|-> 1,\tx{l},\tx{r} /| \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \exists \gamma_1.~ \m{mark1}(\gamma, \tx{x}, \gamma_1)\}$
// $\{\exists \gamma_1.~\p{vertices\_at}(R, \gamma_1) /| \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{mark1}(\gamma, \tx{x}, \gamma_1)\}$
// $\{\p{vertices\_at}(R, \gamma_1) /| \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{mark1}(\gamma, \tx{x}, \gamma_1)\}$
    if (l) {
        root_mark = l -> m;
        if (root_mark == 0) {
            spanning(l);
        } else { x -> l = 0; } }
// $\left\{\!\!\!\begin{array}{l@{}}\exists\gamma_2. ~\p{vertices\_at}(R,\gamma_2)/| \gamma(\tx{x}) = (0,\tx{l},\tx{r})  /| \null \\ \m{mark1}(\gamma, \tx{x}, \gamma_1) /| \m{e\_span}(\gamma_1,\tx{x}.\text{L},\gamma_2)\end{array}\right\}$
// $\left\{\!\!\!\begin{array}{l@{}}\p{vertices\_at}(R,\gamma_2)/| \gamma(\tx{x}) = (0,\tx{l},\tx{r})  /| \null \\ \m{mark1}(\gamma, \tx{x}, \gamma_1) /|  \m{e\_span}(\gamma_1,\tx{x}.\text{L},\gamma_2)\end{array}\right\}$
    if (r) {
        root_mark = r -> m;
        if (root_mark == 0) {
           spanning(r);
        } else { x -> r = 0; } }
// $\left\{\!\!\!\begin{array}{l@{}}\exists\gamma_3.~\p{vertices\_at}(R,\gamma_3)/| \gamma(\tx{x}) = (0,\tx{l},\tx{r})  /| \null \\ \m{mark1}(\gamma, \tx{x}, \gamma_1) /| \m{e\_span}(\gamma_1,\tx{x}.\text{L},\gamma_2) /| \m{e\_span}(\gamma_2,\tx{x}.\text{R},\gamma_3)\end{array}\right\}$
} // $\{\exists \gamma_3.~\p{vertex\_at}(\p{reachable}(\gamma, \tx{x}), \gamma_3)/|\m{span}(\gamma,\tx{x},\gamma_3)\}$
  \end{lstlisting}
  \small
\begin{gather*}
  \p{vertices\_at}(\p{reachable}(\gamma_1, \tx x), \gamma_2)\defeq \underset{v\in\p{reachable}(\gamma_1, \tx x)}{\bigstar}v \mapsto \gamma_2(v)\\
  \begin{split}
  \m{span}(\gamma_1, \tx x, \gamma_2)\defeq &\m{mark}(\gamma_1,\tx x, \gamma_2) /| \gamma_1\!\uparrow(\lambda v. x\mathrel{{\stackrel{\gamma_1~}{\leadsto^{\star}_{0}}}} v) \text{ is a tree} /| \null\\
  & \gamma_1\!\uparrow\!(\lambda v.\neg x\mathrel{{\stackrel{\gamma_1~}{\leadsto^{\star}_{0}}}} v) = \gamma_2\!\uparrow\!(\lambda v.\neg x\mathrel{{\stackrel{\gamma_1~}{\leadsto^{\star}_{0}}}} v) /| \null\\
  & (\forall v.~x\mathrel{{\stackrel{\gamma_1~}{\leadsto^{\star}_{0}}}} v => \gamma_2\models x \leadsto v) /| \null\\
  & (\forall a,b.~x\mathrel{{\stackrel{\gamma_1~}{\leadsto^{\star}_{0}}}} a => \neg x\mathrel{{\stackrel{\gamma_1~}{\leadsto^{\star}_{0}}}} b => \neg \gamma_2\models a \leadsto b)\\
  \end{split}\\
  \m{e\_span}(\gamma_1, e, \gamma_2)\defeq
  \begin{cases}
    \gamma_1 - e = \gamma_2  & t(\gamma_1,e)=1\\
    \m{span}(\gamma_1, t(\gamma_1,e), \gamma_2) & t(\gamma_1,e)=0\\
  \end{cases}
\end{gather*}
\caption{Clight code and proof sketch for bigraph spanning tree.}
\label{fig:spanning}

\end{figure}
 
In Figure~\ref{fig:spanning} we show a simplified proof script for
the spanning tree algorithm.  Unlike graph marking, the spanning tree algorithm changes the
structure of the graph, leading to a more complicated specification,
in both the pure part and the spatial part. Observe that the $\m{span}$ relation is
rather long; the $\m{e\_span}$ handles the case of either calling spanning tree or deleting an edge.

We put the proof sketch of the graph copying algorithm in
Figure~\ref{fig:copy-part1} and Figure~\ref{fig:copy-part2}. Just like
other parts of the paper, both algorithms have been machine verified.

\begin{figure}
  \begin{lstlisting}
struct Node {
    int m;
    struct Node * l;
    struct Node * r; };
// We use $x \xleftrightarrow{\gamma} x'$ to represent $x = x' = 0 \vee \gamma(x) = (x', \_, \_)$
struct Node * copy(struct Node * x) { 
    struct Node * l, * r, * x0, * l0, * r0;
// $\{\p{graph}(\tx{x},\gamma)\}$
      if (x == 0)
        return 0;
// $\{\p{graph}(\tx{x},\gamma)/| x\neq 0\}$
// $\{\p{graph}(\tx x,\gamma) /| \exists x_0,l,r.~ \gamma(\tx{x}) = (x_0,l,r)\}$
// $\{\p{graph}(\tx x,\gamma) /| \gamma(\tx{x}) = (x_0,l,r)\}$
// $\searrow \{\tx x|-> x_0,l,r /| \gamma(\tx{x}) = (x_0,l,r)\}$
      x0 = x -> m;
// $\swarrow \{\tx x|-> x_0,l,r /| \gamma(\tx{x}) = (x_0,l,r) /| \tx{x0} = x_0\}$
// $\{\p{graph}(\tx x,\gamma) /| \gamma(\tx{x}) = (\tx{x0},l,r)\}$
      if (x0 != 0)
        return x0;
// $\{\p{graph}(\tx x,\gamma) /| \gamma(\tx{x}) = (0,l,r) \}$
      x0 = (struct Node *) mallocN (sizeof (struct Node));
// $\{\p{graph}(\tx x,\gamma) * \tx{x0} |-> \_, \_, \_ /| \gamma(\tx{x}) = (0,l,r) \}$
// $\searrow \{\tx x|-> 0,l,r * \tx{x0} |-> \_, \_, \_ /| \gamma(\tx{x}) = (0,l,r)\}$
      l = x -> l; r = x -> r; x -> m = x0; x0 -> m = 0;
// $\swarrow \left\{\!\!\!\begin{array}{l@{}} \tx x|-> \tx{x0},\tx{l},\tx{r} * \tx{x0} |-> 0, \_, \_ /| \\ \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /|  \exists \gamma_1 \gamma_1'. \m{v\_copy1}(\gamma, \tx{x}, \gamma_1, \gamma_1') \end{array}\right\}$
// $\left\{\!\!\!\begin{array}{l@{}}\exists \gamma_1 \gamma_1'. \p{graph}(\tx x,\gamma_1) * \tx{x0} |-> 0, \_, \_ /| \\ \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{v\_copy1}(\gamma, \tx{x}, \gamma_1, \gamma_1')\end{array}\right\}$
// $\left\{\!\!\!\begin{array}{l@{}} \p{graph}(\tx x,\gamma_1) * \tx{x0} |-> 0, \_, \_ /| \\ \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{v\_copy1}(\gamma, \tx{x}, \gamma_1, \gamma_1')\end{array}\right\}$
// $\left\{\!\!\!\begin{array}{l@{}} \p{graph}(\tx x,\gamma_1) * \tx{x0} |-> 0, \_, \_ * \p{holegraph}(\tx{x0}, \gamma_1') /| \\ \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{v\_copy1}(\gamma, \tx{x}, \gamma_1, \gamma_1')\end{array}\right\}$
// $\searrow \{\p{graph}(\tx l,\gamma_1)\}$
      l0 = copy(l);
// $\swarrow \left\{\!\!\!\begin{array}{l@{}} \exists \gamma_2 \gamma_2''. \p{graph}(\tx{l},\gamma_2) * \p{graph}(\tx{l0}, \gamma_2'') /| \\ \m{copy}(\gamma_1, \tx{l}, \gamma_2, \gamma_2'') /| \tx{l} \xleftrightarrow{\gamma_2} \tx{l0} \end{array}\right\}$
// $\left\{\!\!\!\begin{array}{l@{}} \exists \gamma_2 \gamma_2''. \p{graph}(\tx{x},\gamma_2)  * \tx{x0} |-> 0, \_, \_ * \p{holegraph}(\tx{x0}, \gamma_1') * \\ \p{graph}(\tx{l0}, \gamma_2'') /|\gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{v\_copy1}(\gamma, \tx{x}, \gamma_1, \gamma_1')/| \\ \m{copy}(\gamma_1, \tx{l}, \gamma_2, \gamma_2'') /| \tx{l} \xleftrightarrow{\gamma_2} \tx{l0}\end{array}\right\}$
// $\left\{\!\!\!\begin{array}{l@{}} \exists \gamma_2 \gamma_2'. \p{graph}(\tx{x},\gamma_2)  * \tx{x0} |-> 0, \_, \_ * \p{holegraph}(\tx{x0}, \gamma_2') /| \\ \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{v\_copy1}(\gamma, \tx{x}, \gamma_1, \gamma_1') /| \\ \m{e\_copy}(\gamma_1, \gamma_1', \tx{x}.L, \gamma_2, \gamma_2') /| \tx{l} \xleftrightarrow{\gamma_2} \tx{l0} \end{array}\right\}$
// $\left\{\!\!\!\begin{array}{l@{}}\p{graph}(\tx{x},\gamma_2)  * \tx{x0} |-> 0, \_, \_ * \p{holegraph}(\tx{x0}, \gamma_2') /| \\ \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{v\_copy1}(\gamma, \tx{x}, \gamma_1, \gamma_1') /| \\ \m{e\_copy}(\gamma_1, \gamma_1', \tx{x}.L, \gamma_2, \gamma_2') /| \tx{l} \xleftrightarrow{\gamma_2} \tx{l0} \end{array}\right\}$
      x0 -> l = l0;
// $\left\{\!\!\!\begin{array}{l@{}} \p{graph}(\tx{x},\gamma_2)  * \tx{x0} |-> 0, \tx{l0}, \_ * \p{holegraph}(\tx{x0}, \gamma_2') /| \\ \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{v\_copy1}(\gamma, \tx{x}, \gamma_1, \gamma_1') /| \\ \m{e\_copy}(\gamma_1, \gamma_1', \tx{x}.L, \gamma_2, \gamma_2') /| \tx{l} \xleftrightarrow{\gamma_2} \tx{l0}\end{array}\right\}$
// $\searrow \{\p{graph}(\tx r,\gamma_2)\}$
      r0 = copy(r);
// $\swarrow \left\{\!\!\!\begin{array}{l@{}} \exists \gamma_3 \gamma_3''. \p{graph}(\tx{r},\gamma_3) * \p{graph}(\tx{r0}, \gamma_3'') /| \\ \m{copy}(\gamma_2, \tx{r}, \gamma_3, \gamma_3'') /| \tx{r} \xleftrightarrow{\gamma_3} \tx{r0}\end{array}\right\}$
// $\left\{\!\!\!\begin{array}{l@{}} \exists \gamma_3 \gamma_3''. \p{graph}(\tx{x},\gamma_3) * \tx{x0} |-> 0, \tx{l0}, \_ * \p{holegraph}(\tx{x0}, \gamma_3') * \\ \p{graph}(\tx{r0}, \gamma_3'')  /| \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{v\_copy1}(\gamma, \tx{x}, \gamma_1, \gamma_1') /| \\ \m{e\_copy}(\gamma_1, \gamma_1', \tx{x}.L, \gamma_2, \gamma_2') /| \m{copy}(\gamma_2, \tx{r}, \gamma_3, \gamma_3'') /| \\ \tx{l} \xleftrightarrow{\gamma_2}  \tx{l0} /| \tx{r} \xleftrightarrow{\gamma_3} \tx{r0} \end{array}\right\}$
// $\left\{\!\!\!\begin{array}{l@{}} \exists \gamma_3 \gamma_3'. \p{graph}(\tx{x},\gamma_3) * \tx{x0} |-> 0, \tx{l0}, \_ * \p{holegraph}(\tx{x0}, \gamma_3')  /| \\ \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{v\_copy1}(\gamma, \tx{x}, \gamma_1, \gamma_1') /| \\ \m{e\_copy}(\gamma_1, \gamma_1', \tx{x}.L, \gamma_2, \gamma_2') /| \m{e\_copy}(\gamma_2, \gamma_2', \tx{x}.R, \gamma_3, \gamma_3') /| \\ \tx{l} \xleftrightarrow{\gamma_2} \tx{l0} /| \tx{r} \xleftrightarrow{\gamma_3} \tx{r0} \end{array}\right\}$
  \end{lstlisting}
\caption{Proof sketch for bigraph copy - part 1}
\label{fig:copy-part1}
\end{figure}

\newpage 

\begin{figure}
  \begin{lstlisting}
// $\left\{\!\!\!\begin{array}{l@{}} \p{graph}(\tx{x},\gamma_3) * \tx{x0} |-> 0, \tx{l0}, \_ * \p{holegraph}(\tx{x0}, \gamma_3')  /| \\ \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{v\_copy1}(\gamma, \tx{x}, \gamma_1, \gamma_1') /| \\ \m{e\_copy}(\gamma_1, \gamma_1', \tx{x}.L, \gamma_2, \gamma_2') /| \m{e\_copy}(\gamma_2, \gamma_2', \tx{x}.R, \gamma_3, \gamma_3') /| \\ \tx{l} \xleftrightarrow{\gamma_2} \tx{l0} /| \tx{r} \xleftrightarrow{\gamma_3} \tx{r0} \end{array}\right\}$
      x0 -> r = r0;
// $\left\{\!\!\!\begin{array}{l@{}} \p{graph}(\tx{x},\gamma_3) * \tx{x0} |-> 0, \tx{l0}, \tx{r0} * \p{holegraph}(\tx{x0}, \gamma_3')  /| \\ \gamma(\tx{x}) = (0,\tx{l},\tx{r}) /| \m{v\_copy1}(\gamma, \tx{x}, \gamma_1, \gamma_1') /| \\ \m{e\_copy}(\gamma_1, \gamma_1', \tx{x}.L, \gamma_2, \gamma_2') /| \m{e\_copy}(\gamma_2, \gamma_2', \tx{x}.R, \gamma_3, \gamma_3') /| \\ \tx{l} \xleftrightarrow{\gamma_2} \tx{l0} /| \tx{r} \xleftrightarrow{\gamma_3} \tx{r0} \end{array}\right\}$
// $\left\{\p{graph}(\tx{x},\gamma_3) * \p{graph}(\tx{x0}, \gamma_3') /| \m{copy}(\gamma, \tx{x}, \gamma_3, \gamma_3') /| \tx{x} \xleftrightarrow{\gamma_3} \tx{x0}\right\}$
  \end{lstlisting}
  \small
\begin{gather*}
  \p{holegraph}(x, \gamma)\defeq \underset{v\in\p{reachable}(\gamma, \tx x) - \{x\}}{\bigstar}v \mapsto \gamma(v)\\
\, \\
  \begin{split}
  \m{iso}(f_V, f_E, \gamma_1, \gamma_2) \defeq 
& f_V \text{ is a bijection between $\phi_V(\gamma_1)$ and $\phi_V(\gamma_2)$} /| \\
& f_E \text{ is a bijection between $\phi_E(\gamma_1)$ and $\phi_E(\gamma_2)$}  /| \\
& \forall e, f_V(s(\gamma_1, e)) = s(\gamma_2, f_E(e)) /| \\
& \forall e, f_V(d(\gamma_1, e)) = d(\gamma_2, f_E(e)) 
  \end{split} \\
  \begin{split}
  \m{v\_copy1}(\gamma_1, x, \gamma_2, \gamma_2')\defeq  \exists x'. & x \neq 0 /| \m{mark1}(\gamma_1,x, \gamma_2) /| \\
    & x \xleftrightarrow{\gamma_2} x' /| \gamma_2' = \{x_0\}
  \end{split}\\
  \begin{split}
  \m{copy}(\gamma_1, x, \gamma_2, \gamma_2')\defeq &\m{mark}(\gamma_1,x, \gamma_2) /| \\
   & \exists f_V f_E. \m{iso}(f_V, f_E,  \gamma_2\!\uparrow(\lambda v. x\mathrel{{\stackrel{\gamma_2~}{\leadsto^{\star}_{0}}}} v), \gamma_2') /| \\
   & \forall x x'. f_V(x) = x' \Leftrightarrow x \xleftrightarrow{\gamma_2} x'
  \end{split}\\
  \begin{split}
  \m{e\_copy}(\gamma_1, \gamma_1', e, \gamma_2, \gamma_2')\defeq & \exists \gamma_2''. \gamma_2' = \gamma_1' + \gamma_2'' /| \\
  & \m{mark}(\gamma_1,x, \gamma_2) /| \exists f_V f_E.  \\
   & \m{iso}(f_V, f_E,  \{e\} +\gamma_2\!\uparrow(\lambda v. x\mathrel{{\stackrel{\gamma_2~}{\leadsto^{\star}_{0}}}} v), \gamma_2'') /| \\
   & \forall x x'. f_V(x) = x' \Leftrightarrow x \xleftrightarrow{\gamma_2} x'
  \end{split}\\
  \begin{split}
&\text{Here, when we mention \m{mark} and \m{mark1}, the value 1s in the} \\
&\text{original definition are changed to non-zero values.}
  \end{split}\\
\end{gather*}
\caption{Proof sketch for bigraph copy - part 2}
\label{fig:copy-part2}
\end{figure}
 



\hide{
\begin{figure*}
Proof of \infrulestyle{Ramify-P} from \infrulestyle{Frame} and \infrulestyle{Consequence}:
\vspace{-3em}
\[
\begin{array}{c}
\infrule{}{
  G_1 |- L_1 * \pguards{c}(L_2 --* G_2) \\
  \infrule{}{\{L_1\}~c~\{L_2\}}
            {\{L_1 * \pguards{c}(L_2 --* G_2)\}~c~\{L_2 * \pguards{c}(L_2 --* G_2)\}}{(1)} \\
  \infrule{}{
            \infrule{}{\stackrel{\langle c \rangle}{\cong} \text{ is reflexive}}{\pguards{c}(L_2 --* G_2) |- L_2 --* G_2}{(2)}}
            {L_2 * \pguards{c}(L_2 --* G_2) |- G_2}{(3)}}
{\{G_1\}~c~\{G_2\}}
{} \\
[5pt]
(1)~ \forall P.~ \pguards{c}P \text{ ignores } \FV(c) \qquad (2)~ \text{axiom T of modal logic} \qquad (3)~ (P * Q |- R) <=> (P |- Q --* R)
\end{array}
\]

Proof of \infrulestyle{Ramify-PQ} from \infrulestyle{Ramify-P}:
\vspace{-4em}
\[
\begin{array}{c}
\infrule{}
{
  \{L_1\}~c~\{\exists x.~ L_2\} \hspace{-0.5em} \\
  \infrule{}
  {
    G_1 |- L_1 * \pguards{c}\big(\forall x.~ (L_2 --* G_2)\big) \hspace{-0.5em} \\
    \infrule{}{
      \infrule{}{
        \infrule{}{
          \vdots
        } {
          \forall x.~ (L_2 --* G_2) |- (\exists x.~ L_2) --* (\exists x.~ G_2)
        } {(1)}
      } {
        \pguards{c}\big(\forall x.~ (L_2 --* G_2)\big) |- \pguards{c}\big((\exists x.~ L_2) --* (\exists x.~ G_2)\big)
      } {(2)}
    } {
      L_1 * \pguards{c}\big(\forall x.~ (L_2 --* G_2)\big) |- L_1 * \pguards{c}\big((\exists x.~ L_2) --* (\exists x.~ G_2)\big)
    } {}
  } {
    G_1 |- L_1 * \pguards{c}\big((\exists x.~ L_2) --* (\exists x.~ G_2)\big)
  } {}
} {
  \{G_1\}~c~\{\exists x.~ G_2\}
} {}
\\
[5pt]
(1)~ \text{tautology using $(P * Q |- R) <=> (P |- Q --* R)$} \qquad (2)~ \text{reduction using modal axioms K and N} \end{array}
\]
\caption{Proofs of \infrulestyle{Ramify-P} and \infrulestyle{Ramify-PQ}}
\label{fig:rampqproofs}
\end{figure*}

See Figure~\ref{fig:rampqproofs} for the proofs of \infrulestyle{Ramify-P} and \infrulestyle{Ramify-PQ}. 
}

\section{Difficulty using $\graphkt$}
\label{apx:problemrecgraph}

\begin{figure*}
\[
\infrule{}
{\infrule{}
  {100 |-> 42,100,0 ~ |- ~ 100 |-> 42,100,0 ** \graphkt(100,\hat{\gamma})}
  {100 |-> 42,100,0 ~ |- ~ \hat{\gamma}(100) = (42,100,0) ~ /| ~ 100 |-> 42,100,0 ** \graphkt(100,\hat{\gamma}) ** \graphkt(0,\hat{\gamma})}
  {(2)}
}
{100 |-> 42,100,0 ~ |- ~ \graphkt(100,\hat{\gamma})}
{(1)}
\]
(1) Unfold $\graphkt$, dismiss first disjunct (contradiction), introduce existentials (which must be 42,100,0) \\
(2) simplify using $P * \p{emp} -|- P$ and remove pure conjunct

\caption{An attempt to prove a ``simple'' entailment}
\label{fig:badcycle}
\end{figure*}

See Figure \ref{fig:badcycle} for an attempt to prove the entailment $100 |-> 42,100,0 ~ |- ~ \graphkt(100,\hat{\gamma})$.  Part of the problem is that the recursive structure interacts very badly with $**$: if the recursion involved~$*$then it \textbf{would} be provable, by induction on the finite memory (each ``recursive call'' would be on a strictly smaller subheap).  This is why Knaster-Tarski works so well with list, tree, and DAG predicates in separation logic.

\section{Problem with Appel and McAllester's fixpoint}
\label{apx:appelfixpiont}

Appel and McAllester proposed another fixpoint $\mu_{\mathsf{A}}$
that is sometimes used to define recursive predicates in separation
logic \cite{appel:fixpoint}.  This time the functional $F_P$ needs to be
\emph{contractive}, which to a first order of approximation means that
all recursion needs to be guarded by the ``approximation
modality''~$\rhd$~\cite{appel:vmm}, \emph{i.e.} our graph predicate would
look like
\begin{align*}
\grapham(x, \gamma) ~ &\stackrel{\Delta}{=}\\
 (x = 0 /| \p{emp}) & |/ \exists m,l,r.~ \gamma(x)=(m,l,r) /| \null \\
 x |-> m,l,r & ** \rhd \grapham(l, \gamma) ** \rhd \grapham(r, \gamma)
\end{align*}

Unfortunately, $\rhd P$ is not precise for all $P$, so $\grapham$ is not precise either.  The approximation modality's universal imprecision has never been noticed before.

\section{Structure of the Garbage Collector Program}
\label{apx:gcstructure}



CertiCoq uses a generational copying garbage collector 
that is inspired by the OCaml GC. 
\hide{It leans on the empirical observation that
new blocks often need to be collected soon after their
allocation, while blocks that survive this initial
culling tend to live for much longer.
}The heap is divided into a series of disjoint
spaces called \emph{generations}. The size of the first generation
is carefully calculated, and then subsequent generations
double in size.
The mutator only ever allocates new memory in the first, 
smallest generation of heap, which is called the nursery. 
If it finds that the nursery is full, 
the mutator calls the GC to free up space.
The GC collects the nursery 
(now called the \emph{from} generation)
into the second generation (the \emph{to} generation): 
it examines the elements 
in \emph{from}, sees if they are accessible by
the mutator, and, if they are, 
copies them over to \emph{to}. This copying is achieved over a few steps, 
and we will explain these shortly, but the larger picture is that 
everything of importance in \emph{from} gets copied to \emph{to}, 
and so \emph{from} can safely be reset. 

An important subtlety here is that \emph{to} had enough 
room to accept \emph{from}'s items. 
In the (empirically improbable) worst case, 
\emph{all} of \emph{from}'s fields were copied over to \emph{to}.
Because \emph{to} has twice the capacity of \emph{from},
\emph{to} could not have been more than half full when 
the collection started.
This guarantee must be renewed before the next collection. 
So, in case the collection of the nursery caused
the second generation to become more than half full, 
the second generation is collected into the third. This makes 
both the first and second generations empty, thus ensuring 
the guarantee trivially. It should be 
clear to see that this may also trigger further collections in 
a cascade effect. The GC's task is only complete once this 
cascade (if any) is over. It returns control to the mutator,
which goes ahead with 
the allocation that it was trying to perform in the nursery.

Having shown that the overall collection 
works via (a series of) two-generational collections, 
we now zoom in and explain a two-generation collection.
The GC starts at the mutator-owned arguments array, whose fields
are either data, or pointers that point at memory blocks in the 
heap. It ignores the data entirely, and, among the pointers, 
cares only for the pointers that point into the \emph{from} generation. 
For each pointer that points into \emph{from}, it copies its
target block to \emph{to}, simply adding it in its entirety 
after \emph{to}'s last-used memory field, which is called \emph{next}. 

This operation only takes care of the blocks in the heap that 
the arguments array was pointing at directly, so the GC still has to copy 
over indirectly-accessible blocks. Of course, the only way to 
access an indirect 
block is via one of the direct blocks that it has
just finished copying into a contiguous array. 
It starts at the old \emph{next} in \emph{to}
and works its way ``upwards'' through the freshly copied blocks, 
again looking exclusively for pointers that point into \emph{from}
and copying over their target blocks into \emph{to}. 
In the \emph{to} generation, these newly copied blocks 
simply get stacked atop our first batch of copied blocks. 

The mutator's dependency graph has indefinite depth, so the second 
batch of copied blocks may still have pointers into \emph{from}. 
However, thanks to this systematic
copying strategy, it is very easy to take care of all indirect
blocks. The GC simply keeps scanning upwards in 
\emph{to}, copying over blocks from \emph{from} as necessary, 
until the scanning pointer catches up to the last-used field in
\emph{to}. This completes a collection 
from \emph{from} to \emph{to}, copying all blocks that lived
in \emph{from} and were of interest to the mutator. 
\emph{from} is now reset.

A good question at this juncture is why this rather selective scan 
of the args array and the heap is good enough to collect \emph{from}. 
The GC definitely collected every direct block by scanning the args array,
but what of the indirect blocks? Couldn't there be valid indirect links
that start either below \emph{next} in the \emph{to} generation, 
or from other generations altogether? 

Both of these turn out to be impossible because the 
mutator behaves in a purely functional manner.
The heap is chronologically
faithful, in that higher-indexed generations host
objects that were allocated earlier. Because
of the immutability of objects in a purely functional language, 
it is impossible for objects to point ``backwards'' to 
a younger generation, as the older object would not have
had known about the younger at the time of its allocation, and could not 
have been modified after its allocation. Fields living in generations 
younger than \emph{from} can point into \emph{from} during 
normal mutator activity, but this is
impossible at the time of collection: 
\emph{from} is only ever collected either if it is
the nursery or if a cascade effect has caused all generations younger
than it to be collected and reset. 
In fact, the only time the GC ever sees backwards pointers
is when it creates (and quickly fixes) them during during its 
activities.

\section{Code for Forward Relation}
\label{apx:forwardrelation}
  \begin{lstlisting}[basicstyle=\normalfont\tiny\tt],
  Inductive
forward_relation (from to : nat) : nat -> forward_t -> LGraph -> LGraph -> Prop :=
    fr_z : forall (depth : nat) (z : Z) (g : LGraph),
           forward_relation from to depth (inl (inl (inl z))) g g
  | fr_p : forall (depth : nat) (p : GC_Pointer) (g : LGraph),
           forward_relation from to depth (inl (inl (inr p))) g g
  | fr_v_not_in : forall (depth : nat) (v : VType) (g : LGraph),
                  vgeneration v <> from ->
                  forward_relation from to depth (inl (inr v)) g g
  | fr_v_in_forwarded : forall (depth : nat) (v : VType)
                          (g : LabeledGraph VType EType raw_vertex_block unit
                                 graph_info),
                        vgeneration v = from ->
                        raw_mark (vlabel g v) = true ->
                        forward_relation from to depth (inl (inr v)) g g
  | fr_v_in_not_forwarded_O : forall (v : VType)
                                (g : LabeledGraph VType EType raw_vertex_block unit
                                       graph_info),
                              vgeneration v = from ->
                              raw_mark (vlabel g v) = false ->
                              forward_relation from to 0 
                                (inl (inr v)) g (lgraph_copy_v g v to)
  | fr_v_in_not_forwarded_Sn : forall (depth : nat) (v : VType)
                                 (g : LabeledGraph VType EType raw_vertex_block unit
                                        graph_info) (g' : LGraph),
                               vgeneration v = from ->
                               raw_mark (vlabel g v) = false ->
                               let new_g := lgraph_copy_v g v to in
                               forward_loop from to depth
                                 (vertex_pos_pairs new_g (new_copied_v g to)) new_g
                                 g' ->
                               forward_relation from to (S depth) (inl (inr v)) g g'
  | fr_e_not_to : forall (depth : nat) (e : EType) (g : LGraph),
                  vgeneration (dst (pg_lg g) e) <> from ->
                  forward_relation from to depth (inr e) g g
  | fr_e_to_forwarded : forall (depth : nat) (e : EType) (g : LGraph),
                        vgeneration (dst (pg_lg g) e) = from ->
                        raw_mark (vlabel g (dst (pg_lg g) e)) = true ->
                        let new_g :=
                          labeledgraph_gen_dst g e
                            (copied_vertex (vlabel g (dst (pg_lg g) e))) in
                        forward_relation from to depth (inr e) g new_g
  | fr_e_to_not_forwarded_O : forall (e : EType) (g : LGraph),
                              vgeneration (dst (pg_lg g) e) = from ->
                              raw_mark (vlabel g (dst (pg_lg g) e)) = false ->
                              let new_g :=
                                labeledgraph_gen_dst
                                  (lgraph_copy_v g (dst (pg_lg g) e) to) e
                                  (new_copied_v g to) in
                              forward_relation from to 0 (inr e) g new_g
  | fr_e_to_not_forwarded_Sn : forall (depth : nat) (e : EType) (g g' : LGraph),
                               vgeneration (dst (pg_lg g) e) = from ->
                               raw_mark (vlabel g (dst (pg_lg g) e)) = false ->
                               let new_g :=
                                 labeledgraph_gen_dst
                                   (lgraph_copy_v g (dst (pg_lg g) e) to) e
                                   (new_copied_v g to) in
                               forward_loop from to depth
                                 (vertex_pos_pairs new_g (new_copied_v g to)) new_g
                                 g' ->
                               forward_relation from to (S depth) (inr e) g g'
  with forward_loop (from to : nat)
         : nat -> list forward_p_type -> LGraph -> LGraph -> Prop :=
    fl_nil : forall (depth : nat) (g : LGraph), forward_loop from to depth [] g g
  | fl_cons : forall (depth : nat) (g1 g2 g3 : LGraph) (f : forward_p_type)
                (fl : list forward_p_type),
              forward_relation from to depth (forward_p2forward_t f [] g1) g1 g2 ->
              forward_loop from to depth fl g2 g3 ->
              forward_loop from to depth (f :: fl) g1 g3
\end{lstlisting} 
 

\end{document}
