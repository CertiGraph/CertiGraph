===========================================================================
                          POPL 2017 Review #266A
---------------------------------------------------------------------------
Paper #266: The Ramifications of Mechanized Localizations within Data
            Structures
---------------------------------------------------------------------------

                      Overall merit: B. OK paper, but I will not champion
                                        it
                         Confidence: X. I am an expert in this area

                         ===== Paper summary =====

This work focuses on mechanized verification of graph algorithms,
implemented as heap-manipulated programs, in a general framework of
separation logic (SL). Unlike list- and tree-like data structures,
graphs are very tricky to reason about in SL because of so-called
"intrinsic sharing", making it impossible to "frame away" possibly
unrelated parts of the heap via the standard frame rule of SL,
commonly used for modular reasoning.

To enable SL-style _local_ reasoning about graph-shaped heaps, this
work employs the "ramified frame rule" from the recent work by Hobor
and Villard (HV). The paper makes an observation that HV's _Ramify_
rule is too weak for typical reasoning patterns and proposes its
strengthened version, accounting for the possible effects of changing
local variables by the subprogram being verified to the overall
"frame" in the presence of possible sharing between the "frame" and
the local footprint. This enhanced _ramify_ rule (as well as a number
of derived rules) is the main theoretical contribution of the paper.

On a more practical side, this work describes a library for reasoning
about mathematical graphs in Coq, which is then employed in the
context of verifying a number of sequential graph algorithms, such as
spanning tree construction, marking and graph copying. The
verification is conducted both in the VST framework by Appel et al. As
an evidence of the generality of the graph library, one of the
examples is also verified semi-automatically via HIP/SLEEK tool,
leveraged by a Coq-based back-end for discharging proof obligations
about graphs.

                           ===== Strengths =====

* To the best of my knowledge, this is the first systematic work on
  _mechanized_ verification of a _class_ of graph algorithms. Even
  though the algorithms considered here are arguably the most basic
  ones, I believe, the development provides enough conceptual evidence
  to extend these insights to more challenging case studies.

* The described graph library seems to be general enough to be useful
  for reasoning about a large class of graph procedures.

* An additional nice part of this work is re-assessment of HV work in
  the context of mechanized verification, identifying the weakness in
  the ramified frame rule.

                          ===== Weaknesses =====

1. The paper _does not make a good case_ that the ramified frame rule
   is absolutely essential for efficiently mechanized verification of
   graph algorithms in SL. That is, it seems that the reasoning in a
   similar style could, in fact, have been performed in a "large
   footprint", threading the entire graph structure in the assertions
   (without framing) and not employing the "overlapping" separating
   conjunction. It's not clear that such an alternative approach will
   impose some inherent additional proof burden.

2. Even though the paper is mostly easy to read, some of its parts
   seem to be quite unfocused and/or detached from the general
   context, discussing some aspects unrelated to the overall story
   about verifying graph algorithms

I elaborate on these points in my comments below.

                      ===== Comments for author =====

(1) The initial premise of the paper is that one should/wants to
formulate the _graph_ predicate in a style, similar to the way
tree-like structures are defined in SL.

However, later, the paper demonstrates that such formulation is
inadequate and suggests an alternative one, supplying it with some
additional equations, mimicking the "unfolding" behavior of a
recursive graph definition. Therefore, it seems that the verification
of the said algorithms could have been conducted out of the
alternative definition of the _graph_ predicate given in Section 4.2
of the paper. Indeed, it would be less SL-like, but it would allow to
avoid reasoning about ramifications and overlapping separating
conjunctions. So far, I fail to see immediate benefits of striving for
the "natural" definition and "zooming" on the subparts of the
graph-manipulating program being verified: it seems that the
alternative definition would work just fine for this purpose.

(2) In several places, the paper discussed topics which do not
contribute directly to the general story.

For instance, the whole discussion about _relational specification_ of
the procedure effects with respect to graphs seems irrelevant for the
future development (it would probably suffice to say that a form of
binary postconditions is used here to capture the relation between
input/output graphs).

In the same spirit, most of the discussion on the design of the graph
library seems too high-level to convey any useful insights. For
instance, I'm not sure what is the intended takeaway of the paragraph
"We use Coq’s typeclass system to manage our plugins in a smooth
manner [...]" Perhaps, it would be more beneficial if the paper were
structured as a tutorial, explaining in detail verification of one or
several examples, gradually introducing all necessary Coq-related
machinery and libraries. Since this is not the case here, the remarks
like the one above are distracting and non-informative.

For some reason, the paper features quite lengthy but irrelevant
discussion on Appel and McAllester's non-solution to the the recursive
definition problem (a remark in related work would be enough)?

It would be nice to see an application of the derived rules (6) and
(7) demonstrated in the context of a specific proof rather than in
this abstract discussion.

      ===== Questions for authors to address in rebuttal period =====

* Could you please comment on the point (1) of the critique above?

* How the "zooming" notation with diagonal arrows for the proof
  outlines is different from Wickerson et al.'s idea of ribbon proofs
  for separation logic?

* What is the purpose of the last conjunct in the definition of the
  _span_ predicate in Figure 10?

* The size of the Coq development for the three examples seems quite
  large (>3 KLOC, spanning 13 files). Could you elaborate on the
  sizes of specific proofs?

* The related work section mentions other results on verifying graph
  algorithms in Coq. Could you compare the approaches and outline main
  similarities/differences in the other formalizations of graphs
  algorithms with respect to this work?

===========================================================================
                          POPL 2017 Review #266B
---------------------------------------------------------------------------
Paper #266: The Ramifications of Mechanized Localizations within Data
            Structures
---------------------------------------------------------------------------

                      Overall merit: C. Weak paper, though I will not fight
                                        strongly against it
                         Confidence: Y. I am knowledgeable in this area,
                                        but not an expert

                         ===== Paper summary =====

The paper highlights and addresses several difficulties in the details of mechanized application of Hobor and Villard's "Ramification" technique for verifying graph-manipulating code.

One difficulty is the reliance on a syntax of formulas to define the notion of "free variable" used in the side conditions of inference rules.  Another is that the statement of the main "Ramify" rule has a variable occurrence condition with an annoyingly broader scope.

The paper also describes a Coq graph library that fits with the use case of data structure manipulation code verification.

The development supporting ramification-based reasoning is integrated with both the Verified Software Toolchain and HIP/SLEEK.  The paper describes these integrations.

                           ===== Strengths =====

- Clearly highlights detailed difficulties not normally emphasized

                          ===== Weaknesses =====

- It is not clear that this paper's contributions will be very valuable to more than a reasonably narrow audience.

                      ===== Comments for author =====

Can't the need for a fixed inductive syntax for formulas can be avoided by existentially quantifying the modified variables in the frame formula.  Or, equivalently, checking that F and exists ModVar(c). F are equivalent.

Statement of RAMIFY-PQ missing subscript on L

===========================================================================
                          POPL 2017 Review #266C
---------------------------------------------------------------------------
Paper #266: The Ramifications of Mechanized Localizations within Data
            Structures
---------------------------------------------------------------------------

                      Overall merit: C. Weak paper, though I will not fight
                                        strongly against it
                         Confidence: X. I am an expert in this area

                         ===== Paper summary =====

The paper presents an approach to mechanized verification of graph
algorithms in (sequential) separation logic.  The approach is based
closely on Hobor and Villard's previously published idea of
"ramification" (POPL'13).  Specifically, the contributions of the
present paper are as follows:

1. The paper begins by making some fairly minor updates to the basic
ramification rule in order to properly handle program variables and
existential variables in the general case.

2. It presents some libraries for reasoning about graphs in Coq,
although these are only discussed at a very high level.

3. It discusses the issue of how to represent graphs properly.  In
contrast to Hobor and Villard, which represented graphs as recursive
separation-logic predicates, the present paper adopts a flat
representation using iterated separating conjunction.

4. It explains how the ramification approach was integrated into Appel
et al.'s VST framework, as well as Chin et al.'s HIP/SLEEK framework
for more automated verification.  Concerning the latter, HIP/SLEEK is
generalized to allow it to make use of externally-verified lemmas,
which must be proven separately in Coq.

5. The VST framework is used to mechanize full functional correctness
of a few graph algorithms.  The HIP/SLEEK approach is used to verify a
single graph-marking algorithm.

                           ===== Strengths =====

- The improvements to the ramification rule for handling program
variables and existential variables are appealing and well explained.

- The paper demonstrates a significant effort in proof engineering.

                          ===== Weaknesses =====

I appreciate the goal of engineering proof technologies that work well
when mechanized, but I'm afraid that, in terms of new proof
engineering ideas, this paper comes up short.

- Section 2 on the improvements to the ramification rule is
well-written, and makes a good introduction to the ramification rule,
but the improvements are really pretty minor.  Also, they seem to be
motivated primarily (or solely?) by program variables, which I find
uninspiring.  (There are known ways of eliminating program variables
and working with a more uniform heap-based model, so this does not
feel like a fundamental problem.)

- Section 3 is very high-level, and I failed to get much useful out of
it.  The authors have developed what looks like a reasonably
well-structured graph library, but there did not seem to be much that
was particularly interesting here.

- Section 4 makes a lot of fuss about a completely standard and
well-known idea, which is to use a flat representation and iterated
separating conjunction.  (I have used such representations in my own
work on separation logic, and so have many others.)  IMHO, this is
indeed the obvious way of representing a general graph data structure
because of cycles, so I failed to see what was interesting or novel in
this section.

- Section 5 on the extensions to VST seemed like fairly
straightforward tactic engineering.  Well done, but nothing
surprising.  Did I miss something that was supposed to be surprising
here?

- Section 6 was the most interesting to me, since it promised some
integration of the ramification rule into the more automated HIP/SLEEK
tool.  Unfortunately, here it is revealed that this approach is only
applied to a single, very simple (8-line) algorithm, and much of the
proof (around 400 lines of key lemmas, which constitute the meat of
the proof) is still done manually in Coq.  Furthermore, the detailed
discussion of the proof itself (in Section 6.3) left me lost in the
weeds and missing a broader perspective.  For instance, the natural
question after reading Sections 5 and 6 is: why is it more natural for
the "automatic" HIP/SLEEK tool to work with overlapping conjunction,
but the overlapping conjunction is not used for the fully manual Coq
proofs?  This very basic question, which is at the core of the
difference in the two approaches, is never answered.

In the end, I failed to see what constitutes a significant new idea in
this paper.  The basic ramification idea is prior work, the
mechanization (while worthwhile) seems to have involved pretty
standard techniques, and the potentially interesting application to
the more automated HIP/SLEEK tool is clearly preliminary.  Thus, as it
stands, the paper seems more appropriate for a proof mechanization
conference like CPP or ITP.

                      ===== Comments for author =====

Generally, the low-level writing in the paper is reasonably good.
However, there are various points where the authors use irritatingly
twee language ("the program variable bugaboo", "the existential ogre",
"an honest academic tries to prove a simple entailment"), which I would
suggest to remove.

- p2: "it is probably a mistake to write (1) as a definition...rather
than as a biimplication."  It **is** written as biimplication, so it's
not clear at this point what you're talking about.

- p3: "The side condition F ignores ModVar(c) relates". Put commas
around "F ignores ModVar(c)".

- p4: "substitute x for 6" -> "substitute 6 for x"

- footnote 3: perhaps clarify what modal operator you're talking about

- Figure 4: "Instantializes" -> "Instantiates"

- p5: "Finally, s and e" -> "Finally, s and t"

- p5: "edges and vertices related" -> "...are related"

- p6: "contains the all" -> "contains all"

- p6: "Much more interesting is the concept of GeneralGraph".  Why is
it much more interesting?

- Figure 6: "Lemms" -> "Lemmas".  Also, I couldn't understand what this
figure was supposed to convey.

- p6: "forall any" -> "for any"

- p6: "none-the-less" -> "nonetheless"

- p7: displayed formula at the end of section 3.  I don't understand
what I'm supposed to get out of seeing this formula, esp. given that
it is not explained.

- p7: "Unfortunately, later P is not precise for all P..."  I think
this comment needs some more explanation to be useful.

- p8: "On the other hand, for HIP/SLEEK fold/unfold is vital, and
knowing that the recursive relationship holds produces a pleasant
feeling."  Produces a pleasant feeling?

- p8: "We provide of our spatial".  Missing a word, I think.

- p9: "not know how which" -> "not know which"

- p9: "show our a" -> "show our"

- p9: "Observe that the span relation is rather long."  Why is this
a useful thing to observe?

- p10: "line 13 contains" -> "line 13"

- p11, fourth display: there are l's appearing in different fonts.

- Section 6.4: "...users must build a Coq module...using definitions
for the abstract relations that they think are reasonable".  What do
you mean by "that they think are reasonable"?  I must admit that based
on the code snippets in Figures 11 and 12, I don't have a clear
understanding of how the Coq verification and the HIP/SLEEK
verification fit together in a formal sense.  What is the formal model
for proofs that combine HIP/SLEEK and Coq?  Is it possible to prove
something vacuous by instantiating Mgraphmark in an "unreasonable"
way?

- Section 6.5: the "precise(P)" side condition should be
"precise(L1)".

- p11: "not burdensome" -> "is not burdensome"

- p12: The section on comparison with Hobor and Villard is a dead
giveaway that one of the present authors is Hobor or Villard.  It is
not appropriate to say that "they hacked their way around..." or
"they fell into the trap..." in a double-blind submission.

- p12: "unfortunately other members of the research community have
since followed them in."  No citation is given, and I'm not sure who
the authors are referring to.  If you're going to besmirch other
researchers, you should at least say who you're talking about.

- p12: "program and existential quantifiers" -> "program variables and
existential quantifiers"

===========================================================================
        Rebuttal Response by Aquinas Hobor <AquinasHobor@live.com>
---------------------------------------------------------------------------
We would like to thank reviewers for their time, especially reviewers A & C for their detailed comments.  However, we strongly disagree with reviewer C’s characterization of our work, especially in sections 2 and 4.

Specifically, in section 2 reviewer C’s suggestion to instead use standard techniques like “a more uniform heap-based model”, by which we think C means “variables as resource” is a cop out.  Both VST and H/S use the standard model for program variables.  Both have very large codebases (about 140k and 179k LOC respectively, each representing more than 50 person-years of work), and in both cases it would be a massive effort to rewrite something as fundamental as their treatment of modified program variables.  Moreover, as we mention in section 8, most other verification tools also model program variables in the standard way.  We want a solution that is widely applicable to tools as they actually exist today.  One measure of showing that we have accomplished this is that the modifications to Floyd and H/S (1.9k and 2.5k LOC as per Table 1) were only approximately 1.4% of their respective codebases.  (We mention in 2.4 that systems that do not wish to add our modal operator [c] can bundle the RAMIFY-PQ and SOLVE RAMIFY-PQ rules together.)

Given this strong motivation to work within the standard model for program variables, we also reject the idea that the modifications were straightforward.  Firstly, finding a relatively short and clean rule that works in practice and at scale is usually difficult, and the amount of ink needed to express such a rule is not a good metric of the significance of the accomplishment.  Even if it were, since the RAMIFY-PQ and SOLVE-RAMIFY-PQ rules are designed together, the “new style” has two entailments (rather than just one in RAMIFY) as well as a universal quantifier so that we can extract existential quantifiers from the localization block.  Secondly, to dismiss the second entailment automatically requires the rather delicate and subtle manipulations we show in 2.3, so in fact the design of RAMIFY-PQ, SOLVE-RAMIFY-PQ, and these manipulations were all tightly interlinked.  Finally, even in a variables-as-resource world we would need to extract existential quantifiers to specify programs relationally rather than functionally, e.g. in lines 25-26 in figure 1.

In section 4, we did not mean to claim that “flat” graphs originated with us, and apologize if it came off that way.  What was new was 4.1 (showing that standard recursive methods fail) and the second half of 4.2 (showing that we can recover the fixed point).  We know of published uses of “flat” graphs that do *not* use fold-unfold as well as published uses of “recursive” graphs (beyond Hobor & Villard) that contain the mistake uncovered in 4.1.  We are unaware of any published work that defines graphs in a flat way and then shows that you can still reason recursively, which is the main result of 4.2.  Moreover, proving fold/unfold is not trivial (e.g. in the <= direction one runs into alignment/skewing issues).

In response to reviewer A's questions:

1. You are asking about several distinct things.  First, we are aware of three different SL graph definition styles: fold/unfold (as in Figure 1), flat-but-rooted (as in section 4.2), and flat-whole-graph (as in [Sergey et al. 2015]).  The major advance in section 4 was that the first two styles are mutually compatible – call both of them in the “local style” because the graph predicate takes both a mathematical graph and a root.  The third “global style”, in which the graph predicate takes a mathematical graph but no root, is not compatible with fold/unfold but we do not say (or think) that means it is an unreasonable choice.

We used local style fold/unfold graphs in Figure 1 because we think it most closely mirrors traditional SL proofs and would thus be the simplest for readers to follow.  We do think that the program invariants in Figure 1 are natural, which we think is important.  However, global style graph predicates can also produce natural invariants, and we encourage experimentation; generally speaking we think that the more options verifiers have the better.  In most of our VST proofs we used the flat-but-rooted style since with the aid of a clever human we found we did not need fold/unfold.  In our H/S proof we did use fold/unfold because they mirror the way H/S treats other predicates in SL, allowing us to leverage other parts of the H/S codebase.  However, we suspect that with additional work H/S could do global-style proofs as well.  (We also note as an aside that the arguments for global-style graphs in concurrent settings may be stronger than they are in the sequential settings we considered.)

Second, you are asking about whether the “ramified frame rule” is essential.  To do the recursive calls, global style proofs do not need such a rule (a point in their favor), although our ramification library makes such localizing straightforward in the context of a concrete verification.  However, to modify the root, we believe both the local and the global styles essentially need a ramification.  That is, you need to do a fancy frame (the rest of the graph, expressed one way or another), a local modification to the node you are left with, and then after getting the frame back a fancy rule of consequence (to move from mathematical graph g1 to mathematical graph g2, where g2 has been updated from g1 appropriately).  Ramification packages this idea up nicely, but you could do it with FRAME and CONSEQUENCE directly if you preferred.  Similarly, RAMIFY-PQ is useful for more than just graphs.  For example, recently the proof of the LOAD rule in VST was nicely simplified using localize and unlocalize rather than explicit FRAME and CONSEQUENCE.  (Note that LOAD of course also modifies program variables.)

2. Ribbon proofs are a way to visualize FRAME (how spatially distinct premises are “piped around”).  Localization proofs are a way to visualize RAMIFY (how changes in the local state impact the global).  This is part of why we sometimes put lightning bolts with lemma numbers (e.g. line 18 in figure 1).  Ribbon proofs don’t need lightning bolts because they are just FRAME.

3. If “x |-> left, right”, and “left is a tree”, and “right is a tree”, you don’t know that x is a tree (the simplest counterexample is when left = right).  It took some effort to find this conjunct.

4. * mark (both graph & dag): 5 files; 1,039 lines
* copy (graph): 4 files; 1,027 lines
* spanning tree (graph): 4 files; 1,187 lines

We have two general points about the length.  First, most of our mathematical proofs are done in general settings – for example, most of our proofs about “copy” do not assume that a node has at most two children.  This adds some effort but lets us apply them in more settings.  Second, some of the size is just due to the complexity of verifying real code.  For comparison, verifying a simple list-based merge sort in VST takes 600 lines.

5. Yang used many explicit wands.  Bornat et al. used * to partition the graph into many disjoint pieces based on reachability.  Reynolds presented U* but never really used it.  Gardner et al. used U* in a single specific spot and reasoned about it in an ad-hoc way.  Raad et al. used fold/unfold graphs in a concurrent setting (as did Hobor & Villard and as does H/S and 1 VST verification in the present paper).  Sergey et al. used a global-style graph also in a concurrent setting (but did not have any kind of fold/unfold ability).  Leino used a global-style graph in a sequential (non-SL) setting and so also did not have any kind of fold/unfold, although he did modify the vertices represented in the graph as he processed nodes so it could be considered a hybrid of the global style and the flat-but-rooted/local style.
