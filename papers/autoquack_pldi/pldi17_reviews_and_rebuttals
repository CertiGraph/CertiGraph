===========================================================================
                           PLDI '17 Review #298A
                    Updated 13 Feb 2017 11:20:27am EST
---------------------------------------------------------------------------
Paper #298: The Ramifications of Mechanized Localizations within Data
            Structures
---------------------------------------------------------------------------

                 Reviewer expertise: Y. Knowledgeable
                      Overall merit: C. Weak paper, though I will not fight
                                        strongly against it

                           ===== Strengths =====

- This paper presents a solution to the challenging problem of verifying algorithms that manipulate graph structures in the heap.
- There is extensive formal and mechanized development that backs this paper.

                          ===== Weaknesses =====

- The work extends two verification tools that emphasize different aspects (e.g., automation versus expressivity), but the two extensions are not treated equally. The evaluation could be strengthened by considering more examples.
- The presentation of the paper's contributions is fragmented.

                      ===== Comments to authors =====

# Summary

This paper considers the problem of mechanically verifying code that manipulate pointer-based graph structures in the heap. The key idea is to adapt and apply the "ramify" reasoning rule in a deductive verification framework. The ramify rule is a generalization of the frame rule that enables local reasoning without a strict, syntactic framing of unmodified memory. This mechanization of ramify is presented in the context of the Verified Software Toolchain (VST) and the HIP/SLEEK verifier. The main result is a verification of C and Java code that marks a graph.

# Comments

The central motivating example in this paper is verifying a function that marks the nodes of a heap-allocated, pointer-based data structure. This code is particularly challenging to verify because the algorithm makes no a priori assumption about the structure---it is simply a graph that can have arbitrary sharing including cycles. This example is presumably a pre-cursor to verifying the correctness of a garbage collector. 

To make the verification reasonable, one would like to leverage local reasoning approach put forth by separation logic, but the arbitrary sharing makes the application of separation logic's frame rule untenable. This challenge is what the paper calls the "intrinsic sharing" problem. This motivation is clear from Section 2.

From the theoretical perspective, the main contribution of this paper, in my words, is to generalize the ramify rule to be able reason about modifications in a localized sub-heap. This is an important step to making the ramify rule practically useful in an automated verifier. The paper then describes a mechanization of this generalized ramify rule in the form of Coq tactics as part of VST. While ramify has been previously published, the generalization and mechanization represents an important advance.

Regarding the presentation of ramify, I found Section 4.1 to be fascinating, but
it seemed buried. I would have preferred a discussion of this separated from the
mechanization discussion, perhaps coming right after Section 2 (or even Section
2.2). I think this discussion could have been more clear and direct by separating the concepts underlying ramify from its mechanization.

While I am overall supportive of this paper, it could be a much stronger paper if it were more focused in its presentation. The HIP/SLEEK discussion in Section 3 and 4.4 are disconnected from the main thread, which made it hard to follow. Similarly, the graph reasoning library described in Section 5, while necessary, also feels disconnected.

I don't think this was explicitly mentioned, but I think the point of the HIP/SLEEK discussion is to demonstrate that ramify is useful both for more manual verification as in VST/Floyd or something more automated (even though loop invariants are still required in HIP/SLEEK). This would have been more convincing if both the marking and the copy algorithms were verified in both tools.

A related area of work is on shape analysis for data structures with sharing. The tradeoffs, considerations, challenges are different since typically these works focus on simpler shape properties than full functional correctness
on more structured data structures, but they also perform invariant inference. 

- Oukseh Lee, Hongseok Yang, Rasmus Petersen:
Program Analysis for Overlaid Data Structures. CAV 2011: 592-608.
- Cezara Dragoi, Constantin Enea, Mihaela Sighireanu:
Local Shape Analysis for Overlaid Data Structures. SAS 2013: 150-171.
- Huisong Li, Xavier Rival, Bor-Yuh Evan Chang:
Shape Analysis for Unstructured Sharing. SAS 2015: 90-108.

A potential connection is that these works use unfold/fold reasoning with some structure-specific semantic reduction with a (potentially implicit) flat representation (like in Section 6.2).

# Editing

- p2, Fig 2: |= 2 -> |= Q

# Questions

- Out of interest, what are the kinds of examples best suited for this verification technique? Are there examples in addition to these algorithms in a garbage collector?

# Summary of the PC Discussion

The PC discussed this paper at length. Major concerns included a presentation that is hard to follow and identify the substantive contributions. The possible automation offered by the integration with HIP/SLEEK is potentially significant but seems preliminary at this time.

The PC also discussed the points raised in the response regarding the previous POPL reviewers. The fact that a previous POPL reviewer re-reviewed this paper for PLDI was not intentional but coincidental; it is bound to happen in trying to find expert reviewers. While coincidental to have had the same reviewer, the PC also believes this was a potential opportunity for this paper to be considered in the context of its improvement since its last submission. The PC suggests that a positive dialogue focusing on how the paper has improved would be more effective in future iterations.

===========================================================================
                           PLDI '17 Review #298B
---------------------------------------------------------------------------
Paper #298: The Ramifications of Mechanized Localizations within Data
            Structures
---------------------------------------------------------------------------

                 Reviewer expertise: Y. Knowledgeable
                      Overall merit: C. Weak paper, though I will not fight
                                        strongly against it

                           ===== Strengths =====

+ the class of verified algorithms is challenging, off limits for current verifiers

                          ===== Weaknesses =====

- I don't find the contribution important enough for PLDI 
- the presentation is poor

                      ===== Comments to authors =====

This submission focusses on verifying programs that manipulate data structures with complicated sharing layouts such as unrestricted graphs. This submission proposes a theory to mechanically verify such programs, using an extension of separation logic axiomatized in Coq.  
The framework is integrated with VST Verified software toolchain, which leads to end-to-end machined checked proofs and HI/SLEEK a semi-automated verification engines, that uses less human intervention compare with VST, by asking an expert only for inductive invariants. 

Verifying programs that manipulate graph like structures is a big challenge.  Separation logic has been successfully applied to automatically verify programs that manipulate recursively defined data structures, as long as these structures share zero or a clearly identified elements. In case the program creates unrestricted graphs sharing is no longer identifiable. This submission verifies mechanically several challenging graph algorithms such as: marking the nodes of a potentially cyclic graph, pruning a graph into a spanning tree, and copying a graph. 

The paper builds on [16] which addresses the verification of the same class of programs, but proposes pen and paper proofs using separation logic extended with a ramification rule. The contribution of this submission consists in mechanizing those proofs. 
The key inside to deal with data structures with intrinsic sharing is to express their configuration with recursive predicate in combination with the overlapping conjunction, and to use the ramification rule to reason modularly about the semantics of program instructions (same as [16]). 


My first concern is that the paper is dense in notations and the results are accessible to only a niche experts. 
From a practical perspective the main contribution is the mechanization of the proofs, which is possible due to the integration of the framework with VST and HIP/SLEEK. However, I am not sure to understand the technical challenges that mechanization imposed. 
From a theoretical perspective, the main contribution is the generalization of the ramification rule, allowing to deal with free variables side conditions. However, the paper does not say clear if the generalization is necessary for the mechanized proofs. They add elegancy to the proofs indeed, but what are the examples for which these rules are necessary ? 

Some comments and questions: 
- The presentation is not easy to follow. The motivating example sends so many pointers to future explanations that becomes confusing. I find the discussion about notationâ€™s succinctness in sec 2 almost irrelevant compared to giving at least the intuition of the semantics of one of the F formulas used in the motivating example. 
The rule ramify-PQ is used in Fig. 1. It would have been more natural to explain it on this example and not on some unrelated program instruction just to refer at the end to function mark.  
- Regarding  the recursive definition of an unstructured graph: I can see how this predicate is not standard, in the sense that unfolding it does not lead to predicates representing smaller subheaps. So indeed it might pose problems, at least to an automated verifier. However, I could not understand why your definition does not have the same problem. 
- Could you apply Ramify-PQ to functions that do no preserve the graphâ€™s set of nodes ?
- Overlaid data structures have also unstructured sharing. Does you theory apply to programs manipulating such structures ?

===========================================================================
                           PLDI '17 Review #298C
                     Updated 30 Jan 2017 1:16:31pm EST
---------------------------------------------------------------------------
Paper #298: The Ramifications of Mechanized Localizations within Data
            Structures
---------------------------------------------------------------------------

                 Reviewer expertise: Z. Some familiarity
                      Overall merit: C. Weak paper, though I will not fight
                                        strongly against it

                           ===== Strengths =====

* Smart proof engineering

                          ===== Weaknesses =====

* It is unclear if the approach really solves he problem: I am convinced it works for the mark example, but what about different graph algorithms written by other people?

                      ===== Comments to authors =====

== Summary 

Graph-manipulating programs are hard to verify in general. In the separation logic setting, the problem is even worse (because by definition graphs have intrinsic sharing).
A lot of work has been devoted on pen & paper proof of graph algorithms in separation logic, and in particular Hobor and Villard developed a theory of ramification to relax the rigidity of the frame rule. In the submission, the authors improve on the ramification theory to make it amenable to be used in a proof-assistant.


== Evaluation

Section 1 introduces the Verified Software Chain and the HIP/SLEEK verifiers in a quite approximative way - to really understand it I had to do some Google search. It would be useful if the introduction is enlarged to provide more details on the tools, their successes and limits.

The informal discussion of the approach in Section 2 is pretty good, but the presentation can be improved. For instance at first I thought the font used for "mark" was a typo (missing a mathsf) and the caption for fig.1 let me ignore the definitions for the predicate graph, etc. 

Even if they provide many proof engineering details, or probably because of that Sect 3 and 4 are very interesting.

It is unclear to me how Section 5 ("Framework for graph theory") connects to the previous two sections. To me it's kind of orthogonal, if this is the case, should be moved earlier? In a way it breaks the narrative that you have after with Section 6.
Section 6, with the discussion of the limits of "informal" fixpoint definitions is may favorite of the paper. I wonder if such part can be expanded and more articulated in a successive paper? I am asking that because I have some intuition that there may be  some deeper result there.

The experimental section is the most deceiving part of the paper. The numbers of lines of the tool/development is probably less interesting that the time it took to you. Also, what about the verification efforts, which other programs you verified, apart  from the running example?

===========================================================================
                           PLDI '17 Review #298D
---------------------------------------------------------------------------
Paper #298: The Ramifications of Mechanized Localizations within Data
            Structures
---------------------------------------------------------------------------

                 Reviewer expertise: X. Expert
                      Overall merit: C. Weak paper, though I will not fight
                                        strongly against it

                           ===== Strengths =====

I have previously reviewed this paper for POPL.  This appears to be
essentially a resubmission of the original paper, with the sections
rearranged and some text removed to fit the PLDI page limit.  So I am
resubmitting the main part of my original review (minus the list of
typos).  I give some additional comments at the end about the authors'
previous rebuttal and why I (and the other POPL reviewers) were not
convinced.

---------

Summary:

The paper presents an approach to mechanized verification of graph
algorithms in (sequential) separation logic.  The approach is based
closely on Hobor and Villard's previously published idea of
"ramification" (POPL'13).  Specifically, the contributions of the
present paper are as follows:

1. The paper begins by making some fairly minor updates to the basic
ramification rule in order to properly handle program variables and
existential variables in the general case.

2. It presents some libraries for reasoning about graphs in Coq,
although these are only discussed at a very high level.

3. It discusses the issue of how to represent graphs properly.  In
contrast to Hobor and Villard, which represented graphs as recursive
separation-logic predicates, the present paper adopts a flat
representation using iterated separating conjunction.

4. It explains how the ramification approach was integrated into Appel
et al.'s VST framework, as well as Chin et al.'s HIP/SLEEK framework
for more automated verification.  Concerning the latter, HIP/SLEEK is
generalized to allow it to make use of externally-verified lemmas,
which must be proven separately in Coq.

5. The VST framework is used to mechanize full functional correctness
of a few graph algorithms.  The HIP/SLEEK approach is used to verify a
single graph-marking algorithm.

---------

Strengths:

- The improvements to the ramification rule for handling program
variables and existential variables are appealing and well explained.

- The paper demonstrates a significant effort in proof engineering.

                          ===== Weaknesses =====

[Below, the section numbers pertain to the original submission.
The PLDI submission permutes them.]

I appreciate the goal of engineering proof technologies that work well
when mechanized, but I'm afraid that, in terms of new proof
engineering ideas, this paper comes up short.

- Section 2 on the improvements to the ramification rule is
well-written, and makes a good introduction to the ramification rule,
but the improvements are really pretty minor.  Also, they seem to be
motivated primarily (or solely?) by program variables, which I find
uninspiring.  (There are known ways of eliminating program variables
and working with a more uniform heap-based model, so this does not
feel like a fundamental problem.)

- Section 3 is very high-level, and I failed to get much useful out of
it.  The authors have developed what looks like a reasonably
well-structured graph library, but there did not seem to be much that
was particularly interesting here.

- Section 4 makes a lot of fuss about a completely standard and
well-known idea, which is to use a flat representation and iterated
separating conjunction.  (I have used such representations in my own
work on separation logic, and so have many others.)  IMHO, this is
indeed the obvious way of representing a general graph data structure
because of cycles, so I failed to see what was interesting or novel in
this section.

- Section 5 on the extensions to VST seemed like fairly
straightforward tactic engineering.  Well done, but nothing
surprising.  Did I miss something that was supposed to be surprising
here?

- Section 6 was the most interesting to me, since it promised some
integration of the ramification rule into the more automated HIP/SLEEK
tool.  Unfortunately, here it is revealed that this approach is only
applied to a single, very simple (8-line) algorithm, and much of the
proof (around 400 lines of key lemmas, which constitute the meat of
the proof) is still done manually in Coq.  Furthermore, the detailed
discussion of the proof itself (in Section 6.3) left me lost in the
weeds and missing a broader perspective.  For instance, the natural
question after reading Sections 5 and 6 is: why is it more natural for
the "automatic" HIP/SLEEK tool to work with overlapping conjunction,
but the overlapping conjunction is not used for the fully manual Coq
proofs?  This very basic question, which is at the core of the
difference in the two approaches, is never answered.

In the end, I failed to see what constitutes a significant new idea in
this paper.  The basic ramification idea is prior work, the
mechanization (while worthwhile) seems to have involved pretty
standard techniques, and the potentially interesting application to
the more automated HIP/SLEEK tool is clearly preliminary.  Thus, as it
stands, the paper seems more appropriate for a proof mechanization
conference like CPP or ITP.

                      ===== Comments to authors =====

Comments about/after POPL rebuttal:

The authors disputed specifically my characterization of Sections 2
and 4 (which are Sections 4 and 6 in the PLDI submission).

- I claimed that the improvements concerning treatment of program
variables were only of minor interest.  They said this comment was not
appropriate because real programs do use program variables, and that
if I was suggesting to use "variables-as-resource", then that was a
cop-out.  Actually, what I was suggesting was that there is nothing
fundamental about variables that should make them so challenging to
reason about.  One option is variables-as-resource; another is to just
apply a program transformation that replaces variables with memory
locations and variable occurrences with pointer dereferences.  I
appreciate that if one wants to reason about variables directly
without applying the above techniques, as the authors do, then there
are some engineering issues, but nothing considered in the paper
struck me as a particularly deep problem.

- Concerning the section on graph representation, the authors claimed
the major point was to show how one could recover "fold-unfold" lemmas
even when one uses a flat representation of graphs.  Perhaps this is
of interest, but the paper only claims that these lemmas are relevant
to HIP/SLEEK, and there is (still) only one 8-line case study given
for the HIP/SLEEK part of the paper.  So I continue to be unconvinced
that this constitutes a major contribution.

All in all, the paper was rejected from POPL because the reviewers
felt the work was pretty incremental compared to the previous paper on
the ramified frame rule: a bunch of small engineering improvements
without overwhelming evidence of success.  Given that the present
paper seems to have been reorganized but not much revised, my opinion
still stands.


===========================================================================
             Response by Aquinas Hobor <AquinasHobor@live.com>
Paper #298: The Ramifications of Mechanized Localizations within Data
            Structures
---------------------------------------------------------------------------
We would like to thank reviewers A, B, and C for their reviews.  We will use them to improve our paper.

We are disappointed that reviewer D has given only a cursory reread/rereview (e.g. his review still refers to our old section numbers).  Review D gave a detailed and careful review at POPL, although we disagreed with some of his assertions (see below for our response to the points at which we disagree).  A second POPL review was very short (by a non-expert) and the last (by another expert) was also long while being substantially more positive.

We made quite a few changes to the paper after reading and thinking about all of our POPL reviews (our response to reviewer D below discusses some of these that are relevant to his review).  Like many others, both this year and in the past, we hoped that these changes, plus a set of "fresh eyes", would lead to a better understanding of our result at another conference, or at least new suggestions for further improvements.

Accordingly, we are particularly disappointed that reviewer D brings in "the Ghost of POPL Reviewers Past" in the new preamble and coda to his review.  An argument from authority is not appropriate in the context of PLDI, which is an independent conference from POPL.  If those other reviewers are involved in PLDI then they can reread the paper and speak for themselves.  If not then they should be kept out of the discussion given that they have not re-reviewed (nor presumably reread) the paper and will not participate in the PC discussion.

We now provide a detailed response to all four reviewers as follows.

Response to reviewer A:

Sections 4.1 and 4.2 used to be after section 2.2 in the previous version of our paper.  We believe they are one of the two major theoretical advances in our paper.  Our earlier reviews seemed to suggest that we move the examples forward, which we also hoped would be a better "fit" for PLDI.  However, given the reviews from PLDI, we now believe this was the wrong choice.

Likewise, H/S was moved earlier due to our interpretation of previous reviews.  We absolutely agree that it would be better if we had more examples in H/S, and indeed we spent quite a bit of time between POPL and PLDI trying to get "spanning tree" to work.  Unfortunately, as we mention at the end of section 3.1, we run into other issues, mostly related to the expressivity allowed in H/S's assertion language.  The requirement that  all spatial predicates have a "root pointer" was the blocking issue to get "spanning tree" to work.  Briefly, this requirement prevents spatial predicates indexed from a set: e.g. "tree(x)" is allowed, where x is an address, but "trees(S)", where S is a set of vertices, is not.  Unfortunately this requirement seems to be fairly deeply "baked in" to H/S at the moment, so even though it is in one sense not related to ramification at all, it is preventing our examples from going through.  We are in the process of investigating "copy" to see if the proo
 f can be restructured to avoid this problem, but it is not straightforward.

Thank you for your suggested references.  Beyond agreeing that this line of research is worth mentioning in general, we will look carefully to see if their use of fold/unfold is relevant to our 6.2.

To answer your question, we are in the process of verifying a ~400-line garbage collector for CertiCoq (https://www.cs.princeton.edu/~appel/certicoq/).  Thus far, we needed no changes or generalizations to the theory presented in the paper, although VST has required some generalizations and we are not finished.

Response to reviewer B:

Absent program transformations or using variables-as-resource (neither of which is supported by VST or H/S, or indeed many other existing verification tools), the new RAMIFY-P and RAMIFY-PQ rules definitely seem necessary.  Without them we do not know how to verify lines 11 and 17-19 in figure 1 (we need the ability to ramify over lines that modify local variables).  Moreover, if that modification is nondeterministic (e.g. due to "malloc") then we need the ability to extract existential quantifiers as discussed at the start of section 4.2.  It's hard to write a useful program that doesn't modify local variables in key spots, and many useful programs allocate memory.

In addition, we do not know how to verify lines 24 and 29 (figure 1) assuming that the mathematical marking is defined relationally "mark(g,x,g')" rather than functionally "mark(g,x) = g'".  For a variety of reasons discussed in section 2.1 (the last paragraph starting on page 2), relational specifications are better.

In terms of whether the mechanization is sizable enough to justify publication in PLDI, all we can say is that the 32.5k LOC codebase we developed (table 1) was sizable in part because we wanted a general solution rather than the minimal solution required to get a few examples to go through.  As we mention above, we are in the process of using the same development to verify a much larger and more complicated example (a 400-line garbage collector).

We can definitely apply RAMIFY-PQ for functions that do not preserve a graph's set of nodes.  We do so in "copy", where the set of nodes grows.  In theory we could also do so to shrink the set of nodes.  However, the ramification entailment might be difficult prove, since in general safely deleting a node from a graph requires that you prove that no other nodes point to it (since otherwise afterwards they will point to an invalid location), which in general is not a local property.  However, you could imagine a situation in which this was provable, e.g. in which nodes kept a count of the number of incoming edges; in this case if you remove the last edge then RAMIFY-PQ will certainly allow you to remove (and even free the memory of) the now-disconnected node.

Our theory definitely applies to overlaid data structures e.g. threaded trees.  However, we have not yet coded up the infrastructure to make this work smoothly.  This is our second ongoing project (in addition to the garbage collector mentioned above).

Response to reviewer C:

As discussed in section 2.4, in addition to "mark" for graphs, we have verified "mark" for DAGs, "spanning tree" for graphs, and "copy" for graphs.  Both "spanning" and "copy" are in Appendix A (and have of course been 100% verified in Coq).  We can definitely do other examples, including those from other people without making any modifications; it's just an issue of "turning the crank" enough times.  As mentioned to reviewers A and B above, we are currently working on a 400-line garbage collector written by the CertiCoq project.

Response to reviewer D:

We again would like to register our strong disagreement with reviewer D's assertion that one can easily avoid the problems of modified variables.  Partly as a result of reviewer D's POPL review, we discussed this in several places in the current submission, e.g. the first two paragraphs of section 4.

We wish to verify graph-manipulating programs in the verification tools that exist today.  Both VST and H/S use the standard model for program variables.  Both have very large codebases (about 140k and 179k LOC respectively, each representing more than 50 person-years of work), and in both cases it would be a massive effort to rewrite something as fundamental as their treatment of modified program variables.  It would also be a significant effort to add a module to reason about program equivalence (both of these possibilities are discussed in the two paragraphs at the start of section 4).  For example, VST does not allow pointer dereferences in any commend other than assignments, and even there only allows a single dereference.  The transformation you propose (to say nothing of its proof) will not be as straightforward to implement as you assume it will be.  Our modifications to VST and H/S are only approximately 1.4% of their codebases.

Moreover, as we mention in section 8, most other verification tools also model program variables in the standard way.  Many also have quirks; for example, Charge! also prohibits pointer dereferences in any command other than assignments and even in assignments only allows a single dereference.  We believe that Charge!, as well as other tools, can add our technique with minimal effort.  We appreciate that our demonstration of this with H/S is not ideal, since we have not yet gotten additional examples to work.  However, the difficulties we have encountered are related to other issues with H/S such as the requirement that all spatial predicates have a root pointer (see the discussion we added to this version of the paper at the end of section 3.1).  Our technique was difficult to develop precisely because we wanted it to work in a variety of tools and this gave us a very restricted set of choices.

We would also like to emphasize again that even if one handled modified variables differently, one would want to handle existential quantifiers in postconditions.  We modified several parts of the paper to make this clearer.  For example, the first paragraph of section 4 references lines 22-26 in figure 1 exactly to make this point.  Neither variables-as-resource nor local program transformations will help verify this recursive call given the existentially-quantified postcondition of the function.

We also disagree with the characterization of the "fold-unfold" lemmas, although we did modify the paper in a number of places as a result of reviewer D's review in POPL.  For example, we reworked our claims in section 6 to make it clearer that others had defined graphs in a flat way before and to provide better connections to that previous work.  We repeat that what is novel is 6.1 (showing that standard recursive methods fail) and the second half of 6.2 (showing that we can recover the fixed point).

As we mention in section 8, we are aware of other published examples that have made the error exposed in 6.1 ("defining" graphs recursively).  In our POPL submission we did not cite any out of a desire to avoid embarrassing members of the community, but after reading our POPL reviews we reluctantly provided one such reference in this submission [23].  The error is subtle and easy to make.

We do mention (at the end of section 6.2) that some of the VST proofs do not use fold-unfold, but others do.  We prefer to give verifiers as many tools as we can; their job is hard enough already.  In addition to the VST proof that uses fold/unfold, the H/S setup requires it.  We are still unaware of any published work that defines graphs in a flat way and then shows that you can still reason recursively, which is the main result of 4.2.  Moreover, proving fold/unfold is not trivial (e.g. in the <= direction one runs into alignment/skewing issues).
