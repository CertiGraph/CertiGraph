We would like to thank reviewers for their time, especially reviewers A & C for their detailed comments.  However, we strongly disagree with reviewer C’s characterization of our work, especially in sections 2 and 4.

Specifically, in section 2 reviewer C’s suggestion to instead use standard techniques like “a more uniform heap-based model”, by which we think C means “variables as resource” is a cop out.  Both VST and H/S use the standard model for program variables.  Both have very large codebases (about 140k and 179k LOC respectively, each representing more than 50 person-years of work), and in both cases it would be a massive effort to rewrite something as fundamental as their treatment of modified program variables.  Moreover, as we mention in section 8, most other verification tools also model program variables in the standard way.  We want a solution that is widely applicable to tools as they actually exist today.  One measure of showing that we have accomplished this is that the modifications to Floyd and H/S (1.9k and 2.5k LOC as per Table 1) were only approximately 1.4% of their respective codebases.  (We mention in 2.4 that systems that do not wish to add our modal operator [c] can bundle the RAMIFY-PQ and SOLVE RAMIFY-PQ rules together.)

Given this strong motivation to work within the standard model for program variables, we also reject the idea that the modifications were straightforward.  Firstly, finding a relatively short and clean rule that works in practice and at scale is usually difficult, and the amount of ink needed to express such a rule is not a good metric of the significance of the accomplishment.  Even if it were, since the RAMIFY-PQ and SOLVE-RAMIFY-PQ rules are designed together, the “new style” has two entailments (rather than just one in RAMIFY) as well as a universal quantifier so that we can extract existential quantifiers from the localization block.  Secondly, to dismiss the second entailment automatically requires the rather delicate and subtle manipulations we show in 2.3, so in fact the design of RAMIFY-PQ, SOLVE-RAMIFY-PQ, and these manipulations were all tightly interlinked.  Finally, even in a variables-as-resource world we would need to extract existential quantifiers to specify programs relationally rather than functionally, e.g. in lines 25-26 in figure 1.

In section 4, we did not mean to claim that “flat” graphs originated with us, and apologize if it came off that way.  What was new was 4.1 (showing that standard recursive methods fail) and the second half of 4.2 (showing that we can recover the fixed point).  We know of published uses of “flat” graphs that do *not* use fold-unfold as well as published uses of “recursive” graphs (beyond Hobor & Villard) that contain the mistake uncovered in 4.1.  We are unaware of any published work that defines graphs in a flat way and then shows that you can still reason recursively, which is the main result of 4.2.  Moreover, proving fold/unfold is not trivial (e.g. in the <= direction one runs into alignment/skewing issues).

In response to reviewer A's questions:

1. You are asking about several distinct things.  First, we are aware of three different SL graph definition styles: fold/unfold (as in Figure 1), flat-but-rooted (as in section 4.2), and flat-whole-graph (as in [Sergey et al. 2015]).  The major advance in section 4 was that the first two styles are mutually compatible – call both of them in the “local style” because the graph predicate takes both a mathematical graph and a root.  The third “global style”, in which the graph predicate takes a mathematical graph but no root, is not compatible with fold/unfold but we do not say (or think) that means it is an unreasonable choice.

We used local style fold/unfold graphs in Figure 1 because we think it most closely mirrors traditional SL proofs and would thus be the simplest for readers to follow.  We do think that the program invariants in Figure 1 are natural, which we think is important.  However, global style graph predicates can also produce natural invariants, and we encourage experimentation; generally speaking we think that the more options verifiers have the better.  In most of our VST proofs we used the flat-but-rooted style since with the aid of a clever human we found we did not need fold/unfold.  In our H/S proof we did use fold/unfold because they mirror the way H/S treats other predicates in SL, allowing us to leverage other parts of the H/S codebase.  However, we suspect that with additional work H/S could do global-style proofs as well.  (We also note as an aside that the arguments for global-style graphs in concurrent settings may be stronger than they are in the sequential settings we considered.)

Second, you are asking about whether the “ramified frame rule” is essential.  To do the recursive calls, global style proofs do not need such a rule (a point in their favor), although our ramification library makes such localizing straightforward in the context of a concrete verification.  However, to modify the root, we believe both the local and the global styles essentially need a ramification.  That is, you need to do a fancy frame (the rest of the graph, expressed one way or another), a local modification to the node you are left with, and then after getting the frame back a fancy rule of consequence (to move from mathematical graph g1 to mathematical graph g2, where g2 has been updated from g1 appropriately).  Ramification packages this idea up nicely, but you could do it with FRAME and CONSEQUENCE directly if you preferred.  Similarly, RAMIFY-PQ is useful for more than just graphs.  For example, recently the proof of the LOAD rule in VST was nicely simplified using localize and unlocalize.  (Note that LOAD of course also modifies program variables.)

2. Ribbon proofs are a way to visualize FRAME (how spatially distinct premises are “piped around”).  Localization proofs are a way to visualize RAMIFY (how changes in the local state impact the global).  This is part of why we sometimes put lightning bolts with lemma numbers (e.g. line 18 in figure 1).  Ribbon proofs don’t need lightning bolts because they are just FRAME.

3. If “x |-> left, right”, and “left is a tree”, and “right is a tree”, you don’t know that x is a tree (the simplest counterexample is when left = right).  It took some effort to find this conjunct.

4. * mark (both graph & dag): 5 files; 1,039 lines
* copy (graph): 4 files; 1,027 lines
* spanning tree (graph): 4 files; 1,187 lines

We have two general points about the length.  First, most of our mathematical proofs are done in general settings – for example, most of our proofs about “copy” do not assume that a node has at most two children.  This adds some effort but lets us apply them in more settings.  Second, some of the size is just due to the complexity of verifying real code.  For comparison, verifying a simple list-based merge sort in VST takes 600 lines.

5. Yang used many explicit wands.  Bornat et al. used * to partition the graph into many disjoint pieces based on reachability.  Reynolds presented U* but never really used it.  Gardner et al. used U* in a single specific spot and reasoned about it in an ad-hoc way.  Raad et al. used fold/unfold graphs in a concurrent setting (as did Hobor & Villard and as does H/S and 1 VST verification in the present paper).  Sergey et al. used a global-style graph also in a concurrent setting (but did not have any kind of fold/unfold ability).  Leino used a global-style graph in a sequential (non-SL) setting and so also did not have any kind of fold/unfold, although he did modify the vertices represented in the graph as he processed nodes so it could be considered a hybrid of the global style and the flat-but-rooted/local style.