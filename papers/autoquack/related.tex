\paragraph{Comparison with Hobor and Villard.}
The most direct ancestor of our work is \cite{hobor:ramification}, which focused on verifying graph algorithms using and introduced the \infrulestyle{Ramify} rule.  We have generalized this rule to better handle modified program variables and existential quantifiers in postconditions; they hacked their way around these issues by proposing a variant of \infrulestyle{Ramify} called \infrulestyle{RamifyAssign}, which could reason about the special case of a single assignment $\li{x=}f(\ldots)$, assuming the verifier can make the local program translation to $\li{x'=}f(\ldots)\li{; x=x'}$, where \li{x'} is fresh.  They proposed no way to verify unmodified program code, to modify program variables inside nested localization blocks, or to do a ramification across multiple assignments as we do in lines~\ref{code:markbeforetripleramify}--\ref{code:markaftertripleramify} of figure~\ref{fig:markgraph}.  Hobor and Villard avoided existentials in localized postconditions because they defined all of their mathematical operations (\emph{e.g.} $\m{mark}$, $\m{mark1}$) as functions rather than as relations.

Hobor and Villard treated mathematical graphs very simply, as triples $(V,E,L)$ of vertices, edges, and a labeling function on vertices.  Vertices had no more than two neighbors.  In contrast, our mathematical graph framework~(\S\ref{sec:mathgraph}) is very modular and general and has been tuned to work smoothly in a mechanized context.

Hobor and Villard fell into the trap of defining spatial graphs recursively~(\S\ref{sec:fixpointfail}); unfortunately other members of the research community have since followed them in; in their defense they asserted an equivalence with a $\bigstar$ form and other than that single proof their paper has no significant errors.  We exposed their error and provided a sound and quite general definition for \p{graph}~(\S\ref{sec:goodgraph}) that recovers fold/unfold reasoning.  We developed a much more general and more modular set of related lemmas and connect our spatial reasoning to two very different verification tools~(\S\ref{sec:ramifylib}), VST~(\S\ref{sec:vst}) and HIP/SLEEK~(\S\ref{sec:hipsleek}).  Our entire development is machine-checked (\S\ref{sec:development}) whereas Hobor and Villard used only with pen-and-paper.

\paragraph{Local variables.}
An alternative way to avoid local variable issues is to use ``variables as resource''~\cite{bornat:var}.
Unfortunately variables as resource introduces other unpleasantness, which is why many mechanized verification systems do not use it\cite{Beckert:2007,DistefanoP08,chin:hipsleek,Leino10,bengtson:charge,appel:programlogics}.
\paragraph{Verification tools.}

Like many other verification tools~\cite{berdine:smallfoot,jacobs:verifast}, HIP/SLEEK uses forward reasoning based on symbolic execution.

\cite{bengtson:charge} present a set of Coq based tactics for working with a shallow embedding of higher order separation logic that is somewhat similar to Floyd but for reasoning about OO programs (written in Java/C\#). A  more automated approach to verification of low level programs using Coq is implemented in the Bedrock framework \cite{chlipala:bedrock}.

Other separation logic based automated verification tools include Verifast \cite{jacobs:verifast}, jStar \cite{DistefanoP08} and Smallfoot \cite{berdine:smallfoot}. Similar to HIP/SLEEK, they all use forward reasoning but have limited support for user-defined inductive predicates and instead rely on a library of pre-defined predicates for lists, trees etc.. Dafny \cite{Leino10} and KeY \cite{Beckert:2007} are two notable verifiers that are not based on separation logic. The KeY tool uses an interactive verifier while Dafny is automated using an SMT solver Z3.

\paragraph{Verification of graph algorithms, $**$}

Yang, Bornat: early work

Reynolds's notes: $**$

Javascript: Gareth

concurrent, paper: Azalea

In Coq, concurrent: Ilya and Aleks

\paragraph{Mechanized mathematical graph theory.}

The most famous graph related theorem which has been mechanically
verified is the Four Color Theorem: Any planar map can be colored with
only four colours. In 2005, Benjamin Werner and Georges Gonthier
formalized a proof of the theorem \cite{gonthier2005computer} inside
Coq. It is very easy and natural to rephrase the problem in graph
theory: by taking regions as nodes and connecting each pair of
adjacent regions as edges, coloring the map is equivalent to coloring
the graph obtained. However, they used a different kind of
combinatorial structure, known as hypermaps, instead of
graphs. Basically, a hypermap is a type ``dart'' with several
functions mapping dart to dart. The combinatorial and geometrical
properties are encoded as certain permutation properties of those
functions. It is quite a very different structure from graph.

Lars Noschinski built a formalized graph library for the Isabelle/HOL
proof assistant and verified a method of checking Kuratowski subgraphs
used in the LEDA library. It supports general infinite directed graphs
with labeled and parallel arcs \cite{Noschinski2015}. His definition
of graph is similar to our PreGraph except he uses vertex/edge set
instead of validity functions. Besides, Noschinski's library also
covers basic graph related concepts such as reachable component and
spanning tree.

Nordhoff and Lammich \cite{Dijkstra_Shortest_Path-AFP} formalized and
proved Dijkstra's algorithm in Isabelle. Their graph is defined as
vertex and edge sets where the edge is a triple (source, label,
destination). They only defined what they need for the algorithm.

Written in HOL, Wong \cite{wong1991} expressed a small portion of the
conventional graph theory, which is mainly used to model the railway
track network and applied in signalling systems. It does not contain
too many graph property-related theorems.

Chou \cite{chou1994formal} formalized theory of undirected graphs in
HOL that emphasize on the notion and important properties of trees. He
applied this library to verified distributed algorithms
\cite{chou1995mechanical}.

Duprat \cite{duprat2001coq} formalized graph in an inductive way in
Coq. Only some basic properties are proved in it. To our knowledge, no
application is built on it.

In \cite{yamamoto1995formalization} a formalization of planar graph is
inductively defined in HOL. They use it to prove Euler's formula as an
application. \cite{tamai2000formal} treat the same problem. But their
purpose is just giving a formal specification in CafeOBJ. So their
graph library only contains formal definitions.

In \cite{yamamoto1998formalization}, Yamamoto et al formalized
directed graph based on Wong's work \cite{wong1991}. They proved the
correctness of the abstract A* algorithm based on graph and
semi-lattice. \cite{tamai2000formal}

NASA's graph theory library is written in PVS
\cite{R.W.:1998:PGT:886490}. It is restricted to finite graphs only
and does not support multi-edge graphs. They use the library to prove
Ramsey's Theorem and Menger's Theorem.

\cite{bauer20025} inherited the inductive approach of
\cite{yamamoto1995formalization} for the formalization of planar graph
theory. They formally proved the 5 color theorem using graph theory
and triangulations.

In \cite{nipkow2006flyspeck}, a finite, undirected, planar graph is
formalized as a list of faces and faces as lists of vertices. That
library is mainly used to prove the completeness of the enumeration of
tame graphs.

\cite{ridge2005graphs} also mechanised graphs and trees in
Isabelle/HOL. It is closed to \cite{wong1991} with the following
difference: the edges are represented as sets of vertices instead of
atomic objects.

In \cite{noschinski2015formalizing}, Noschinski presented a graph
library in Isabelle/HOL to reason about graphs and implemented a
verified decision procedure for combinatorial planarity of graphs. He
also verified checkers for both the planarity and the non-planarity
certificates emitted by the LEDA library. Both the implementation and
verification of the checker are written in the abstract language of
AutoCorres.

In \cite{dubois2015graphes} they proposed a formalization of graphs
without multiple edges. A formally verified auditor was developed to
certify the result of a function that calculates a maximum cardinality
matching. The executable code of the auditor is extracted from Coq
directly.

{\color{magenta}
5.2. An alternative way of verifying marking program is reasoning about the whole history of marking operations. The disadvantage of it is that it currently needs more work in a Hoare logic framework. The advantage of it is that its reasoning structure are more similar with the way we understand it in our first algorithm class.
5.3. I take some effort on garbage collector like graph structural. Though it is only connecting this special structural with 5.1.1 and 1.3, it takes much time and it is not finished yet.}


